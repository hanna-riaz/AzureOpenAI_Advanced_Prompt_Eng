{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import openai\n",
        "# from openai import AzureOpenAI\n",
        "# import os \n",
        "# from azure.identity import ManagedIdentityCredential\n",
        "\n",
        "# default_credential=ManagedIdentityCredential(client_id=\"f4980c43-9766-48d7-a925-c377a74605bb\")\n",
        "# token=default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "# Resource_endpoint=\"https://openaiykus.openai.azure.com/\"\n",
        "\n",
        "# client = AzureOpenAI(\n",
        "#   azure_endpoint = Resource_endpoint, \n",
        "#   api_key=token.token,  \n",
        "#   api_version=\"2023-05-15\"\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720079567328
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-dotenv\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting python-dotenv\n  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\nDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nInstalling collected packages: python-dotenv\nSuccessfully installed python-dotenv-1.0.1\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720028225972
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting openai\n  Downloading openai-1.35.9-py3-none-any.whl.metadata (21 kB)\nCollecting anyio<5,>=3.5.0 (from openai)\n  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\nCollecting distro<2,>=1.7.0 (from openai)\n  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\nCollecting httpx<1,>=0.23.0 (from openai)\n  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\nCollecting pydantic<3,>=1.9.0 (from openai)\n  Downloading pydantic-2.8.0-py3-none-any.whl.metadata (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sniffio (from openai)\n  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: tqdm>4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai) (4.66.4)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai) (4.12.2)\nRequirement already satisfied: idna>=2.8 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\nRequirement already satisfied: certifi in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\nCollecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\nCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\nCollecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\nCollecting pydantic-core==2.20.0 (from pydantic<3,>=1.9.0->openai)\n  Downloading pydantic_core-2.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nDownloading openai-1.35.9-py3-none-any.whl (328 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading anyio-4.4.0-py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\nDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic-2.8.0-py3-none-any.whl (423 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_core-2.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\nDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: sniffio, pydantic-core, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\nSuccessfully installed annotated-types-0.7.0 anyio-4.4.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.9 pydantic-2.8.0 pydantic-core-2.20.0 sniffio-1.3.1\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720028231441
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "    \n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
        "    api_version=\"2024-02-01\", #latest GA API version: https://learn.microsoft.com/en-us/azure/ai-services/openai/api-version-deprecation\n",
        "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720028259465
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getenv(\"AZURE_OPENAI_ENDPOINT\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://azuremlopenai.openai.azure.com/\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720028261803
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Temperature\n",
        "\n",
        "Defaults to 1, Optional\n",
        "\n",
        "What sampling temperature to use, between 0 and 2. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 for ones with a well-defined answer.\n",
        "\n",
        "We generally recommend altering this or top_p but not both."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(num_times, start_phrase, temperature):\n",
        "    for i in range(num_times):\n",
        "        \n",
        "        deployment_name='gpt-35-turbo' \n",
        "\n",
        "        # Send a completion call to generate an answer\n",
        "        response = client.completions.create(\n",
        "            model=deployment_name, \n",
        "            prompt=start_phrase, \n",
        "            temperature=temperature,\n",
        "            max_tokens=10)\n",
        "        print(response.choices[0].text)\n",
        "        print(\"*****************************\")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1720028405274
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'Azure machine learning is ', temperature = 0)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720028410613
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'Azure machine learning is ', temperature =0.5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " a cloud-based platform for building, deploying, and\n*****************************\n100% cloud-based. It can be used to\n*****************************\n a cloud-based service that provides a platform for training\n*****************************\n a cloud-based platform for machine learning. It provides\n*****************************\n a cloud-based service that provides a set of tools\n*****************************\n100% cloud-based and fully managed. It is\n*****************************\n used to build, train and deploy machine learning models\n*****************************\n100% cloud-based and offers a wide range of\n*****************************\n a cloud based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools for building,\n*****************************\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720028422450
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Top_p\n",
        "\n",
        "Defaults to 1, Optional\n",
        "\n",
        "top_p parameter which stands for “top probability” and an alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. \n",
        "\n",
        "The top_p refers to the probability mass that should be used when considering the next word in the generated text. Essentially it ** sets a threshold for the probability of the next word being chosen and only considers the most likely words that exceed that threshold.**\n",
        "\n",
        "We generally recommend altering this or temperature but not both."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(num_times, start_phrase, top_p):\n",
        "    for i in range(num_times):\n",
        "        \n",
        "        deployment_name='gpt-35-turbo' \n",
        "\n",
        "        # Send a completion call to generate an answer\n",
        "        response = client.completions.create(\n",
        "            model=deployment_name, \n",
        "            prompt=start_phrase, \n",
        "            top_p=top_p,\n",
        "            max_tokens=30)\n",
        "        print(response.choices[0].text)\n",
        "        print(\"*****************************\")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1720028486898
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'Azure machine learning is ', top_p = 0.1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a drag-and-drop interface to build models and a\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a drag-and-drop interface to build models and a\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a drag-and-drop interface to build models and a\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a drag-and-drop interface to build models and pipelines\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a drag-and-drop interface to build models and pipelines\n*****************************\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1720028491828
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'Azure machine learning is ', top_p = 1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " rapidly growing Microsoft cloud-based application that enables customers to create tools and applications for data analysis, machine learning, and intelligent predictions. The two Azure Machine Learning\n*****************************\n100% free (if you don’t use more than two cores) and allows you to easily build very complex models. It’s the cloud version of\n*****************************\n designed to handle data in its multiple format and environments, it allows for fast data loading , manipulating, and processing. It provides several data ingestion methods.\n*****************************\n10% service and 90% model management & automation. The service you will see in this exercise involves creating a model, however the real productivity comes\n*****************************\n100% no code. Basic machine learning where you just give upload your data and model will train and you can deploy that. But suppose if you a\n*****************************\n a cloud-based platform for data scientists to build and deploy machine learning models. Utility of ML comes in building predictive models from large or complex datasets that no\n*****************************\n100% compatible with Scikit learn, and have many tools optimized for large datasets.\"\n]\n\nto_clean = ['text', 'text2']\n\ncorpus\n*****************************\n python Package and web-based interface to work with the azure ML features provided by azure cloud platform. It tools helps to build the ML model by drag and\n*****************************\n100% “serverless” solution. It takes care of the underlying infrastructure and with pay-as-you-go model, makes machine learning accessible to everyone.\n*****************************\n used for builders, data scientists and developers to create, build, train and deploy machine learning models. Models are then used elsewhere either to perform predicting or\n*****************************\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1720028498656
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Max_Tokens \n",
        "\n",
        "Default value=16, Optional\n",
        "\n",
        "The maximum number of tokens to generate in the completion. **The token count of your prompt plus max_tokens can't exceed the model's context length. **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deployment_name='gpt-35-turbo' \n",
        "#This will correspond to the custom name you chose for your deployment when you deployed a model. \n",
        "    \n",
        "# Send a completion call to generate an answer\n",
        "start_phrase = 'Azure machine learning is '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    temperature=1,\n",
        "    max_tokens=15)\n",
        "\n",
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9gyJ6s7BPDMGpbkiNsT6qHv0ua9mM\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"text\": \" now Azure machine learning studio in the azure portal. It connects to Azure ML\",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1720028624,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 15,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 20\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720028624456
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Send a completion call to generate an answer\n",
        "start_phrase = 'The Bupa company is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    temperature=1,\n",
        "    max_tokens=90)\n",
        "\n",
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9gyJnC2iEWaPk0pZbePTjpqpWFfmg\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"text\": \"73 million year old giant. While not as ancient as Thundersaurus, who was formed when both Tommy and Trey were zords, it’s still one of the longest running private healthcare companies in the world.\\n\\nBattlizer? Once again, this is the distillation of what it means to be Power Rangers. Battlizers represent another level of power one can obtain in order to defeat the stronger enemies that may come our way. With the\",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1720028667,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 90,\n    \"prompt_tokens\": 7,\n    \"total_tokens\": 97\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720028667260
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# n\n",
        "\n",
        "Defaults to 1, optional\n",
        "\n",
        "How many completions to generate for each prompt. To generate multiple completions, we specify the n request parameter, which simply stands for ** “number of completions” **\n",
        "\n",
        "Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "deployment_name='gpt-35-turbo' \n",
        "#This will correspond to the custom name you chose for your deployment when you deployed a model. \n",
        "    \n",
        "# Send a completion call to generate an answer\n",
        "start_phrase = 'Azure machine learning is '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    temperature=1,\n",
        "    n=3)\n",
        "\n",
        "for i in response.choices:\n",
        "    print(i.text)\n",
        "    print (\"**************************\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " backed by popular ML libraries such as RDKit, TensorFlow, PyTorch,\n**************************\n a cloud-based service that provides tools for building, training, and deploying machine learning\n**************************\n based on the concepts of experiments and runs. An experiment consists of a series of\n**************************\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720028726949
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# logprobs\n",
        "\n",
        "Defaults to null, optional\n",
        "\n",
        "Log probabilities of output tokens indicate **the likelihood of each token occurring in the sequence given the context.** To simplify, a logprob is log(p), where p = probability of a token occurring at a specific position based on the previous tokens in the context.\n",
        "\n",
        "For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response.\n",
        "\n",
        "** tokens ** — is an array of tokens generated by the language model. Each token is a word or part of a word.\n",
        "\n",
        "** token_logprobs ** — represents an array of log probabilities for each token in the tokens array. Log probability indicates the likelihood of the language model generating that token for the given prompt. The logprob values are negative, where smaller (more negative) numbers indicate a less likely outcome.\n",
        "\n",
        "** top_logprobs ** — represents an array of log probability objects, representing tokens most likely to be used for the completion. For example, if we specify the request parameter top_p = 0.5, then top_logprobs would contain log probabilities for top 50% of generated tokens."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'Azure machine learning is  '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    temperature=0,\n",
        "    logprobs=2)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720028786448
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].text"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "' a cloud-based service that provides tools for building, deploying, and managing machine learning'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720028788239
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9gyLizaKP2S3HMPPyyuDvTPGa27uS\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": {\n        \"text_offset\": [\n          27,\n          29,\n          35,\n          41,\n          49,\n          54,\n          63,\n          69,\n          73,\n          82,\n          83,\n          93,\n          94,\n          98,\n          107,\n          115\n        ],\n        \"token_logprobs\": [\n          -1.3544242,\n          -0.5052965,\n          -0.33200297,\n          -1.3254664,\n          -0.74125546,\n          -1.3207276,\n          -1.5644419,\n          -0.8489064,\n          -0.5393729,\n          -0.46892568,\n          -0.54874253,\n          -0.2936565,\n          -0.079444215,\n          -0.48917344,\n          -0.09763703,\n          -0.018707484\n        ],\n        \"tokens\": [\n          \" a\",\n          \" cloud\",\n          \"-based\",\n          \" service\",\n          \" that\",\n          \" provides\",\n          \" tools\",\n          \" for\",\n          \" building\",\n          \",\",\n          \" deploying\",\n          \",\",\n          \" and\",\n          \" managing\",\n          \" machine\",\n          \" learning\"\n        ],\n        \"top_logprobs\": [\n          {\n            \" a\": -1.3544242,\n            \" used\": -3.096278\n          },\n          {\n            \" cloud\": -0.5052965,\n            \" fully\": -2.8223684\n          },\n          {\n            \"-based\": -0.33200297,\n            \" based\": -2.368193\n          },\n          {\n            \" service\": -1.3254664,\n            \" platform\": -1.5957549\n          },\n          {\n            \" that\": -0.74125546,\n            \" for\": -1.9083602\n          },\n          {\n            \" provides\": -1.3207276,\n            \" enables\": -1.8764279\n          },\n          {\n            \" tools\": -1.5644419,\n            \" a\": -1.9370768\n          },\n          {\n            \" for\": -0.8489064,\n            \" to\": -0.9779347\n          },\n          {\n            \" building\": -0.5393729,\n            \" data\": -1.4708171\n          },\n          {\n            \",\": -0.46892568,\n            \" and\": -1.7726157\n          },\n          {\n            \" deploying\": -0.54874253,\n            \" training\": -1.5892203\n          },\n          {\n            \",\": -0.2936565,\n            \" and\": -1.4170219\n          },\n          {\n            \" and\": -0.079444215,\n            \" testing\": -4.4498515\n          },\n          {\n            \" managing\": -0.48917344,\n            \" sharing\": -1.7967639\n          },\n          {\n            \" machine\": -0.09763703,\n            \" predictive\": -3.9510438\n          },\n          {\n            \" learning\": -0.018707484,\n            \"-learning\": -4.8182507\n          }\n        ]\n      },\n      \"text\": \" a cloud-based service that provides tools for building, deploying, and managing machine learning\",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1720028786,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 16,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 21\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720028794392
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720028873453
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Word values :\",response.choices[0].logprobs.tokens)\n",
        "print(\"Token log probabilities :\",response.choices[0].logprobs.token_logprobs)\n",
        "print(\"Top log linear probabilities :\",np.round(np.exp(response.choices[0].logprobs.token_logprobs)*100,2))\n",
        "\n",
        "print(\"Response:\", response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Word values : [' a', ' cloud', '-based', ' service', ' that', ' provides', ' tools', ' for', ' building', ',', ' deploying', ',', ' and', ' managing', ' machine', ' learning']\nToken log probabilities : [-1.3544242, -0.5052965, -0.33200297, -1.3254664, -0.74125546, -1.3207276, -1.5644419, -0.8489064, -0.5393729, -0.46892568, -0.54874253, -0.2936565, -0.079444215, -0.48917344, -0.09763703, -0.018707484]\nTop log linear probabilities : [25.81 60.33 71.75 26.57 47.65 26.69 20.92 42.79 58.31 62.57 57.77 74.55\n 92.36 61.31 90.7  98.15]\nResponse:  a cloud-based service that provides tools for building, deploying, and managing machine learning\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720028875491
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Presence_penalty\n",
        "\n",
        "Defaults to 0, Optional -> 0 means there is really no penalty or reward for the same token appearing multiple times. \n",
        "\n",
        "Number between -2.0 and 2.0. Positive values penalize new tokens based on ** whether they appear in the text so far **, increasing the model's likelihood to talk about new topics.\n",
        "\n",
        "Smaller values (minimum -2) decrease the penalty and increase the chances of a token appearing, while higher values (maximum 2) increase the penalty and decrease the chances of a token appearing."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'Azure machine learning is '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    presence_penalty=2,\n",
        "    max_tokens=50)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720029368450
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " used for building the models using data and deploy that trained model to make predictions. By doing this we can create a complete workflow within a single MLOps tool.\n\nAzure machine learning provides an integrated version control, test each deployment automatically, allow us to\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720029371844
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'Azure machine learning is '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    presence_penalty=-2,\n",
        "    max_tokens=50)\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " most commonly used for developing, deploying, and sharing predictive analytics models, along with developing and sharing data preparation and transformation solutions and automating model generation and training.\n\nThe platform allows for building and training models with popular machine learning frameworks, and deploying models as\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720029536967
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9gyXo0lwHERGp5EvVWF35QMZWAFFL\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"text\": \" most commonly used for developing, deploying, and sharing predictive analytics models, along with developing and sharing data preparation and transformation solutions and automating model generation and training.\\n\\nThe platform allows for building and training models with popular machine learning frameworks, and deploying models as\",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1720029536,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 50,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 55\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720029542854
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Frequency_penalty\n",
        "\n",
        "Defaults to 0\n",
        "\n",
        "Number between -2.0 and 2.0. Positive values ** penalize new tokens based on their existing frequency in the text so far **, decreasing the model's likelihood to repeat the same line verbatim."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Best_of\n",
        "\n",
        "Defaults to 1,optional\n",
        "\n",
        "This parameter tells the language model to generate multiple completions and return the best one, which is the one with the highest log probability per token.\n",
        "\n",
        "\n",
        "Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'The Bupa company is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    best_of=3,\n",
        "    max_tokens=50)\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "29-billion-pound revenue healthcare company from the United Kingdom that was started in 1947. It provides health insurance to its customers in more than 190 countries around the world. Until February 2021, it was located in central London but has now\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720029573590
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# logit_bias\n",
        "\n",
        "Defaults to null\n",
        "\n",
        "The logit_bias request parameter is used to modify the likelihood of specified tokens appearing in the completion. We can use this parameter to provide hints to the language model about **which tokens we want or don’t want to appear in the completion**. It basically allows us to make the model more biased towards certain keywords or topics."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-100 bias, which should completely prevent them from appearing.\n",
        "# 100 bias will show only that word\n",
        "start_phrase = 'The Bupa company is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    logit_bias={\"30\":10, \"5936\": 10})\n",
        "#5936 for April\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "70 year old organization with full UK coverage, acquired April? April? April? April? April? April? April? April? April? April? April? April? April? April? April? April? April? April? April? April?\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720029782073
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Echo and Stop"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By setting the echo parameter to true, you’re asking the language model to **return the prompt embedded within the completion.** This is useful for debugging."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'The Bupa company is a '\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    echo=False)\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "private health company. It provides a large range of health services which include health insurance, dental care, travel insurance, care homes, and physiotherapy. It has subsidiaries in a total of 190 countries and serves over 25 million clients. It\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720029894556
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ** stop ** parameter allows you to specify up to 4 sequences of text on which the language model will halt and return the result. This is useful for specifying early termination triggers for the language model."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'The Bupa company is a '\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    temperature=0,\n",
        "    stop=\"company\")\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "70-year-old \n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720030022270
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'The Bupa company is a '\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    temperature=0,\n",
        "    stop=[\"company\",\"United\"])\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "70-year-old \n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720030054405
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/reference"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}