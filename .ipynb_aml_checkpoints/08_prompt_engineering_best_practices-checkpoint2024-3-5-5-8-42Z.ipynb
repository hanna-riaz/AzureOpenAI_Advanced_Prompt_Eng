{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import openai\n",
        "# from openai import AzureOpenAI\n",
        "# import os \n",
        "# from azure.identity import ManagedIdentityCredential\n",
        "\n",
        "# default_credential=ManagedIdentityCredential(client_id=\"d30cba06-04c1-4065-a91d-8b7ce3b07b78\")\n",
        "# token=default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "# Resource_endpoint=\"https://openaiykus.openai.azure.com/\"\n",
        "\n",
        "# client = AzureOpenAI(\n",
        "#   azure_endpoint = Resource_endpoint, \n",
        "#   api_key=token.token,  \n",
        "#   api_version=\"2023-05-15\"\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700435703977
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "    \n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
        "    api_version=\"2024-02-15-preview\",#2024-02-01\n",
        "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293114576
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Understand the AOAI Models' capabilities. Start with the latest model, prove your idea , then test with smaller models. \n",
        "Model size is critical for better performance."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Be specific, descriptive and as detailed as possible about the desired context, outcome, length, format, style, etc"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Length ** control (specify desired output length e.g.: number of words)\n",
        "\n",
        "** Tone ** control (e.g.: polite, passionate, professional, technical, funny, casual, serious etc.)\n",
        "\n",
        "** Style ** control (e.g.: in the style of Shakespeare, JK Rowling, Nelson Mandela etc.)\n",
        "\n",
        "** Audience ** control (e.g.: a 5-year-old can understand etc)\n",
        "\n",
        "** Context ** control (e.g.: news, novel, textbook, report, white paper, blog etc.)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = \" Write a 2 paragraph inspiring poem which can be understood by 5 years-old child focussing on brands of The Very Group\"\n",
        "# Write a 2 paragraph inspiring poem about The Very Group company\n",
        "# Write a 2 paragraph inspiring poem focussing on products of the Very Group company in a funny way\n",
        "# Write a 2 paragraph inspiring poem focussing on products of The Very Group company in the style of Shakespeare\n",
        "# Write a 2 paragraph inspiring poem which can be understood by 5 years-old child focussing on products of The Very Group company\n"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293652630
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of appending, writing messages in the SDK\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "In a world filled with cheerful toys and pretty dresses, \nThere’s a place called The Very Group, that truly impresses.\nIt has Lego blocks to build your fantasy tower,\nBarbie dolls, tea parties, you could play for an hour! \nTed Baker clothes to make you look bright,\nWith Converse shoes, you’ll run as light as the night.\n\nSo dream big, little one, let your imagination take flight,\nWith The Very Group, every day is a colorful sight.\nFrom Littlewoods Home for your playful room,\nTo Sony Playstation, taking you to another planet's moon.\nYour world is full of wonders, just waiting to be unfurled,\nWith The Very Group, you'll discover your beautiful world!\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293663259
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Put instructions at the begining of the prompt and use ### or \"\"\" to separate the instruction and context"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\\\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \\\n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \\\n",
        "increasingly safe, useful, and powerful. \\n\\n \\\n",
        "In pursuit of our mission to ensure advanced AI benefits all of humanity, OpenAI remains a \\\n",
        "capped-profit company and is governed by the OpenAI non-profit. This structure allows us to \\\n",
        "raise the capital we need to fulfill our mission without sacrificing our core beliefs about \\\n",
        "broadly sharing benefits and the need to prioritize safety. \\\n",
        "Microsoft shares this vision and our values, and our partnership is instrumental to our progress.\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293394405
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by hashtags as a bullet point list of the most important points.\n",
        "###{text}###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293395454
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.completions.create(\n",
        "    model='gpt-35-turbo-instruct' , \n",
        "    prompt=prompt, \n",
        "    temperature=0,\n",
        "    max_tokens=60\n",
        "    )\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n- OpenAI and Microsoft are extending their partnership\n- Microsoft is making a multi-year, multi-billion dollar investment in OpenAI\n- This follows previous investments in 2019 and 2021\n- The partnership will allow OpenAI to continue independent research and develop safe, useful, and powerful\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293398150
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Articulate the desired output format through examples"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\""
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293405962
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_message=f\"\"\"Extract the entities mentioned in the text below. \n",
        "First extract all company names, then extract all years, \n",
        "then extract specific topics which fit the content and finally extract general overarching themes\\n\\n \n",
        "Desired format: \n",
        "Company names: <comma_separated_list_of_company_names> \n",
        "Years: \n",
        "Specific topics:\n",
        "General themes: \n",
        "### Text:\n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \n",
        "increasingly safe, useful, and powerful. \\n\\n \n",
        "###\n",
        "\"\"\"\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293412571
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of appending, writing messages in the SDK\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Company names: OpenAI, Microsoft\nYears: 2019, 2021\nSpecific topics: Partnership extension, Multi-year investment, Independent research, AI development\nGeneral themes: Corporate partnership, Investment in technology, AI research and development\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293418791
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Start with zero-shot, then few-shot (example)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\""
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293427985
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_zero=f\"\"\"Extract most important keywords from the corresponding texts below.\\n\\n \n",
        "\n",
        "###Text: \n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \n",
        "increasingly safe, useful, and powerful. \\n\n",
        "Keywords:###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293428995
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_zero}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "OpenAI, Microsoft, extending partnership, multi-year, multi-billion dollar investment, previous investments, 2019, 2021, independent research, develop AI, safe, useful, powerful.\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293432283
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_few=f\"\"\"Extract most important keywords from the corresponding texts below.\\n\\n \n",
        "### Text 1: \n",
        "Stripe provides APIs that web developers can use to integrate \n",
        "payment processing into their websites and mobile applications. \\n\n",
        "Keywords 1: Stripe, payment processing, APIs, web developers, websites \n",
        "### \n",
        "\n",
        "###Text 2: \n",
        "OpenAI has trained cutting-edge language models that are very good at understanding \n",
        "and generating text. Our API provides access to these models and can be used to solve virtually \n",
        "any task that involves processing language. \\n\n",
        "Keywords 2: OpenAI, language models, text processing, API.\n",
        "### \n",
        "\n",
        "###Text 3: \n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \n",
        "increasingly safe, useful, and powerful. \\n\n",
        "Keywords 3:\"\"\""
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293462169
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of appending, writing messages in the SDK\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_few}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "OpenAI, Microsoft, partnership, multi-year, multi-billion dollar investment, independent research, AI, safe, useful, powerful.\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293463853
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Instead of just saying what not to do, say what to do instead"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message= f\"\"\"You are an agent trying to diagnose the problem and suggest a solution, whilst refraining from asking any questions related to PII. \n",
        "Instead of asking for PII, such as username or password, refer the user to the help article www.samplewebsite.com/help/faq \\n\\n\"\"\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = \"I can’t log in to my account.\"\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293478935
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4-32k\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "I'm sorry to hear that you're having trouble logging in. This can often be due to incorrect username or password. Please ensure there are no typographical errors that might prevent logging in. If this doesn't work, you might want to consider resetting your password. You can do this by visiting our Help guide at www.samplewebsite.com/help/faq where you can find step-by-step instructions to assist in resetting your password.\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293517841
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Divide complex tasks into sub-tasks"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\""
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293544021
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "The Very Group: As the way families shop has changed, so have we. From catalogues, to bricks, to clicks, to mobile. We have consistently transformed to meet their needs.\n",
        "Our ambition is to build the most trusted ecosystem for families. We want to offer the most flexible ways to pay for all the brands, products, and services they want and need within a seamless digital experience. To achieve our ambition, we are focused on three things: ease, choice and understanding.\n",
        "\"\"\"\n",
        "# example 1\n",
        "user_message = f\"\"\"\n",
        "Perform the actions below by separating your answers with line breaks. \n",
        "1 - Summarize the following text below with 1 sentence.\n",
        "2 - Translate the summary into Turkish.\n",
        "3 - List each company name in the Turkish summary.\n",
        "4 - Output a json object that contains the following:\n",
        "keys: turkish_summary, turkish_company_names.\n",
        "\n",
        "###\n",
        "Text:\n",
        "{text} \n",
        "###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293719000
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4-32k\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293687227
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Chain of Thought"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The language model is prompted to generate a few intermediate reasoning steps to arrive at the final answer. \n",
        "\n",
        "Uses \"greedy decoding\" which means selecting the most likely token (word or character) at each step of the sequence generation process. At each time step, the model predicts the next token based on the previously generated tokens, and the token with the highest predicted probability is chosen as the output for that step. This process is repeated until the desired sequence length is reached or until a special end-of-sequence token is generated.\n",
        "\n",
        "**Temp=0** is used because it uses greedy decoding. It first creates the greedy coding and then the answer."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This prompt gets wrong answer\n",
        "\n",
        "PROMPT_ZERO_SHOT = \"\"\"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A: The answer (arabic numerals) is\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700437347240
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.completions.create(\n",
        "    model=\"gpt-35-turbo-instruct\", \n",
        "    prompt=PROMPT_ZERO_SHOT, \n",
        "    temperature=0,\n",
        "    max_tokens=60\n",
        "    )\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n6\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700437379127
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_ZERO_SHOT_CoT = \"\"\"Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A: Let’s think step by step.\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700437443843
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.completions.create(\n",
        "    model=\"gpt-35-turbo-instruct\", \n",
        "    prompt=PROMPT_ZERO_SHOT_CoT, \n",
        "    temperature=0,\n",
        "    max_tokens=100\n",
        "    )\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1. Roger has 5 tennis balls.\n2. He buys 2 cans of tennis balls, each with 3 balls. So, he has 5 + 2 x 3 = 11 tennis balls.\n3. He gives 4 of them to his friend. So, he now has 11 - 4 = 7 tennis balls.\nTherefore, Roger now has 7 tennis balls.\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700437479151
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_FEW_SHOT_CoT = \"\"\"\n",
        "Q: Elif went to market with £10 and consumed £2. How much does she have now?\n",
        "A: Elif had £10 at the beginning. When she consumed £2, 10-2=8 , £8 remains.\n",
        "Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A:\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700437593310
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.completions.create(\n",
        "    model=\"gpt-35-turbo-instruct\", \n",
        "    prompt=PROMPT_FEW_SHOT_CoT, \n",
        "    temperature=0,\n",
        "    max_tokens=100\n",
        "    )\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Roger had 5 tennis balls at the beginning. He bought 2 cans of tennis balls, each with 3 balls, so he now has 5+2x3=11 tennis balls. After giving 4 to his friend, he has 11-4=7 tennis balls remaining.\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700437601095
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Auto-COT ** uses zero-shot-cot results just like few-shot learning for reasoning. Instead of using few-shot-cot, auto-cot can be useful and easy because you don't need to create manual examples (labels/reasonings)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Prompt_Auto_cot= f\"\"\"\n",
        "Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A: Let’s think step by step.Roger had 5 tennis balls at the beginning. He bought 2 cans of tennis balls, each with 3 balls, so he now has 5+2x3=11 tennis balls. After giving 4 to his friend, he has 11-4=7 tennis balls remaining.\n",
        "Q: Elif went to market with £10 and consumed £2. How much does she have now?\n",
        "A:\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 47,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700438804045
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.completions.create(\n",
        "    model=\"gpt-35-turbo-instruct\", \n",
        "    prompt=Prompt_Auto_cot, \n",
        "    temperature=0,\n",
        "    max_tokens=100\n",
        "    )\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Elif has £8 left after consuming £2.\n"
        }
      ],
      "execution_count": 48,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700438805650
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Self Consistency\n",
        "\n",
        "Self-consistency aims \"to replace the naive greedy decoding used in chain-of-thought prompting\". The idea is to sample multiple, diverse reasoning paths through few-shot CoT, and use the generations to ** select the most consistent answer.**\n",
        "\n",
        "In the chat scenarios, **Asking the model to self-verify** its own responses. Like a student double-checking their answers, the AI model cross-references its responses to maintain consistency. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= f\"\"\"When I was 6, my sister was half my age. Now\n",
        "I’m 70 how old is my sister?\"\"\""
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700438901194
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.completions.create(\n",
        "    model=\"gpt-35-turbo-yk\", \n",
        "    prompt=prompt, \n",
        "    temperature=0,\n",
        "    max_tokens=100\n",
        "    )\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".\n\nWhen I was 6, my sister was half my age. So, my sister was 6/2=3 years old.\n\nNow I’m 70. So, my sister is 70-6=64 years old.\n\nBut wait, my sister was half my age when I was 6. So, my sister is 64+3=67 years old.\n\nTherefore, my sister is 67 years old now.<|im_end|>\n"
        }
      ],
      "execution_count": 83,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700440779042
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2= f\"\"\"When I was 6, my sister was half my age. Now\n",
        "I’m 70 how old is my sister? Let's think step by step\"\"\""
      ],
      "outputs": [],
      "execution_count": 62,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700439663169
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2=f\"\"\"\n",
        "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,\n",
        "there will be 21 trees. How many trees did the grove workers plant today?\n",
        "A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.\n",
        "So, they must have planted 21 - 15 = 6 trees. The answer is 6.\n",
        "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
        "A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\n",
        "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
        "A: Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74\n",
        "chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\n",
        "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops\n",
        "did Jason give to Denny?\n",
        "A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\n",
        "lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\n",
        "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does\n",
        "he have now?\n",
        "A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so\n",
        "in total he has 7 + 2 = 9 toys. The answer is 9.\n",
        "Q: There were nine computers in the server room. Five more computers were installed each day, from\n",
        "monday to thursday. How many computers are now in the server room?\n",
        "A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =\n",
        "20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.\n",
        "The answer is 29.\n",
        "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many\n",
        "golf balls did he have at the end of wednesday?\n",
        "A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On\n",
        "Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\n",
        "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
        "A: She bought 5 bagels for $3 each. This means she spent 5\n",
        "Q: When I was 6 my sister was half my age. Now I’m 70 how old is my sister?\n",
        "A:.\"\"\""
      ],
      "outputs": [],
      "execution_count": 79,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700440713168
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.completions.create(\n",
        "    model=\"gpt-35-turbo-yk\", \n",
        "    prompt=prompt2, \n",
        "    temperature=0,\n",
        "    max_tokens=100\n",
        "    )\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " When you were 6, your sister was half your age, so she was 6 / 2 = 3 years old. You are now 70. That means\nyour sister is 70 - (6 - 3) = 67 years old. The answer is 67.\nQ: A car travels 120 miles in 2 hours. How many miles will it travel in 5 hours?\nA: The car travels 120 miles in 2 hours. That means it\n"
        }
      ],
      "execution_count": 82,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700440763036
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"response = client.completions.create(\n",
        "    model=\"gpt-35-turbo-instruct\", \n",
        "    prompt=PROMPT_FEW_SHOT_CoT, \n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    n=4\n",
        "    )\n",
        "\n",
        "print(response.choices[0].text)\"\"\""
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 60,
          "data": {
            "text/plain": "'response = client.completions.create(\\n    model=\"gpt-35-turbo-instruct\", \\n    prompt=PROMPT_FEW_SHOT_CoT, \\n    temperature=0,\\n    max_tokens=100,\\n    n=4\\n    )\\n\\nprint(response.choices[0].text)'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 60,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700439621454
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling independently to remove any bias\n",
        "def call_openai(num_times, prompt, temperature):\n",
        "    for i in range(num_times):\n",
        "        \n",
        "        response = client.completions.create(\n",
        "        model=\"gpt-35-turbo-yk\", \n",
        "        prompt=prompt2, \n",
        "        temperature=0,\n",
        "        max_tokens=100\n",
        "        )\n",
        "\n",
        "        print(response.choices[0].text)\n",
        "        print(\"*****************************\")"
      ],
      "outputs": [],
      "execution_count": 80,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700440721857
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, prompt2, temperature = 1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " When you were 6, your sister was half your age, so she was 6 / 2 = 3 years old. You are now 70. That means\nyour sister is 70 - (6 - 3) = 67 years old. The answer is 67.\nQ: A car travels 120 miles in 2 hours. How many miles will it travel in 5 hours?\nA: The car travels 120 miles in 2 hours. That means it\n*****************************\n When you were 6, your sister was half your age, so she was 6 / 2 = 3 years old. You are now 70. That means\nyour sister is 70 - (6 - 3) = 67 years old. The answer is 67.\nQ: A car travels 120 miles in 2 hours. How many miles will it travel in 5 hours?\nA: The car travels 120 miles in 2 hours. That means it\n*****************************\n When you were 6, your sister was half your age, so she was 6 / 2 = 3 years old. You are now 70. That means\nyour sister is 70 - (6 - 3) = 67 years old. The answer is 67.\nQ: A car travels 120 miles in 2 hours. How many miles will it travel in 5 hours?\nA: The car travels 120 miles in 2 hours. That means it\n*****************************\n When you were 6, your sister was half your age, so she was 6 / 2 = 3 years old. You are now 70. That means\nyour sister is 70 - (6 - 3) = 67 years old. The answer is 67.\nQ: A car travels 120 miles in 2 hours. How many miles will it travel in 5 hours?\nA: The car travels 120 miles in 2 hours. That means it\n*****************************\n When you were 6, your sister was half your age, so she was 6 / 2 = 3 years old. You are now 70. That means\nyour sister is 70 - (6 - 3) = 67 years old. The answer is 67.\nQ: A car travels 120 miles in 2 hours. How many miles will it travel in 5 hours?\nA: The car travels 120 miles in 2 hours. That means it\n*****************************\n When you were 6, your sister was half your age, so she was 6 / 2 = 3 years old. You are now 70. That means\nyour sister is 70 - (6 - 3) = 67 years old. The answer is 67.\nQ: A car travels 120 miles in 2 hours. How many miles will it travel in 5 hours?\nA: The car travels 120 miles in 2 hours. That means it\n*****************************\n When you were 6, your sister was half your age, so she was 6 / 2 = 3 years old. You are now 70. That means\nyour sister is 70 - (6 - 3) = 67 years old. The answer is 67.\nQ: A car travels 120 miles in 2 hours. How many miles will it travel in 5 hours?\nA: The car travels 120 miles in 2 hours. That means it\n*****************************\n When you were 6, your sister was half your age, so she was 6 / 2 = 3 years old. You are now 70. That means\nyour sister is 70 - (6 - 3) = 67 years old. The answer is 67.\nQ: A car travels 120 miles in 2 hours. How many miles will it travel in 5 hours?\nA: The car travels 120 miles in 2 hours. That means it\n*****************************\n When you were 6, your sister was half your age, so she was 6 / 2 = 3 years old. You are now 70. That means\nyour sister is 70 - (6 - 3) = 67 years old. The answer is 67.\nQ: A car travels 120 miles in 2 hours. How many miles will it travel in 5 hours?\nA: The car travels 120 miles in 2 hours. That means it\n*****************************\n When you were 6, your sister was half your age, so she was 6 / 2 = 3 years old. You are now 70. That means\nyour sister is 70 - (6 - 3) = 67 years old. The answer is 67.\nQ: A car travels 120 miles in 2 hours. How many miles will it travel in 5 hours?\nA: The car travels 120 miles in 2 hours. That means it\n*****************************\n"
        }
      ],
      "execution_count": 81,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700440735112
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Iterative approach\n",
        "\n",
        "Prompt engineering is an iterative process. If you're unsatisfied with the AI's response, refine your prompt and try again. Analyze the results you receive and consider adjusting your prompt's context, clarity, or structure. This process of trial and error will help you better understand how the AI model interprets your prompts and allow you to fine-tune your approach.\n",
        "\n",
        "·        Try different prompts to find what works best\n",
        "\n",
        "·        When attempting few-shot learning, try also to include direct instructions\n",
        "\n",
        "·        Rephrase a direct instruction set to be more or less concise, e.g.: taking a previous example and giving the next instruction without having to repeat the input\n",
        "\n",
        "·        Try different personas keywords to see how it affects the response style\n",
        "\n",
        "·        Use fewer or more examples in the few-shot learning\n",
        "\n",
        "·        Co-create with AI: An example of a very useful prompt to get a good output from the LLM :"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=f\"\"\"\n",
        "Financial highlights\n",
        "Operating profit \n",
        "before tax1\n",
        "£210m\n",
        "(2021: £133m)\n",
        "Transfer (from)/to the fund \n",
        "for future appropriations2 \n",
        "£(162)m\n",
        "(2021: £79m)\n",
        "Assets under \n",
        "management\n",
        "£147bn\n",
        "(2021: £164bn)\n",
        "Investor View capital \n",
        "cover ratio3\n",
        "213%\n",
        "(2021: 216%)\n",
        "Operational highlights\n",
        "Total number \n",
        "of members\n",
        "2.0m\n",
        "(2021: 1.8m)\n",
        "Employee \n",
        "engagement score5\n",
        "80%\n",
        "(2021: 79%)\n",
        "Total number \n",
        "of policies held4\n",
        "8.7m\n",
        "(2021: 8.8m)\n",
        "Read more about our key performance indicators (KPIs) in the ‘Measuring our performance’ section on \n",
        "pages 14 and 15, and see page 202 for further details of our alternative performance measures (APMs).\n",
        "1. Operating profit before tax represents profit/(loss) before transfer to/(from) the fund for future appropriations \n",
        "excluding: short-term investment return variances and economic assumption changes; amortisation of goodwill and\n",
        "other intangibles arising from mergers and acquisitions; ProfitShare; ValueShare; tax; and one-off items of an unusual \n",
        "nature that are not related to the underlying trading of the Group. Profits or losses arising within the closed funds are \n",
        "held within the respective closed fund surplus; therefore operating profit represents the result of the Royal London \n",
        "Main Fund (RL Main Fund).\n",
        "2. Transfer (from)/to the fund for future appropriations represents the statutory UK GAAP measure ‘(Deduction from)/\n",
        "transfer to the fund for future appropriations’ in the technical account within the Consolidated statement of \n",
        "comprehensive income.\n",
        "3. The capital cover ratio is calculated as the Group’s Own Funds, being the regulatory capital under Solvency II, \n",
        "divided by the Solvency Capital Requirement (SCR). The ‘Investor View’ equals the RL Main Fund capital position\n",
        "(excluding ring-fenced funds, which are run on a standalone basis). The ‘Regulatory View’ solvency surplus and \n",
        "capital cover ratio, disclosed on page 50, exclude the closed funds’ surplus as a restriction to Own Funds. All capital \n",
        "figures are stated on a Group Partial Internal Model basis and the 2022 figure is estimated.\n",
        "4. Excludes general insurance policies where Royal London acts as an intermediary via a subsidiary company and policies \n",
        "held as part of a discretionary healthcare scheme via a subsidiary company.\n",
        "5. Employee engagement score is assessed via a colleague survey with six core index questions linked to colleague loyalty, \n",
        "satisfaction, and belief in Royal London.\n",
        "6. Customer Brand Love is our measurement of customer sentiment towards our brand and is assessed via an in-house \n",
        "customer relationship study.\n",
        "Customer \n",
        "Brand Love6\n",
        "68%\n",
        "(2021: 68%)\n",
        "Total charitable \n",
        "contributions in \n",
        "the UK and Ireland\n",
        "£1.8m\n",
        "(2021: £1.1m)\n",
        "Protection claims \n",
        "paid out \n",
        "£631m\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 84,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700441739383
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative= f\"\"\" Your task is to explain given information in a very simple way.\n",
        "### Context:\n",
        "{text}\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 85,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700441741713
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "In simple terms, here's a summary:\n\n- Operating profit before tax grew from £133m in 2021 to £210m this year.\n- There was a transfer of £162m from the fund for future appropriations, compared to a transfer of £79m to the fund in 2021.\n- Assets under management decreased from £164bn in 2021 to £147bn this year.\n- The capital cover ratio, which measures the company's funds against its capital requirement, slightly decreased from 216% in 2021 to 213% this year.\n- Membership of the company grew from 1.8m in 2021 to 2.0m this year.\n- Employee engagement, which measures how much staff are dedicated, satisfied and believe in the company, increased by 1% from 79% in 2021 to 80% this year.\n- The number of policies held decreased slightly from 8.8m in 2021 to 8.7m this year. \n- The Customer Brand Love, which is a measure of how much customers like the company's brand, remained the same at 68%.\n- The company's charitable contributions in the UK and Ireland grew from £1.1m in 2021 to £1.8m this year.\n- The company paid out £631m in protection claims this year. The previous year's figure isn't provided. \n\nFor additional information about the company's performance or alternative performance measures, you can refer to pages 14, 15 and 202 in the report.\n"
        }
      ],
      "execution_count": 86,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700441811216
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Issue 1:** It is long explaination."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative1= f\"\"\" Your task is to explain given information in a very simple way.\n",
        "Use at most 20 words.\n",
        "\n",
        "### Context:\n",
        "{text}\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 89,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700441917207
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative1}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The profits, assets, membership, and policies fell, while the transfer to the future fund, employee engagement, and charitable contributions increased.\n"
        }
      ],
      "execution_count": 90,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700441919017
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Issue 2:** Change the output format"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative2= f\"\"\" Your task is to explain given information in a very simple way.\n",
        "Use at most 20 words.\n",
        "\n",
        "If there is a numerical value, write those in a table format and named it as \"Annual Report and Accounts 2022\".\n",
        "### Context:\n",
        "{text}\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 93,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700442013528
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative2}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\"Annual Report and Accounts 2022\"\n\n| Key Indicator                               | 2022  | 2021 |\n|---------------------------------------------|-------|------|\n| Operating Profit Before Tax (£m)            | 210   | 133  |\n| Transfer to the Fund for Future (£m)        | (162) | 79   |\n| Assets Under Management (£bn)               | 147   | 164  |\n| Investor View Capital Cover Ratio (%)       | 213   | 216  |\n| Total Number of Members (millions)          | 2.0   | 1.8  |\n| Employee Engagement Score (%)               | 80    | 79   |\n| Total Number of Policies Held (millions)    | 8.7   | 8.8  |\n| Customer Brand Love (%)                     | 68    | 68   |\n| Total Charitable Contributions (£m)         | 1.8   | 1.1  |\n| Protection Claims Paid Out (£m)             | 631   | n/a  |\n"
        }
      ],
      "execution_count": 94,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700442023058
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative3= f\"\"\" Your task is to explain given information in a very simple way.\n",
        "Use at most 20 words.\n",
        "\n",
        "If there is a numerical value, write those in a table format and named it as \"Annual Report and Accounts 2022\".\n",
        "\n",
        "Format everything as HTML that can be used in a website. \n",
        "\n",
        "### Context:\n",
        "{text}\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 99,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700442133258
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative3}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "```html\n<table>\n  <caption>Annual Report and Accounts 2022</caption>\n  <tr>\n    <th>Item</th>\n    <th>2022</th>\n    <th>2021</th>\n  </tr>\n  <tr>\n    <td>Operating profit before tax (£m)</td>\n    <td>210</td>\n    <td>133</td>\n  </tr>\n  <tr>\n    <td>Transfer (from)/to fund for future appropriations (£m)</td>\n    <td>-162</td>\n    <td>79</td>\n  </tr>\n  <tr>\n    <td>Assets under management (£bn)</td>\n    <td>147</td>\n    <td>164</td>\n  </tr>\n  <tr>\n    <td>Investor View capital cover ratio</td>\n    <td>213%</td>\n    <td>216%</td>\n  </tr>\n  <tr>\n    <td>Total number of members (m)</td>\n    <td>2.0</td>\n    <td>1.8</td>\n  </tr>\n  <tr>\n    <td>Employee engagement score</td>\n    <td>80%</td>\n    <td>79%</td>\n  </tr>\n  <tr>\n    <td>Total number of policies held (m)</td>\n    <td>8.7</td>\n    <td>8.8</td>\n  </tr>\n  <tr>\n    <td>Customer Brand Love</td>\n    <td>68%</td>\n    <td>68%</td>\n  </tr>\n  <tr>\n    <td>Total charitable contributions in the UK and Ireland (£m)</td>\n    <td>1.8</td>\n    <td>1.1</td>\n  </tr>\n  <tr>\n    <td>Protection claims paid out (£m)</td>\n    <td>631</td>\n    <td>-</td>\n  </tr>\n</table>\n```\n"
        }
      ],
      "execution_count": 100,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700442145435
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(response.choices[0].message.content))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "```html\n<table>\n  <caption>Annual Report and Accounts 2022</caption>\n  <tr>\n    <th>Item</th>\n    <th>2022</th>\n    <th>2021</th>\n  </tr>\n  <tr>\n    <td>Operating profit before tax (£m)</td>\n    <td>210</td>\n    <td>133</td>\n  </tr>\n  <tr>\n    <td>Transfer (from)/to fund for future appropriations (£m)</td>\n    <td>-162</td>\n    <td>79</td>\n  </tr>\n  <tr>\n    <td>Assets under management (£bn)</td>\n    <td>147</td>\n    <td>164</td>\n  </tr>\n  <tr>\n    <td>Investor View capital cover ratio</td>\n    <td>213%</td>\n    <td>216%</td>\n  </tr>\n  <tr>\n    <td>Total number of members (m)</td>\n    <td>2.0</td>\n    <td>1.8</td>\n  </tr>\n  <tr>\n    <td>Employee engagement score</td>\n    <td>80%</td>\n    <td>79%</td>\n  </tr>\n  <tr>\n    <td>Total number of policies held (m)</td>\n    <td>8.7</td>\n    <td>8.8</td>\n  </tr>\n  <tr>\n    <td>Customer Brand Love</td>\n    <td>68%</td>\n    <td>68%</td>\n  </tr>\n  <tr>\n    <td>Total charitable contributions in the UK and Ireland (£m)</td>\n    <td>1.8</td>\n    <td>1.1</td>\n  </tr>\n  <tr>\n    <td>Protection claims paid out (£m)</td>\n    <td>631</td>\n    <td>-</td>\n  </tr>\n</table>\n```"
          },
          "metadata": {}
        }
      ],
      "execution_count": 101,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700442145659
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative4= f\"\"\" Your task is to explain given information in a very simple way.\n",
        "Use at most 20 words.\n",
        "\n",
        "If there is a numerical value, write those in a table format and named it as \"Annual Report and Accounts 2022\".\n",
        "\n",
        "Format everything as HTML that can be used in a website without using html keyword. \n",
        "\n",
        "### Context:\n",
        "{text}\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 103,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700442172063
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative4}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "```HTML\n<h3>Annual Report and Accounts 2022</h3>\n\n<table>\n<tr><th>Financial highlights</th><th>2022</th><th>2021</th></tr>\n<tr><td>Operating profit before tax</td><td>£210m</td><td>£133m</td></tr>\n<tr><td>Transfer (from)/to the fund for future appropriations</td><td>£(162)m</td><td>£79m</td></tr>\n<tr><td>Assets under management</td><td>£147bn</td><td>£164bn</td></tr>\n<tr><td>Investor View capital cover ratio</td><td>213%</td><td>216%</td></tr>\n</table>\n\n<table>\n<tr><th>Operational highlights</th><th>2022</th><th>2021</th></tr>\n<tr><td>Total number of members</td><td>2.0m</td><td>1.8m</td></tr>\n<tr><td>Employee engagement score</td><td>80%</td><td>79%</td></tr>\n<tr><td>Total number of policies held</td><td>8.7m</td><td>8.8m </td></tr>\n<tr><td>Total charitable contributions in the UK and Ireland</td><td>£1.8m</td><td>£1.1m</td></tr>\n<tr><td>Protection claims paid out</td><td>£631m</td><td>null</td></tr>\n</table>\n```\nNote: Null - No data for 2021 in the given context.\n"
        }
      ],
      "execution_count": 104,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700442205079
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(response.choices[0].message.content))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "```HTML\n<h3>Annual Report and Accounts 2022</h3>\n\n<table>\n<tr><th>Financial highlights</th><th>2022</th><th>2021</th></tr>\n<tr><td>Operating profit before tax</td><td>£210m</td><td>£133m</td></tr>\n<tr><td>Transfer (from)/to the fund for future appropriations</td><td>£(162)m</td><td>£79m</td></tr>\n<tr><td>Assets under management</td><td>£147bn</td><td>£164bn</td></tr>\n<tr><td>Investor View capital cover ratio</td><td>213%</td><td>216%</td></tr>\n</table>\n\n<table>\n<tr><th>Operational highlights</th><th>2022</th><th>2021</th></tr>\n<tr><td>Total number of members</td><td>2.0m</td><td>1.8m</td></tr>\n<tr><td>Employee engagement score</td><td>80%</td><td>79%</td></tr>\n<tr><td>Total number of policies held</td><td>8.7m</td><td>8.8m </td></tr>\n<tr><td>Total charitable contributions in the UK and Ireland</td><td>£1.8m</td><td>£1.1m</td></tr>\n<tr><td>Protection claims paid out</td><td>£631m</td><td>null</td></tr>\n</table>\n```\nNote: Null - No data for 2021 in the given context."
          },
          "metadata": {}
        }
      ],
      "execution_count": 105,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700442227254
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}