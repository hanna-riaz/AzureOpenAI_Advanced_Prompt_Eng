{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Key topics:\n",
        "\n",
        "**Tokens**: basic units of text/code for LLMs to process/generate language.\n",
        "\n",
        "**Tokenization**: splitting input/output texts into smaller units for LLMs.\n",
        "\n",
        "**Vocabulary size**: the number of tokens each model uses, which varies among different GPT models.\n",
        "\n",
        "**Tokenization cost**: affects the memory and computational resources that a model needs, which influences the cost and performance of running Azure OpenAI model."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken #The open source version of tiktoken can be installed from PyPI"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting tiktoken\n  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting regex>=2022.1.18 (from tiktoken)\n  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tiktoken) (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\nInstalling collected packages: regex, tiktoken\nSuccessfully installed regex-2023.12.25 tiktoken-0.6.0\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712286572541
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken \n",
        "\n",
        "cl100k_base = tiktoken.get_encoding(\"cl100k_base\") \n",
        "\n",
        "enc = tiktoken.Encoding( \n",
        "    name=\"gpt-35-turbo\",  \n",
        "    pat_str=cl100k_base._pat_str, \n",
        "    mergeable_ranks=cl100k_base._mergeable_ranks, \n",
        "    special_tokens={ \n",
        "        **cl100k_base._special_tokens, \n",
        "        \"<|im_start|>\": 100264, \n",
        "        \"<|im_end|>\": 100265\n",
        "    } \n",
        ") \n",
        "\n",
        "tokens = enc.encode( \n",
        "    \"The road to creating new medicines and vaccines has traditionally been long and winding!\"\n",
        ") \n",
        "\n",
        "print('Total number of tokens:', len(tokens))\n",
        "print('Tokens : ', [enc.decode([t]) for t in tokens])\n",
        "print(\"Tokens' numerical values:\", tokens)\n",
        "\n",
        "#https://platform.openai.com/tokenizer"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Total number of tokens: 15\nTokens :  ['The', ' road', ' to', ' creating', ' new', ' medicines', ' and', ' vaccines', ' has', ' traditionally', ' been', ' long', ' and', ' winding', '!']\nTokens' numerical values: [791, 5754, 311, 6968, 502, 39653, 323, 40300, 706, 36342, 1027, 1317, 323, 54826, 0]\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1712286579614
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "import os \n",
        "from azure.identity import ManagedIdentityCredential\n",
        "\n",
        "default_credential=ManagedIdentityCredential(client_id=\"f4980c43-9766-48d7-a925-c377a74605bb\")\n",
        "token=default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "Resource_endpoint=\"https://openaiykus.openai.azure.com/\"\n",
        "openai.api_type=\"azure_ad\"\n",
        "\n",
        "client = AzureOpenAI(\n",
        "  azure_endpoint = Resource_endpoint, \n",
        "  api_key=token.token,  \n",
        "  api_version=\"2023-05-15\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712286644625
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deployment_name='gpt-35-turbo-instruct' \n",
        "#This will correspond to the custom name you chose for your deployment when you deployed a model. \n",
        "    \n",
        "# Send a completion call to generate an answer\n",
        "print('Sending a test completion job')\n",
        "start_phrase = 'Help with the cost of living. '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    max_tokens=100)\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sending a test completion job\n\n\n1. Budgeting: The first step to tackle the cost of living is to create a budget. Write down all your monthly expenses, including rent, utilities, groceries, transportation, and other essential items. Then, compare it with your income. This will help you identify where you can make cuts and save money.\n\n2. Cut unnecessary expenses: Identify areas where you can cut unnecessary expenses such as dining out, cable TV, gym membership, subscription services, etc. Cancel or reduce these expenses to\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1712286767711
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usage"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "Completion(id='cmpl-9AUIRvUKNxSJGYQe9DnaaJeE1n7Gb', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text='\\n\\n1. Budgeting: The first step to tackle the cost of living is to create a budget. Write down all your monthly expenses, including rent, utilities, groceries, transportation, and other essential items. Then, compare it with your income. This will help you identify where you can make cuts and save money.\\n\\n2. Cut unnecessary expenses: Identify areas where you can cut unnecessary expenses such as dining out, cable TV, gym membership, subscription services, etc. Cancel or reduce these expenses to')], created=1712286767, model='gpt-35-turbo-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=100, prompt_tokens=8, total_tokens=108))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712286791751
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.usage"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "CompletionUsage(completion_tokens=100, prompt_tokens=8, total_tokens=108)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1712286827424
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Azure OpenAI uses a subword tokenization method called \"Byte-Pair Encoding (BPE)\" for its GPT-based models. ** BPE is a method that merges the most frequently occurring pairs of characters or bytes into a single token **, until a certain number of tokens or a vocabulary size is reached. BPE can help the model to handle rare or unseen words, and to create more compact and consistent representations of the texts. BPE can also allow the model to generate new words or tokens, by combining existing ones. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/tokens"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}