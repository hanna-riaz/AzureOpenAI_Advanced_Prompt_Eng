{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Key topics:\n",
        "\n",
        "**Tokens**: Tokens are a numerical representation of how the Azure OpenAI models process text. So they are representing words or just chunks of characters. For English text, 1 token is approximately 4 characters or 0.75 words. \n",
        "\n",
        "**Tokenization**: splitting input/output texts into smaller units for LLMs.\n",
        "\n",
        "**Vocabulary size**: the number of tokens each model uses, which varies among different GPT models."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install tiktoken #The open source version of tiktoken can be installed from PyPI"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712286572541
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken \n",
        "\n",
        "cl100k_base = tiktoken.get_encoding(\"cl100k_base\") \n",
        "\n",
        "enc = tiktoken.Encoding( \n",
        "    name=\"gpt-35-turbo\",  \n",
        "    pat_str=cl100k_base._pat_str, \n",
        "    mergeable_ranks=cl100k_base._mergeable_ranks, \n",
        "    special_tokens={ \n",
        "        **cl100k_base._special_tokens, \n",
        "        \"<|im_start|>\": 100264, \n",
        "        \"<|im_end|>\": 100265\n",
        "    } \n",
        ") \n",
        "\n",
        "tokens = enc.encode( \n",
        "    \"The Very Group announces long term strategic partnership with Carlyle and IMI and a robust Q2 performance.\"\n",
        ") \n",
        "\n",
        "print('Total number of tokens:', len(tokens))\n",
        "print('Tokens : ', [enc.decode([t]) for t in tokens])\n",
        "print(\"Tokens' numerical values:\", tokens)\n",
        "\n",
        "#https://platform.openai.com/tokenizer"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Total number of tokens: 21\nTokens :  ['The', ' Very', ' Group', ' announces', ' long', ' term', ' strategic', ' partnership', ' with', ' Carly', 'le', ' and', ' IM', 'I', ' and', ' a', ' robust', ' Q', '2', ' performance', '.']\nTokens' numerical values: [791, 15668, 5856, 48782, 1317, 4751, 19092, 15664, 449, 79191, 273, 323, 6654, 40, 323, 264, 22514, 1229, 17, 5178, 13]\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1712287040915
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "import os \n",
        "from azure.identity import ManagedIdentityCredential\n",
        "\n",
        "default_credential=ManagedIdentityCredential(client_id=\"f4980c43-9766-48d7-a925-c377a74605bb\")\n",
        "token=default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "Resource_endpoint=\"https://openaiykus.openai.azure.com/\"\n",
        "openai.api_type=\"azure_ad\"\n",
        "\n",
        "client = AzureOpenAI(\n",
        "  azure_endpoint = Resource_endpoint, \n",
        "  api_key=token.token,  \n",
        "  api_version=\"2023-05-15\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712286644625
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deployment_name='gpt-35-turbo-instruct' \n",
        "#This will correspond to the custom name you chose for your deployment when you deployed a model. \n",
        "    \n",
        "# Send a completion call to generate an answer\n",
        "print('Sending a test completion job')\n",
        "start_phrase = 'Help with the cost of living. '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    max_tokens=100)\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sending a test completion job\n\n\n1. Budgeting: The first step to tackle the cost of living is to create a budget. Write down all your monthly expenses, including rent, utilities, groceries, transportation, and other essential items. Then, compare it with your income. This will help you identify where you can make cuts and save money.\n\n2. Cut unnecessary expenses: Identify areas where you can cut unnecessary expenses such as dining out, cable TV, gym membership, subscription services, etc. Cancel or reduce these expenses to\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1712286767711
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usage"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "Completion(id='cmpl-9AUIRvUKNxSJGYQe9DnaaJeE1n7Gb', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text='\\n\\n1. Budgeting: The first step to tackle the cost of living is to create a budget. Write down all your monthly expenses, including rent, utilities, groceries, transportation, and other essential items. Then, compare it with your income. This will help you identify where you can make cuts and save money.\\n\\n2. Cut unnecessary expenses: Identify areas where you can cut unnecessary expenses such as dining out, cable TV, gym membership, subscription services, etc. Cancel or reduce these expenses to')], created=1712286767, model='gpt-35-turbo-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=100, prompt_tokens=8, total_tokens=108))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712286791751
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.usage"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "CompletionUsage(completion_tokens=100, prompt_tokens=8, total_tokens=108)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1712286827424
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Azure OpenAI uses a subword tokenization method called \"Byte-Pair Encoding (BPE)\" for its GPT-based models. ** BPE is a method that merges the most frequently occurring pairs of characters or bytes into a single token **, until a certain number of tokens or a vocabulary size is reached. BPE can help the model to handle rare or unseen words, and to create more compact and consistent representations of the texts. BPE can also allow the model to generate new words or tokens, by combining existing ones. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/tokens"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}