{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import openai\n",
        "# from openai import AzureOpenAI\n",
        "# import os \n",
        "# from azure.identity import ManagedIdentityCredential\n",
        "\n",
        "# default_credential=ManagedIdentityCredential(client_id=\"d30cba06-04c1-4065-a91d-8b7ce3b07b78\")\n",
        "# token=default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "# Resource_endpoint=\"https://openaiykus.openai.azure.com/\"\n",
        "\n",
        "# client = AzureOpenAI(\n",
        "#   azure_endpoint = Resource_endpoint, \n",
        "#   api_key=token.token,  \n",
        "#   api_version=\"2023-05-15\"\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700435703977
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "    \n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
        "    api_version=\"2024-02-15-preview\",#2024-02-01\n",
        "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712294016776
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Understand the AOAI Models' capabilities. Start with the latest model, prove your idea , then test with smaller models. \n",
        "Model size is critical for better performance."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Be specific, descriptive and as detailed as possible about the desired context, outcome, length, format, style, etc"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Length ** control (specify desired output length e.g.: number of words)\n",
        "\n",
        "** Tone ** control (e.g.: polite, passionate, professional, technical, funny, casual, serious etc.)\n",
        "\n",
        "** Style ** control (e.g.: in the style of Shakespeare, JK Rowling, Nelson Mandela etc.)\n",
        "\n",
        "** Audience ** control (e.g.: a 5-year-old can understand etc)\n",
        "\n",
        "** Context ** control (e.g.: news, novel, textbook, report, white paper, blog etc.)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = \" Write a 2 paragraph inspiring poem which can be understood by 5 years-old child focussing on brands of The Very Group\"\n",
        "# Write a 2 paragraph inspiring poem about The Very Group company\n",
        "# Write a 2 paragraph inspiring poem focussing on products of the Very Group company in a funny way\n",
        "# Write a 2 paragraph inspiring poem focussing on products of The Very Group company in the style of Shakespeare\n",
        "# Write a 2 paragraph inspiring poem which can be understood by 5 years-old child focussing on products of The Very Group company\n"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293652630
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of appending, writing messages in the SDK\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "In a world filled with cheerful toys and pretty dresses, \nThere’s a place called The Very Group, that truly impresses.\nIt has Lego blocks to build your fantasy tower,\nBarbie dolls, tea parties, you could play for an hour! \nTed Baker clothes to make you look bright,\nWith Converse shoes, you’ll run as light as the night.\n\nSo dream big, little one, let your imagination take flight,\nWith The Very Group, every day is a colorful sight.\nFrom Littlewoods Home for your playful room,\nTo Sony Playstation, taking you to another planet's moon.\nYour world is full of wonders, just waiting to be unfurled,\nWith The Very Group, you'll discover your beautiful world!\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293663259
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Put instructions at the begining of the prompt and use ### or \"\"\" to separate the instruction and context"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\\\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \\\n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \\\n",
        "increasingly safe, useful, and powerful. \\n\\n \\\n",
        "In pursuit of our mission to ensure advanced AI benefits all of humanity, OpenAI remains a \\\n",
        "capped-profit company and is governed by the OpenAI non-profit. This structure allows us to \\\n",
        "raise the capital we need to fulfill our mission without sacrificing our core beliefs about \\\n",
        "broadly sharing benefits and the need to prioritize safety. \\\n",
        "Microsoft shares this vision and our values, and our partnership is instrumental to our progress.\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293394405
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by hashtags as a bullet point list of the most important points.\n",
        "###{text}###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293395454
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.completions.create(\n",
        "    model='gpt-35-turbo-instruct' , \n",
        "    prompt=prompt, \n",
        "    temperature=0,\n",
        "    max_tokens=60\n",
        "    )\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n- OpenAI and Microsoft are extending their partnership\n- Microsoft is making a multi-year, multi-billion dollar investment in OpenAI\n- This follows previous investments in 2019 and 2021\n- The partnership will allow OpenAI to continue independent research and develop safe, useful, and powerful\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293398150
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Articulate the desired output format through examples"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\""
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293405962
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_message=f\"\"\"Extract the entities mentioned in the text below. \n",
        "First extract all company names, then extract all years, \n",
        "then extract specific topics which fit the content and finally extract general overarching themes\\n\\n \n",
        "Desired format: \n",
        "Company names: <comma_separated_list_of_company_names> \n",
        "Years: \n",
        "Specific topics:\n",
        "General themes: \n",
        "### Text:\n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \n",
        "increasingly safe, useful, and powerful. \\n\\n \n",
        "###\n",
        "\"\"\"\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293412571
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of appending, writing messages in the SDK\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Company names: OpenAI, Microsoft\nYears: 2019, 2021\nSpecific topics: Partnership extension, Multi-year investment, Independent research, AI development\nGeneral themes: Corporate partnership, Investment in technology, AI research and development\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293418791
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Start with zero-shot, then few-shot (example)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\""
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293427985
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_zero=f\"\"\"Extract most important keywords from the corresponding texts below.\\n\\n \n",
        "\n",
        "###Text: \n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \n",
        "increasingly safe, useful, and powerful. \\n\n",
        "Keywords:###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293428995
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_zero}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "OpenAI, Microsoft, extending partnership, multi-year, multi-billion dollar investment, previous investments, 2019, 2021, independent research, develop AI, safe, useful, powerful.\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293432283
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_few=f\"\"\"Extract most important keywords from the corresponding texts below.\\n\\n \n",
        "### Text 1: \n",
        "Stripe provides APIs that web developers can use to integrate \n",
        "payment processing into their websites and mobile applications. \\n\n",
        "Keywords 1: Stripe, payment processing, APIs, web developers, websites \n",
        "### \n",
        "\n",
        "###Text 2: \n",
        "OpenAI has trained cutting-edge language models that are very good at understanding \n",
        "and generating text. Our API provides access to these models and can be used to solve virtually \n",
        "any task that involves processing language. \\n\n",
        "Keywords 2: OpenAI, language models, text processing, API.\n",
        "### \n",
        "\n",
        "###Text 3: \n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \n",
        "increasingly safe, useful, and powerful. \\n\n",
        "Keywords 3:\"\"\""
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293462169
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of appending, writing messages in the SDK\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_few}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "OpenAI, Microsoft, partnership, multi-year, multi-billion dollar investment, independent research, AI, safe, useful, powerful.\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293463853
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Instead of just saying what not to do, say what to do instead"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message= f\"\"\"You are an agent trying to diagnose the problem and suggest a solution, whilst refraining from asking any questions related to PII. \n",
        "Instead of asking for PII, such as username or password, refer the user to the help article www.samplewebsite.com/help/faq \\n\\n\"\"\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = \"I can’t log in to my account.\"\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293478935
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4-32k\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "I'm sorry to hear that you're having trouble logging in. This can often be due to incorrect username or password. Please ensure there are no typographical errors that might prevent logging in. If this doesn't work, you might want to consider resetting your password. You can do this by visiting our Help guide at www.samplewebsite.com/help/faq where you can find step-by-step instructions to assist in resetting your password.\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293517841
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Divide complex tasks into sub-tasks"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\""
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293544021
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "The Very Group: As the way families shop has changed, so have we. From catalogues, to bricks, to clicks, to mobile. We have consistently transformed to meet their needs.\n",
        "Our ambition is to build the most trusted ecosystem for families. We want to offer the most flexible ways to pay for all the brands, products, and services they want and need within a seamless digital experience. To achieve our ambition, we are focused on three things: ease, choice and understanding.\n",
        "\"\"\"\n",
        "# example 1\n",
        "user_message = f\"\"\"\n",
        "Perform the actions below by separating your answers with line breaks. \n",
        "1 - Summarize the following text below with 1 sentence.\n",
        "2 - Translate the summary into Turkish.\n",
        "3 - List each company name in the Turkish summary.\n",
        "4 - Output a json object that contains the following:\n",
        "keys: turkish_summary, turkish_company_names.\n",
        "\n",
        "###\n",
        "Text:\n",
        "{text} \n",
        "###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293719000
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4-32k\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1 - The Very Group continuously adapts to changing consumer patterns, aiming to build the most trusted ecosystem by offering flexible payment methods and diverse brands through a seamless digital experience.\n2 - The Very Group, tüketici alışkanlıklarındaki değişikliklere sürekli adapte olurken, en güvenilir ekosistemi kurmayı hedefliyor ve kusursuz bir dijital deneyim içinde çeşitli markalar için esnek ödeme yöntemleri sunmayı hedefliyor.\n3 - The Very Group\n4 - {\n        \"turkish_summary\": \"The Very Group, tüketici alışkanlıklarındaki değişikliklere sürekli adapte olurken, en güvenilir ekosistemi kurmayı hedefliyor ve kusursuz bir dijital deneyim içinde çeşitli markalar için esnek ödeme yöntemleri sunmayı hedefliyor.\",\n        \"turkish_company_names\": \"The Very Group\"\n      }\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293736886
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Chain of Thought"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The language model is prompted to generate a few intermediate reasoning steps to arrive at the final answer. \n",
        "\n",
        "Uses \"greedy decoding\" which means selecting the most likely token (word or character) at each step of the sequence generation process. At each time step, the model predicts the next token based on the previously generated tokens, and the token with the highest predicted probability is chosen as the output for that step. This process is repeated until the desired sequence length is reached or until a special end-of-sequence token is generated.\n",
        "\n",
        "**Temp=0** is used because it uses greedy decoding. It first creates the greedy coding and then the answer."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This prompt gets wrong answer\n",
        "\n",
        "PROMPT_ZERO_SHOT = \"\"\"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A: The answer (arabic numerals) is\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293817643
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.completions.create(\n",
        "    model=\"gpt-35-turbo-instruct\", \n",
        "    prompt=PROMPT_ZERO_SHOT, \n",
        "    temperature=0,\n",
        "    max_tokens=60\n",
        "    )\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n6\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712293818292
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_ZERO_SHOT_CoT = \"\"\"Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A: Let’s think step by step.\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712294133471
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.completions.create(\n",
        "    model=\"gpt-35-turbo-instruct\", \n",
        "    prompt=PROMPT_ZERO_SHOT_CoT, \n",
        "    temperature=0,\n",
        "    max_tokens=100\n",
        "    )\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1. Roger has 5 tennis balls.\n2. He buys 2 cans of tennis balls, each with 3 balls. So, he has 5 + 2 x 3 = 11 tennis balls.\n3. He gives 4 of them to his friend. So, he now has 11 - 4 = 7 tennis balls.\nTherefore, Roger now has 7 tennis balls.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712294135779
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_FEW_SHOT_CoT = \"\"\"\n",
        "Q: Elif went to market with £10 and consumed £2. How much does she have now?\n",
        "A: Elif had £10 at the beginning. When she consumed £2, 10-2=8 , £8 remains.\n",
        "Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A:\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712294142276
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.completions.create(\n",
        "    model=\"gpt-35-turbo-instruct\", \n",
        "    prompt=PROMPT_FEW_SHOT_CoT, \n",
        "    temperature=0,\n",
        "    max_tokens=100\n",
        "    )\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Roger had 5 tennis balls at the beginning. He bought 2 cans of tennis balls, each with 3 balls, so he now has 5+2x3=11 tennis balls. After giving 4 to his friend, he has 11-4=7 tennis balls remaining.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712294146126
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Auto-COT ** uses zero-shot-cot results just like few-shot learning for reasoning. Instead of using few-shot-cot, auto-cot can be useful and easy because you don't need to create manual examples (labels/reasonings)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_auto_cot = \"\"\"\n",
        "Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A: Lets think step by step.Roger had 5 tennis balls at the beginning. He bought 2 cans of tennis balls, each with 3 balls, so he now has 5+2x3=11 tennis balls. After giving 4 to his friend, he has 11-4=7 tennis balls remaining.\n",
        "Q: Elif went to market with £10 and consumed £2. How much does she have now?\n",
        "A:\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712294297910
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.completions.create(\n",
        "    model=\"gpt-35-turbo-instruct\", \n",
        "    prompt=prompt_auto_cot, \n",
        "    temperature=0,\n",
        "    max_tokens=100\n",
        "    )\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nElif now has £8 left.\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712294299769
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Self Consistency\n",
        "\n",
        "Self-consistency aims \"to replace the naive greedy decoding used in chain-of-thought prompting\". The idea is to sample multiple, diverse reasoning paths through few-shot CoT, and use the generations to ** select the most consistent answer.**\n",
        "\n",
        "In the chat scenarios, **Asking the model to self-verify** its own responses. Like a student double-checking their answers, the AI model cross-references its responses to maintain consistency. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= f\"\"\"When I was 6, my sister was half my age. Now\n",
        "I am 70 how old is my sister?\"\"\""
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712294452980
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.completions.create(\n",
        "    model=\"gpt-35-turbo-yk\", \n",
        "    prompt=prompt, \n",
        "    temperature=0,\n",
        "    max_tokens=10\n",
        "    )\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\nQ: 35\nA: When I\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712294473766
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2= f\"\"\"When I was 6, my sister was half my age. Now\n",
        "I am 70 how old is my sister? Let's think step by step\"\"\""
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712294441489
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.completions.create(\n",
        "    model=\"gpt-35-turbo-yk\", \n",
        "    prompt=prompt2, \n",
        "    temperature=0,\n",
        "    max_tokens=100\n",
        "    )\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".\n\nWhen I was 6, my sister was half my age. So, my sister was 6/2=<<6/2=3>>3 years old.\nNow I am 70. So, my sister is 70-6+3=<<70-6+3=67>>67 years old. Answer: \\boxed{67}.<|im_end|>\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712294492997
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt3=f\"\"\"\n",
        "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,\n",
        "there will be 21 trees. How many trees did the grove workers plant today?\n",
        "A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.\n",
        "So, they must have planted 21 - 15 = 6 trees. The answer is 6.\n",
        "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
        "A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\n",
        "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
        "A: Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74\n",
        "chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\n",
        "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops\n",
        "did Jason give to Denny?\n",
        "A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\n",
        "lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\n",
        "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does\n",
        "he have now?\n",
        "A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so\n",
        "in total he has 7 + 2 = 9 toys. The answer is 9.\n",
        "Q: There were nine computers in the server room. Five more computers were installed each day, from\n",
        "monday to thursday. How many computers are now in the server room?\n",
        "A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =\n",
        "20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.\n",
        "The answer is 29.\n",
        "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many\n",
        "golf balls did he have at the end of wednesday?\n",
        "A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On\n",
        "Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\n",
        "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
        "A: She bought 5 bagels for $3 each. This means she spent 5\n",
        "Q: When I was 6 my sister was half my age. Now I’m 70 how old is my sister?\n",
        "A:\"\"\""
      ],
      "outputs": [],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712295154195
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(num_times, start_phrase, temperature):\n",
        "    for i in range(num_times):\n",
        "        \n",
        "        deployment_name='gpt-35-turbo-instruct' \n",
        "\n",
        "        # Send a completion call to generate an answer\n",
        "        response = client.completions.create(\n",
        "            model=deployment_name, \n",
        "            prompt=start_phrase, \n",
        "            temperature=temperature,\n",
        "            max_tokens=200)\n",
        "        print(response.choices[0].text)\n",
        "        print(\"*****************************\")"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712295156929
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, prompt3, temperature = 1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " When you were 6, your sister was half your age, so she was 6 / 2 = 3 years old. Now you are 70 and\nyour sister is 70 - (6 - 3) = 67 years old. The answer is 67.\n*****************************\n When you were 6, your sister was half your age which would be 3 years old. From this, we can infer that your sister is 3 * 12 = 36 years younger than you. Therefore, your sister must be 70 - 36 = 34 years old now. The answer is 34.\n*****************************\n Your sister is still half your age. When you were 6, she was 3 (half of 6). You are 64 years older than\nshe is. So now your sister is 70 - 64 = 6 years old.\n*****************************\n Since you were 6, your sister was half your age, so she must have been 6 / 2 = 3 years old. The\ndifference in age always remains the same, so now when you are 70, your sister must be 70 - 3 = 67\nyears old. The answer is 67.\n*****************************\n If you are 70 and your sister was half your age when you were 6, that means she was 70 / 2 = 35 years\nold at that time. Since that was the case when you were 6, she is now 35 + (6 - 6) = 35 years old. The answer is 35.\n\n*****************************\n If you are 70 years old now, that means you are 70 - 6 = 64 years older than when you were 6. This also means your sister must have been half your age, so she must have been 6/2 = 3 years old when you were 6. Adding 64 years to her age, she must be 3 + 64 = 67 years old now. The answer is 67.\n*****************************\n If you were 6, your sister was half your age, which was 3. Now you are 70, so your sister is 70 - (6 - 3) =\n70 - 3 = 67 years old. The answer is 67.\n*****************************\n When you were 6, your sister was half your age, so she was 3 years younger than you. Since you are now 70, your sister is still 3 years younger than you. This means she is 70 - 3 = 67 years old. The answer is 67.\n*****************************\n When you were 6, your sister was half your age. That means she was 6 / 2 = 3 years old. Now you are 70,\nso your sister must be 70 - (70-6) = 6 + 70 - 70 = 6 + 0 = your sister is 6 years old. The answer is 6.\n*****************************\n When you were 6, your sister was half your age. That means when you were 12, your sister was 6. Now\nyou are 70 and she is 6 years younger, that means she is 70 - 6 = 64 years old. The answer is 64.\n\n \n*****************************\n"
        }
      ],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712295167808
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Iterative approach\n",
        "\n",
        "Prompt engineering is an iterative process. If you're unsatisfied with the AI's response, refine your prompt and try again. Analyze the results you receive and consider adjusting your prompt's context, clarity, or structure. This process of trial and error will help you better understand how the AI model interprets your prompts and allow you to fine-tune your approach.\n",
        "\n",
        "·        Try different prompts to find what works best\n",
        "\n",
        "·        When attempting few-shot learning, try also to include direct instructions\n",
        "\n",
        "·        Rephrase a direct instruction set to be more or less concise, e.g.: taking a previous example and giving the next instruction without having to repeat the input\n",
        "\n",
        "·        Try different personas keywords to see how it affects the response style\n",
        "\n",
        "·        Use fewer or more examples in the few-shot learning\n",
        "\n",
        "·        Co-create with AI: An example of a very useful prompt to get a good output from the LLM :"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=f\"\"\"\n",
        "Location Action and impact\n",
        "Global We updated and expanded our audit policy to require annual audits from all suppliers including both tier 1 and priority tier 2 factories. We defined remediation for different gradings from \n",
        "low to high risk and developed an escalation process that is aligned across all regions.\n",
        "China More than 800 workers took part in our women’s empowerment programme, delivered in partnership with INNO. Modules are designed to boost skills and have a positive impact both in the \n",
        "workplace and personally.\n",
        "China 100 participants from Tier 1 factories and 25 participants from Tier 2 factories took part in online training about ethical recruitment. Topics included raising awareness of and preventing \n",
        "modern slavery and child labour.\n",
        "India Continued our UN-award winning work in India’s textile industry. To date, we have opened six migrant resource centres and will open a seventh centre during FY24. In FY23, 13 female \n",
        "migrant workers were supported with retrieving unpaid wages and returning home, in line with their wishes.\n",
        "Malaysia\n",
        "4 factories began reimbursing fees paid by workers during the recruitment process. Such fees are not permitted, as they are linked to modern slavery. \n",
        "5 factories began progressing plans to implement responsible recruitment. Sometimes referred to as ethical or fair recruitment, this means treating workers lawfully and in a fair and \n",
        "transparent manner that respects and protects their rights throughout recruitment, employment, and post-termination. \n",
        "Poland and Romania The Just Good Work app we developed and launched in FY22 was used by 1,532 Ukrainian refugees in Poland and Romania in FY23. The app provides labour rights and human rights \n",
        "guidance to prevent refugee exploitation.\n",
        "Sri Lanka In response to the economic crisis in Sri Lanka, risk assessments were carried out in two factories to help us better understand conditions for workers in our supply chain. No negative \n",
        "responses were received from the 776 workers we engaged with.\n",
        "Turkey Social dialogue training was conducted in three factories, with 1,018 participants. Delivered in partnership with Varner, Tesco, Primark, M&S, and JustMaxIt, the training was designed to \n",
        "strengthen communication between workers and managers.\n",
        "Leicester, UK Provided continued support for FAB-L’s community outreach programme for garment workers, of which we were founding members. In FY23, our support helped FAB-L to introduce English \n",
        "language and IT classes and hire two new employees to continue and expand their essential work.\n",
        "UK Visited all of our UK furniture suppliers to carry out assessment of non-conformances from third party audits, and observations of modern slavery indicators. No cases of modern slavery were \n",
        "identified. We also worked with suppliers on follow up actions and supported them with compliance to our audit programme.\n",
        "UK 50% of our UK furniture suppliers attended a modern slavery training event we held in partnership with partnership with Slave-Free Alliance.\n",
        "UK We began to consider our broader ESG commitments through the lens of preventing modern slavery by carrying out due diligence on our UK-based third-party take-back scheme partners. \n",
        "This included site visits to Traid, Reskinned and Vision Ireland\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712295362934
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative= f\"\"\" Your task is to explain given information in a very simple way.\n",
        "### Context:\n",
        "{text}\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712295364230
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "In simpler terms:\n\nAround the world, we have strengthened our policy to check our suppliers more regularly and ensure they are operating responsibly. We have special steps in place if we find any risky behavior.\n\nIn China, we have programs aimed at empowering women, with over 800 participants. We also provided online training about responsible recruitment to 125 people from our supplier factories.\n\nIn India, we support textile workers, especially migrant women. We have created places for them to go for resources, and helped some recover unpaid wages. \n\nIn Malaysia, four of our factories have started reimbursing recruitment fees to workers, as these fees are tied to unfair practices. Five more factories are planning to implement fairer recruiting methods.\n\nIn Poland and Romania, we launched an app offering advice on labor and human rights to Ukrainian refugees. Over 1500 have used it so far.\n\nIn Sri Lanka, we assessed two of our factories to better understand the challenges of workers, and we didn't receive any negative feedback from the workers. \n\nIn Turkey, we held training sessions with over a thousand people to improve communication between workers and managers.\n\nIn Leicester, UK, we supported a community program that helps garment workers by offering services like English language and IT classes.\n\nAcross the UK, we visited our furniture suppliers to check on their working conditions and found no signs of forced labor. We also held a training event to help our suppliers understand and prevent forced labor.\n\nIn the UK, we are examining our practices even more closely to make sure we're not connected to forced labor. This includes visiting and checking the organizations we work with.\n\n"
        }
      ],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712295386837
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Issue 1:** I want to keep numerical values in more readable output format."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative1= f\"\"\" Your task is to organize given information in table format by keeping numarical values. \n",
        "\n",
        "### Context:\n",
        "{text}\n",
        "###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 50,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712295872133
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative1}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "| Location | Numerical Information/Action |\n| --- | --- |\n| Global | Updated and expanded audit policy to require annual audits from all suppliers|\n| China | 800 workers took part in women’s empowerment programme |\n| China | 100 participants from Tier 1 factories and 25 participants from Tier 2 factories took part in online training about ethical recruitment |\n| India | Opened six migrant resource centres, will open a seventh centre during FY24. Supported 13 female migrants in FY23 |\n| Malaysia | 4 factories began reimbursing fees paid by workers, 5 factories began progressing plans for responsible recruitment |\n| Poland and Romania | Just Good Work app used by 1,532 Ukrainian refugees |\n| Sri Lanka | Risk assessments done in two factories, engaged with 776 workers |\n| Turkey | Social dialogue training conducted in three factories with 1,018 participants |\n| Leicester, UK | Supported FAB-L community outreach programme |\n| UK | Visited all UK furniture suppliers for assessment and followed up on actions |\n| UK | 50% of UK furniture suppliers attended a modern slavery training event |\n| UK | Carried out due diligence on UK-based third-party take-back scheme partners |\n\n"
        }
      ],
      "execution_count": 51,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712295898914
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Issue 2:** It is long so I need a brief summary."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative2= f\"\"\" \n",
        "Your task is to organize given information briefly in table format by keeping numarical values.\n",
        "\n",
        "Then, provide simple explanation by using at most 20 words.\n",
        "\n",
        "### Context:\n",
        "{text}\n",
        "###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712296057268
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative2}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "| Location       | Action                                                                                                             | Impact                                           |\n|----------------|--------------------------------------------------------------------------------------------------------------------|-------------------------------------------------|\n| Global         | Updated audit policy                                                                                                | Annual audits from all suppliers required       |\n| China          | Women’s empowerment programme                                                                                       | Over 800 workers participated                   |\n| China          | Online ethical recruitment training                                                                                 | 125 participants from Tier1 and Tier2 factories |\n| India          | Continuing UN-award winning work in textile industry                                                                | Supported 13 female migrant workers             |\n| Malaysia       | Began reimbursing fees and plans for responsible recruitment                                                        | Impacted 9 factories                            |\n| Poland, Romania| Launched the Just Good Work app                                                                                     | Used by 1,532 Ukrainian refugees                |\n| Sri Lanka      | Carried out risk assessments in factories                                                                           | Engaged with 776 workers                        |\n| Turkey         | Conducted social dialogue training                                                                                  | Involved 1,018 participants                     |\n| Leicester, UK  | Supported FAB-L’s community outreach programme                                                                      | Expanded programme with new hires               |\n| UK             | Assessed non-conformances and observed modern slavery indicators At suppliers                                       | No cases of modern slavery identified           |\n| UK             | Organized modern slavery training event                                                                             | 50% of UK furniture suppliers attended          |\n| UK             | Carried out due diligence on third-party take-back scheme partners                                                  | Included site visits                            |\n\nSuppliers globally underwent policy update and region specific programs were executed for workers' benefits and rights.\n"
        }
      ],
      "execution_count": 53,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712296086862
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative3= f\"\"\" Your task is to organize given information briefly in table format by keeping numarical values.\n",
        "\n",
        "Then, provide simple explanation of the given context by using at most 20 words.\n",
        "\n",
        "Format everything as HTML that can be used in a website. \n",
        "\n",
        "### Context:\n",
        "{text}\n",
        "###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 59,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712296402392
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative3}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "```html\n<table>\n  <tr>\n    <th>Location</th>\n    <th>Action and Impact</th>\n    <th>Numerical Values</th>\n  </tr>\n  <tr>\n    <td>Global</td>\n    <td>Updated and expanded audit policy including the development of an escalation process; defined remediation for gradings.</td>\n    <td></td>\n  </tr>\n  <tr>\n    <td>China</td>\n    <td>Women’s empowerment program impacted over 800 workers.</td>\n    <td>800</td>\n  </tr>\n  <tr>\n    <td>China</td>\n    <td>Conducted online training about ethical recruitment for Tier 1 and Tier 2 factories.</td>\n    <td>100, 25</td>\n  </tr>\n  <tr>\n    <td>India</td>\n    <td>Opened migrant resource centres; supported female migrant workers with unpaid wages.</td>\n    <td>6, 13</td>\n  </tr>\n  <tr>\n    <td>Malaysia</td>\n    <td>Began reimbursing recruitment fees and implementing responsible recruitment across factories.</td>\n    <td>4, 5</td>\n  </tr>\n  <tr>\n    <td>Poland and Romania</td>\n    <td>Provided labor and human rights guidance via an app to Ukrainian refugees.</td>\n    <td>1532</td>\n  </tr>\n  <tr>\n    <td>Sri Lanka</td>\n    <td>Carried out risk assessments in factories; engaged with workers on economic crisis.</td>\n    <td>776</td>\n  </tr>\n  <tr>\n    <td>Turkey</td>\n    <td>Conducted social dialogue training in factories.</td>\n    <td>1018</td>\n  </tr>\n  <tr>\n    <td>UK (Leicester)</td>\n    <td>Supported FAB-L’s community outreach programme for garment workers.</td>\n    <td></td>\n  </tr>\n  <tr>\n    <td>UK</td>\n    <td>Carried out assessments of suppliers and modern slavery indicators; no cases found.</td>\n    <td></td>\n  </tr>\n  <tr>\n    <td>UK</td>\n    <td>50% of furniture suppliers attended a modern slavery training event.</td>\n    <td>50%</td>\n  </tr>\n  <tr>\n    <td>UK</td>\n    <td>Carried out due diligence on third-party take-back scheme partners.</td>\n    <td></td>\n  </tr>\n</table>\n```\n\nA brief overview: Various actions were undertaken globally to improve working conditions, prevent modern slavery and empower workers.\n"
        }
      ],
      "execution_count": 60,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712296450811
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(response.choices[0].message.content))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "```html\n<table>\n  <tr>\n    <th>Location</th>\n    <th>Action and Impact</th>\n    <th>Numerical Values</th>\n  </tr>\n  <tr>\n    <td>Global</td>\n    <td>Updated and expanded audit policy including the development of an escalation process; defined remediation for gradings.</td>\n    <td></td>\n  </tr>\n  <tr>\n    <td>China</td>\n    <td>Women’s empowerment program impacted over 800 workers.</td>\n    <td>800</td>\n  </tr>\n  <tr>\n    <td>China</td>\n    <td>Conducted online training about ethical recruitment for Tier 1 and Tier 2 factories.</td>\n    <td>100, 25</td>\n  </tr>\n  <tr>\n    <td>India</td>\n    <td>Opened migrant resource centres; supported female migrant workers with unpaid wages.</td>\n    <td>6, 13</td>\n  </tr>\n  <tr>\n    <td>Malaysia</td>\n    <td>Began reimbursing recruitment fees and implementing responsible recruitment across factories.</td>\n    <td>4, 5</td>\n  </tr>\n  <tr>\n    <td>Poland and Romania</td>\n    <td>Provided labor and human rights guidance via an app to Ukrainian refugees.</td>\n    <td>1532</td>\n  </tr>\n  <tr>\n    <td>Sri Lanka</td>\n    <td>Carried out risk assessments in factories; engaged with workers on economic crisis.</td>\n    <td>776</td>\n  </tr>\n  <tr>\n    <td>Turkey</td>\n    <td>Conducted social dialogue training in factories.</td>\n    <td>1018</td>\n  </tr>\n  <tr>\n    <td>UK (Leicester)</td>\n    <td>Supported FAB-L’s community outreach programme for garment workers.</td>\n    <td></td>\n  </tr>\n  <tr>\n    <td>UK</td>\n    <td>Carried out assessments of suppliers and modern slavery indicators; no cases found.</td>\n    <td></td>\n  </tr>\n  <tr>\n    <td>UK</td>\n    <td>50% of furniture suppliers attended a modern slavery training event.</td>\n    <td>50%</td>\n  </tr>\n  <tr>\n    <td>UK</td>\n    <td>Carried out due diligence on third-party take-back scheme partners.</td>\n    <td></td>\n  </tr>\n</table>\n```\n\nA brief overview: Various actions were undertaken globally to improve working conditions, prevent modern slavery and empower workers."
          },
          "metadata": {}
        }
      ],
      "execution_count": 61,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712296455902
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}