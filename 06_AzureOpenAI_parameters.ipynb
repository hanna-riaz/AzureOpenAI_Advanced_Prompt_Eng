{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import openai\n",
        "# from openai import AzureOpenAI\n",
        "# import os \n",
        "# from azure.identity import ManagedIdentityCredential\n",
        "\n",
        "# default_credential=ManagedIdentityCredential(client_id=\"f4980c43-9766-48d7-a925-c377a74605bb\")\n",
        "# token=default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "# Resource_endpoint=\"https://openaiykus.openai.azure.com/\"\n",
        "\n",
        "# client = AzureOpenAI(\n",
        "#   azure_endpoint = Resource_endpoint, \n",
        "#   api_key=token.token,  \n",
        "#   api_version=\"2023-05-15\"\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712287450305
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "    \n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
        "    api_version=\"2024-02-01\", #latest GA API version: https://learn.microsoft.com/en-us/azure/ai-services/openai/api-version-deprecation\n",
        "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720052757779
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getenv(\"AZURE_OPENAI_ENDPOINT\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://azuremlopenai.openai.azure.com/\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720052758100
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Temperature\n",
        "\n",
        "Defaults to 1, Optional\n",
        "\n",
        "What sampling temperature to use, between 0 and 2. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 for ones with a well-defined answer.\n",
        "\n",
        "We generally recommend altering this or top_p but not both."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(num_times, start_phrase, temperature):\n",
        "    for i in range(num_times):\n",
        "        \n",
        "        deployment_name='gpt-35-turbo' \n",
        "\n",
        "        # Send a completion call to generate an answer\n",
        "        response = client.completions.create(\n",
        "            model=deployment_name, \n",
        "            prompt=start_phrase, \n",
        "            temperature=temperature,\n",
        "            max_tokens=10)\n",
        "        print(response.choices[0].text)\n",
        "        print(\"*****************************\")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1720052764821
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'Azure machine learning is ', temperature = 0)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720052768744
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'Azure machine learning is ', temperature =0.5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "100% cloud-based. You can start using it\n*****************************\n a cloud-based machine learning platform that provides tools to\n*****************************\n a cloud-based platform for building, deploying, and\n*****************************\n a cloud-based service that enables you to build,\n*****************************\n the cloud-based machine learning service provided by Microsoft.\n*****************************\n a cloud-based platform for AI and machine learning.\n*****************************\n a cloud-based platform for building, deploying, and\n*****************************\n100% cloud based service that is used to develop\n*****************************\n a cloud-based machine learning solution that provides a platform\n*****************************\n a cloud-based service that provides tools for building,\n*****************************\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720052774749
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Top_p\n",
        "\n",
        "Defaults to 1, Optional\n",
        "\n",
        "top_p parameter which stands for “top probability” and an alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. \n",
        "\n",
        "The top_p refers to the probability mass that should be used when considering the next word in the generated text. Essentially it ** sets a threshold for the probability of the next word being chosen and only considers the most likely words that exceed that threshold.**\n",
        "\n",
        "We generally recommend altering this or temperature but not both."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(num_times, start_phrase, top_p):\n",
        "    for i in range(num_times):\n",
        "        \n",
        "        deployment_name='gpt-35-turbo' \n",
        "\n",
        "        # Send a completion call to generate an answer\n",
        "        response = client.completions.create(\n",
        "            model=deployment_name, \n",
        "            prompt=start_phrase, \n",
        "            top_p=top_p,\n",
        "            max_tokens=30)\n",
        "        print(response.choices[0].text)\n",
        "        print(\"*****************************\")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1720052775818
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'Azure machine learning is ', top_p = 0.1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a drag-and-drop interface to build models and a\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a drag-and-drop interface to build models and pipelines\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a drag-and-drop interface to build models and pipelines\n*****************************\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1720052779748
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'Azure machine learning is ', top_p = 1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "90% automated or 95% automated, but still there's going to be a team that you have to consult with. And we want to make\n*****************************\n focused on MLaaS to fulfil the needs of entrepreneurs and data scientists who want to complete and implement machine learning models without managing whole infrastructure.\n\nVisual Studio tools\n*****************************\n a cloud based service provided by Microsoft Azure. It allows for automated machine learning, building models using prebuilt services and model sharing.\n+\n+## Benefits\n*****************************\n Microsoft’s cloud based one click machine learning platform. With its pre-built algorithms, drag and drop interface, and custom code feature, it enables the user\n*****************************\n100% managed cloud environment that is simple to deploy & scalable\n\nMachine learning with Microsoft allows the use of favorite open-source frameworks including Tensorflow, Py\n*****************************\n100 times cheaper than AWS when it comes to training machine learning models. It also offers more tools and advanced analytics than AWS.\n\nConclusion\n\nOverall, Azure\n*****************************\n80% similar to other platforms.\" “The AZ-103 exam is a toughie and requires a good grip on the Azure basics, like deploying,\n*****************************\n enterprise ready cloud-based platform that extends numerous capabilities for data scientists, machine learning engineers and developers to scale and automate the end-to-end machine learning lifecycle process\n*****************************\n service provided by Microsoft for creating, testing, deploying and managing machine learning models. With this service, developers can quickly access pre-defined algorithms, tools and\n*****************************\n a cloud-based controled item on which developers can train, evaluate, deploy predictive models fastlyly. By it, developers can deploy their own models\n*****************************\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1720052782755
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Max_Tokens \n",
        "\n",
        "Default value=16, Optional\n",
        "\n",
        "The maximum number of tokens to generate in the completion. **The token count of your prompt plus max_tokens can't exceed the model's context length. **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deployment_name='gpt-35-turbo' \n",
        "#This will correspond to the custom name you chose for your deployment when you deployed a model. \n",
        "    \n",
        "# Send a completion call to generate an answer\n",
        "start_phrase = 'Azure machine learning is '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    temperature=1,\n",
        "    max_tokens=15)\n",
        "\n",
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9h4allUHv5QORBs5ZRNuuBjGYCoLq\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"text\": \"100% integrated with visual studio. It's preferred to use the cloud,\",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1720052783,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 15,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 20\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720052782916
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Send a completion call to generate an answer\n",
        "start_phrase = 'The Bupa company is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    temperature=1,\n",
        "    max_tokens=90)\n",
        "\n",
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9h4asH3fZSIJtJldc1RW6yYKgkjoi\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"text\": \"20-minute walk from Angel tube station. 240 facilities were rented to ensure a peaceful picket, where many staff chose to join the protest. The company initially offered a payrise of just over 1%, which workers rejected. This led to a strike being planned in August of this year, but it was called off when Bupa offered further talks and an improved offer. However, the 2% annual increase offered was seen by workers as too\",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1720052790,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 90,\n    \"prompt_tokens\": 7,\n    \"total_tokens\": 97\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720052790746
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# n\n",
        "\n",
        "Defaults to 1, optional\n",
        "\n",
        "How many completions to generate for each prompt. To generate multiple completions, we specify the n request parameter, which simply stands for ** “number of completions” **\n",
        "\n",
        "Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "deployment_name='gpt-35-turbo' \n",
        "#This will correspond to the custom name you chose for your deployment when you deployed a model. \n",
        "    \n",
        "# Send a completion call to generate an answer\n",
        "start_phrase = 'Azure machine learning is '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    temperature=1,\n",
        "    n=3)\n",
        "\n",
        "for i in response.choices:\n",
        "    print(i.text)\n",
        "    print (\"**************************\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "100% cloud-based so you don’t need any local hardware or infrastructure to use\n**************************\n1st comprehensive cloud ml service with automated ml capabilities.\nImportant to note that it\n**************************\n a SAAS product by Microsoft that enables capability of creating, developing, deploying and\n**************************\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720052797749
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# logprobs\n",
        "\n",
        "Defaults to null, optional\n",
        "\n",
        "Log probabilities of output tokens indicate **the likelihood of each token occurring in the sequence given the context.** To simplify, a logprob is log(p), where p = probability of a token occurring at a specific position based on the previous tokens in the context.\n",
        "\n",
        "For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response.\n",
        "\n",
        "** tokens ** — is an array of tokens generated by the language model. Each token is a word or part of a word.\n",
        "\n",
        "** token_logprobs ** — represents an array of log probabilities for each token in the tokens array. Log probability indicates the likelihood of the language model generating that token for the given prompt. The logprob values are negative, where smaller (more negative) numbers indicate a less likely outcome.\n",
        "\n",
        "** top_logprobs ** — represents an array of log probability objects, representing tokens most likely to be used for the completion. For example, if we specify the request parameter top_p = 0.5, then top_logprobs would contain log probabilities for top 50% of generated tokens."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'Azure machine learning is  '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    temperature=0,\n",
        "    logprobs=2)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720052802757
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].text"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "' a cloud-based service that provides tools for building, deploying, and managing machine learning'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720052802918
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9h4b4MBWC4jmPH6wFsmhGJgiRObBH\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": {\n        \"text_offset\": [\n          27,\n          29,\n          35,\n          41,\n          49,\n          54,\n          63,\n          69,\n          73,\n          82,\n          83,\n          93,\n          94,\n          98,\n          107,\n          115\n        ],\n        \"token_logprobs\": [\n          -1.3544242,\n          -0.5052965,\n          -0.33200297,\n          -1.3254664,\n          -0.74125546,\n          -1.3207276,\n          -1.5644419,\n          -0.8489064,\n          -0.5393729,\n          -0.46892568,\n          -0.54874253,\n          -0.2936565,\n          -0.079444215,\n          -0.48917344,\n          -0.09763703,\n          -0.018707484\n        ],\n        \"tokens\": [\n          \" a\",\n          \" cloud\",\n          \"-based\",\n          \" service\",\n          \" that\",\n          \" provides\",\n          \" tools\",\n          \" for\",\n          \" building\",\n          \",\",\n          \" deploying\",\n          \",\",\n          \" and\",\n          \" managing\",\n          \" machine\",\n          \" learning\"\n        ],\n        \"top_logprobs\": [\n          {\n            \" a\": -1.3544242,\n            \" used\": -3.096278\n          },\n          {\n            \" cloud\": -0.5052965,\n            \" fully\": -2.8223684\n          },\n          {\n            \"-based\": -0.33200297,\n            \" based\": -2.368193\n          },\n          {\n            \" service\": -1.3254664,\n            \" platform\": -1.5957549\n          },\n          {\n            \" that\": -0.74125546,\n            \" for\": -1.9083602\n          },\n          {\n            \" provides\": -1.3207276,\n            \" enables\": -1.8764279\n          },\n          {\n            \" tools\": -1.5644419,\n            \" a\": -1.9370768\n          },\n          {\n            \" for\": -0.8489064,\n            \" to\": -0.9779347\n          },\n          {\n            \" building\": -0.5393729,\n            \" data\": -1.4708171\n          },\n          {\n            \",\": -0.46892568,\n            \" and\": -1.7726157\n          },\n          {\n            \" deploying\": -0.54874253,\n            \" training\": -1.5892203\n          },\n          {\n            \",\": -0.2936565,\n            \" and\": -1.4170219\n          },\n          {\n            \" and\": -0.079444215,\n            \" testing\": -4.4498515\n          },\n          {\n            \" managing\": -0.48917344,\n            \" sharing\": -1.7967639\n          },\n          {\n            \" machine\": -0.09763703,\n            \" predictive\": -3.9510438\n          },\n          {\n            \" learning\": -0.018707484,\n            \"-learning\": -4.8182507\n          }\n        ]\n      },\n      \"text\": \" a cloud-based service that provides tools for building, deploying, and managing machine learning\",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1720052802,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 16,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 21\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720052804827
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720052807762
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Word values :\",response.choices[0].logprobs.tokens)\n",
        "print(\"Token log probabilities :\",response.choices[0].logprobs.token_logprobs)\n",
        "print(\"Top log linear probabilities :\",np.round(np.exp(response.choices[0].logprobs.token_logprobs)*100,2))\n",
        "\n",
        "print(\"Response:\", response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Word values : [' a', ' cloud', '-based', ' service', ' that', ' provides', ' tools', ' for', ' building', ',', ' deploying', ',', ' and', ' managing', ' machine', ' learning']\nToken log probabilities : [-1.3544242, -0.5052965, -0.33200297, -1.3254664, -0.74125546, -1.3207276, -1.5644419, -0.8489064, -0.5393729, -0.46892568, -0.54874253, -0.2936565, -0.079444215, -0.48917344, -0.09763703, -0.018707484]\nTop log linear probabilities : [25.81 60.33 71.75 26.57 47.65 26.69 20.92 42.79 58.31 62.57 57.77 74.55\n 92.36 61.31 90.7  98.15]\nResponse:  a cloud-based service that provides tools for building, deploying, and managing machine learning\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720052808811
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Presence_penalty\n",
        "\n",
        "Defaults to 0, Optional -> 0 means there is really no penalty or reward for the same token appearing multiple times. \n",
        "\n",
        "Number between -2.0 and 2.0. Positive values penalize new tokens based on ** whether they appear in the text so far **, increasing the model's likelihood to talk about new topics.\n",
        "\n",
        "Smaller values (minimum -2) decrease the penalty and increase the chances of a token appearing, while higher values (maximum 2) increase the penalty and decrease the chances of a token appearing."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'Azure machine learning is '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    presence_penalty=2,\n",
        "    max_tokens=50)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720052813745
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " built to empower developers and data scientists with the following capabilities,\n\n1. Build models faster: Automate model generation by using automated machine learning.\n\n2. Manage the models better: Track each model version more easily and manage deployment of these versions with ease.\n\n\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720052813892
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'Azure machine learning is '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    presence_penalty=-2,\n",
        "    max_tokens=50)\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " most commonly used for developing, deploying, and sharing predictive analytics models, along with developing and sharing data preparation and transformation solutions and automating model generation and training.\n\nThe platform allows for building and training models with popular machine learning frameworks, and deploying models as\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720029536967
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9gyXo0lwHERGp5EvVWF35QMZWAFFL\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"text\": \" most commonly used for developing, deploying, and sharing predictive analytics models, along with developing and sharing data preparation and transformation solutions and automating model generation and training.\\n\\nThe platform allows for building and training models with popular machine learning frameworks, and deploying models as\",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1720029536,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 50,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 55\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720029542854
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Frequency_penalty\n",
        "\n",
        "Defaults to 0\n",
        "\n",
        "Number between -2.0 and 2.0. Positive values ** penalize new tokens based on their existing frequency in the text so far **, decreasing the model's likelihood to repeat the same line verbatim."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Best_of\n",
        "\n",
        "Defaults to 1,optional\n",
        "\n",
        "This parameter tells the language model to generate multiple completions and return the best one, which is the one with the highest log probability per token.\n",
        "\n",
        "\n",
        "Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'The Bupa company is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    best_of=3,\n",
        "    max_tokens=50)\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "29-billion-pound revenue healthcare company from the United Kingdom that was started in 1947. It provides health insurance to its customers in more than 190 countries around the world. Until February 2021, it was located in central London but has now\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720029573590
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# logit_bias\n",
        "\n",
        "Defaults to null\n",
        "\n",
        "The logit_bias request parameter is used to modify the likelihood of specified tokens appearing in the completion. We can use this parameter to provide hints to the language model about **which tokens we want or don’t want to appear in the completion**. It basically allows us to make the model more biased towards certain keywords or topics."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-100 bias, which should completely prevent them from appearing.\n",
        "# 100 bias will show only that word\n",
        "start_phrase = 'The Bupa company is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    logit_bias={\"30\":10, \"5936\": 10})\n",
        "#5936 for April\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "70 year old organization with full UK coverage, acquired April? April? April? April? April? April? April? April? April? April? April? April? April? April? April? April? April? April? April? April?\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720029782073
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Echo and Stop"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By setting the echo parameter to true, you’re asking the language model to **return the prompt embedded within the completion.** This is useful for debugging."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'The Bupa company is a '\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    echo=False)\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "private health company. It provides a large range of health services which include health insurance, dental care, travel insurance, care homes, and physiotherapy. It has subsidiaries in a total of 190 countries and serves over 25 million clients. It\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720029894556
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ** stop ** parameter allows you to specify up to 4 sequences of text on which the language model will halt and return the result. This is useful for specifying early termination triggers for the language model."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'The Bupa company is a '\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    temperature=0,\n",
        "    stop=\"company\")\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "70-year-old \n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720030022270
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'The Bupa company is a '\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    temperature=0,\n",
        "    stop=[\"company\",\"United\"])\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "70-year-old \n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720030054405
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/reference"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}