{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import openai\n",
        "# from openai import AzureOpenAI\n",
        "# import os \n",
        "# from azure.identity import ManagedIdentityCredential\n",
        "\n",
        "# default_credential=ManagedIdentityCredential(client_id=\"XXX\")\n",
        "# token=default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "# Resource_endpoint=\"XXXX\"\n",
        "\n",
        "# client = AzureOpenAI(\n",
        "#   azure_endpoint = Resource_endpoint, \n",
        "#   api_key=token.token,  \n",
        "#   api_version=\"2023-05-15\"\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720090341386
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "    \n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
        "    api_version=\"2024-02-01\", #latest GA API version: https://learn.microsoft.com/en-us/azure/ai-services/openai/api-version-deprecation\n",
        "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724165993950
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getenv(\"AZURE_OPENAI_ENDPOINT\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://azuremlopenai.openai.azure.com/\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724165995179
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Temperature\n",
        "\n",
        "Defaults to 1, Optional\n",
        "\n",
        "What sampling temperature to use, between 0 and 2. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 for ones with a well-defined answer.\n",
        "\n",
        "We generally recommend altering this or top_p but not both."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(num_times, start_phrase, temperature):\n",
        "    for i in range(num_times):\n",
        "        \n",
        "        deployment_name='gpt-35-turbo' \n",
        "\n",
        "        # Send a completion call to generate an answer\n",
        "        response = client.completions.create(\n",
        "            model=deployment_name, \n",
        "            prompt=start_phrase, \n",
        "            temperature=temperature,\n",
        "            max_tokens=10)\n",
        "        print(response.choices[0].text)\n",
        "        print(\"*****************************\")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1724166025018
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'Azure machine learning is ', temperature = 0)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n a cloud-based service that provides tools to build,\n*****************************\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724166034947
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'Azure machine learning is ', temperature =0.5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "100% cloud-based and it is a fully-man\n*****************************\n a cloud-based platform that provides a complete set of\n*****************************\n a cloud-based service that provides tools and services for\n*****************************\n100% compatible with Python 3.6,\n*****************************\n100% open source, and is the most comprehensive\n*****************************\n100% cloud-based. It is a fully managed\n*****************************\n a cloud-based service that provides tools for building,\n*****************************\n a cloud-based platform for building, deploying, and\n*****************************\n a cloud-based service that provides tools and services for\n*****************************\n100% cloud-based and is designed for building and\n*****************************\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724166042947
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Top_p\n",
        "\n",
        "Defaults to 1, Optional\n",
        "\n",
        "top_p parameter which stands for “top probability” and an alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. \n",
        "\n",
        "The top_p refers to the probability mass that should be used when considering the next word in the generated text. Essentially it ** sets a threshold for the probability of the next word being chosen and only considers the most likely words that exceed that threshold.**\n",
        "\n",
        "We generally recommend altering this or temperature but not both."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(num_times, start_phrase, top_p):\n",
        "    for i in range(num_times):\n",
        "        \n",
        "        deployment_name='gpt-35-turbo' \n",
        "\n",
        "        # Send a completion call to generate an answer\n",
        "        response = client.completions.create(\n",
        "            model=deployment_name, \n",
        "            prompt=start_phrase, \n",
        "            top_p=top_p,\n",
        "            max_tokens=30)\n",
        "        print(response.choices[0].text)\n",
        "        print(\"*****************************\")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1724167565988
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'Azure machine learning is ', top_p = 0.1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a drag-and-drop interface to build models and a\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a drag-and-drop interface to build models and pipelines\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a drag-and-drop interface to build models and a\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a drag-and-drop interface to build models and a\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a drag-and-drop interface to build models and a\n*****************************\n a cloud-based service that provides tools to build, deploy, and manage machine learning models. It provides a web interface to create and manage experiments, which\n*****************************\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1724167575058
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'Azure machine learning is ', top_p = 1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " a cloud-based machine learning service to train, deploy, automate, manage, and track ML models. This solution accelerator quickly deploys the solution instance in\n*****************************\n a cloud based service used to train, deploy, automate, manage and track the performance of the machine learning models.\n\nIt includes:\n1. A cloud\n*****************************\n100% a cloud service, namely a group of web interfaces and APIs hosted on Azure. When you build, train, and deploy a deep learning model\n*****************************\n a Microsoft cloud service that helps you build, train, and deploy machine learning models and inference pipelines at scale. Even people with no data science experience can\n*****************************\n an Azure cloud-based solution used to develop, do the data experiment, compare different machine learning models, optimize hyperparameters, \n+deploy as web services\n*****************************\n1.5 times faster than AWS according to this independent product test. Do more with Azure!\n\n#azuremachinelearning #azuremlacceleration #azure\n*****************************\n100% Apache Spark compatible (with no code modification required); therefore, you can connect to an Azure Databricks workspace to access the Spark clusters to\n*****************************\n3rd generation of computing and presently the most important area of research.\n\nML Alone Cannot Help- This is True\n\nYes, machine learning is just not\n*****************************\n100% managed, and customers can start using AML right away without any deep technical knowledge of tools or platforms, there is no hardware or software infrastructure\n*****************************\n79% cheaper than AWS Sagemaker”\n- “Google Cloud is 15% cheaper than Azure”\n- “AWS Sagemaker is 25\n*****************************\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1724167580916
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Max_Tokens \n",
        "\n",
        "Default value=16, Optional\n",
        "\n",
        "The maximum number of tokens to generate in the completion. **The token count of your prompt plus max_tokens can't exceed the model's context length. **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deployment_name='gpt-35-turbo' \n",
        "#This will correspond to the custom name you chose for your deployment when you deployed a model. \n",
        "    \n",
        "# Send a completion call to generate an answer\n",
        "start_phrase = 'Azure machine learning is '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    temperature=1,\n",
        "    max_tokens=15)\n",
        "\n",
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9yL2ThKpe5Rgvzj4wmPwsZgNgdgJP\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"text\": \"0.01 inbuilt features.\\nhere we will develop our deep learning model\",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1724167581,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 15,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 20\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724167582913
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Send a completion call to generate an answer\n",
        "start_phrase = 'Nationwide Building Society is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    temperature=1,\n",
        "    max_tokens=90)\n",
        "\n",
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9yL2eeozHttVfP2SWH0CkIQu25T37\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"text\": \"50-50 joint-venture between STO and the Nationwide Group and operates in the Indian agrochemical market.\\n\\nConstruction Milestones Achieved\\n\\nDuring the quarter, the company’s Bathinda Chemical Complex achieved the first-time production of alternate fuel gas (AF Gas). The facility has a proposed capacity of 7.5 lakh tonnes per year of AF gas.\\n\\nStory continues\\n\\nSIL’s Speciality Chemical Complex at Dahej also achieved the first\",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1724167592,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 90,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 95\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724167593915
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# n\n",
        "\n",
        "Defaults to 1, optional\n",
        "\n",
        "How many completions to generate for each prompt. To generate multiple completions, we specify the n request parameter, which simply stands for ** “number of completions” **\n",
        "\n",
        "Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "deployment_name='gpt-35-turbo' \n",
        "#This will correspond to the custom name you chose for your deployment when you deployed a model. \n",
        "    \n",
        "# Send a completion call to generate an answer\n",
        "start_phrase = 'Azure machine learning is '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    temperature=1,\n",
        "    n=3)\n",
        "\n",
        "for i in response.choices:\n",
        "    print(i.text)\n",
        "    print (\"**************************\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " very powerful and complex. It can optimize compute resources, build environments, and be\n**************************\n100% open-source. It is designed to work with innovative open-source tools such\n**************************\n0-stars based on 0 user reviews. \n\nRecent User Reviews\n\nA comprehensive\n**************************\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724220628328
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# logprobs\n",
        "\n",
        "Defaults to null, optional\n",
        "\n",
        "Log probabilities of output tokens indicate **the likelihood of each token occurring in the sequence given the context.** To simplify, a logprob is log(p), where p = probability of a token occurring at a specific position based on the previous tokens in the context.\n",
        "\n",
        "For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response.\n",
        "\n",
        "** tokens ** — is an array of tokens generated by the language model. Each token is a word or part of a word.\n",
        "\n",
        "** token_logprobs ** — represents an array of log probabilities for each token in the tokens array. Log probability indicates the likelihood of the language model generating that token for the given prompt. The logprob values are negative, where smaller (more negative) numbers indicate a less likely outcome.\n",
        "\n",
        "** top_logprobs ** — represents an array of log probability objects, representing tokens most likely to be used for the completion. For example, if we specify the request parameter top_p = 0.5, then top_logprobs would contain log probabilities for top 50% of generated tokens."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'Azure machine learning is  '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    temperature=0,\n",
        "    logprobs=2)"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724220633357
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].text"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "' a cloud-based service that provides tools for building, deploying, and managing machine learning'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724220635388
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9yYq8xLMGxTqQms9tOFGzHEtCsaUu\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": {\n        \"text_offset\": [\n          27,\n          29,\n          35,\n          41,\n          49,\n          54,\n          63,\n          69,\n          73,\n          82,\n          83,\n          93,\n          94,\n          98,\n          107,\n          115\n        ],\n        \"token_logprobs\": [\n          -1.3544242,\n          -0.5052965,\n          -0.33200297,\n          -1.3254664,\n          -0.74125546,\n          -1.3207276,\n          -1.5644419,\n          -0.8489064,\n          -0.5393729,\n          -0.46892568,\n          -0.54874253,\n          -0.2936565,\n          -0.079444215,\n          -0.48917344,\n          -0.09763703,\n          -0.018707484\n        ],\n        \"tokens\": [\n          \" a\",\n          \" cloud\",\n          \"-based\",\n          \" service\",\n          \" that\",\n          \" provides\",\n          \" tools\",\n          \" for\",\n          \" building\",\n          \",\",\n          \" deploying\",\n          \",\",\n          \" and\",\n          \" managing\",\n          \" machine\",\n          \" learning\"\n        ],\n        \"top_logprobs\": [\n          {\n            \" a\": -1.3544242,\n            \" used\": -3.096278\n          },\n          {\n            \" cloud\": -0.5052965,\n            \" fully\": -2.8223684\n          },\n          {\n            \"-based\": -0.33200297,\n            \" based\": -2.368193\n          },\n          {\n            \" service\": -1.3254664,\n            \" platform\": -1.5957549\n          },\n          {\n            \" that\": -0.74125546,\n            \" for\": -1.9083602\n          },\n          {\n            \" provides\": -1.3207276,\n            \" enables\": -1.8764279\n          },\n          {\n            \" tools\": -1.5644419,\n            \" a\": -1.9370768\n          },\n          {\n            \" for\": -0.8489064,\n            \" to\": -0.9779347\n          },\n          {\n            \" building\": -0.5393729,\n            \" data\": -1.4708171\n          },\n          {\n            \",\": -0.46892568,\n            \" and\": -1.7726157\n          },\n          {\n            \" deploying\": -0.54874253,\n            \" training\": -1.5892203\n          },\n          {\n            \",\": -0.2936565,\n            \" and\": -1.4170219\n          },\n          {\n            \" and\": -0.079444215,\n            \" testing\": -4.4498515\n          },\n          {\n            \" managing\": -0.48917344,\n            \" sharing\": -1.7967639\n          },\n          {\n            \" machine\": -0.09763703,\n            \" predictive\": -3.9510438\n          },\n          {\n            \" learning\": -0.018707484,\n            \"-learning\": -4.8182507\n          }\n        ]\n      },\n      \"text\": \" a cloud-based service that provides tools for building, deploying, and managing machine learning\",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1724220632,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 16,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 21\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724220639371
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724220643394
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Word values :\",response.choices[0].logprobs.tokens)\n",
        "print(\"Token log probabilities :\",response.choices[0].logprobs.token_logprobs)\n",
        "print(\"Top log linear probabilities :\",np.round(np.exp(response.choices[0].logprobs.token_logprobs)*100,2))\n",
        "\n",
        "print(\"Response:\", response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Word values : [' a', ' cloud', '-based', ' service', ' that', ' provides', ' tools', ' for', ' building', ',', ' deploying', ',', ' and', ' managing', ' machine', ' learning']\nToken log probabilities : [-1.3544242, -0.5052965, -0.33200297, -1.3254664, -0.74125546, -1.3207276, -1.5644419, -0.8489064, -0.5393729, -0.46892568, -0.54874253, -0.2936565, -0.079444215, -0.48917344, -0.09763703, -0.018707484]\nTop log linear probabilities : [25.81 60.33 71.75 26.57 47.65 26.69 20.92 42.79 58.31 62.57 57.77 74.55\n 92.36 61.31 90.7  98.15]\nResponse:  a cloud-based service that provides tools for building, deploying, and managing machine learning\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724220644380
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Presence_penalty\n",
        "\n",
        "Defaults to 0, Optional -> 0 means there is really no penalty or reward for the same token appearing multiple times. \n",
        "\n",
        "Number between -2.0 and 2.0. Positive values penalize new tokens based on ** whether they appear in the text so far **, increasing the model's likelihood to talk about new topics.\n",
        "\n",
        "Smaller values (minimum -2) decrease the penalty and increase the chances of a token appearing, while higher values (maximum 2) increase the penalty and decrease the chances of a token appearing."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'Azure machine learning is '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    presence_penalty=2,\n",
        "    max_tokens=50)"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724220650306
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " good place for in depth - regression and classification models , where you can create top of line models . \n\nFor simple linear regression , sklearn works great.\n\nIn the above case we are trying to fit a function : y = ax + b \nwhere a\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724220653496
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'Azure machine learning is '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    presence_penalty=-2,\n",
        "    max_tokens=50)\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " a cloud-based environment used to train, deploy, automate, manage, and track machine learning models.. \n\nThe environment provides a cloud-based environment to train, deploy, automate, manage, and track machine learning models..\n\nThe environment provides a cloud-based environment\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724220657321
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9yYqWp02KkpjhMA5ahsAoXHwzXHSy\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"text\": \" a cloud-based environment used to train, deploy, automate, manage, and track machine learning models.. \\n\\nThe environment provides a cloud-based environment to train, deploy, automate, manage, and track machine learning models..\\n\\nThe environment provides a cloud-based environment\",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1724220656,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 50,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 55\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724220660400
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Frequency_penalty\n",
        "\n",
        "Defaults to 0\n",
        "\n",
        "Number between -2.0 and 2.0. Positive values ** penalize new tokens based on their existing frequency in the text so far **, decreasing the model's likelihood to repeat the same line verbatim."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Best_of\n",
        "\n",
        "Defaults to 1,optional\n",
        "\n",
        "This parameter tells the language model to generate multiple completions and return the best one, which is the one with the highest log probability per token.\n",
        "\n",
        "\n",
        "Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'Nationwide Building Society is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    best_of=3,\n",
        "    max_tokens=50)\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "13-time winner of Workplace Employer of the Year. It puts members at the heart of everything it does and has achieved this through building a culture of engagement and involvement.\n\nTo foster this workplace culture, Nationwide provides employees with an extensive range of development opportunities including\n"
        }
      ],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724220666324
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# logit_bias\n",
        "\n",
        "Defaults to null\n",
        "\n",
        "The logit_bias request parameter is used to modify the likelihood of specified tokens appearing in the completion. We can use this parameter to provide hints to the language model about **which tokens we want or don’t want to appear in the completion**. It basically allows us to make the model more biased towards certain keywords or topics."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-100 bias, which should completely prevent them from appearing.\n",
        "# 100 bias will show only that word\n",
        "start_phrase = 'Nationwide Building Society is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    logit_bias={\"30\":10, \"5936\": 0})\n",
        "#5936 for April\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "4 minute walk and Waitrose? Watford?????? is? a??????...?????????????????????????\n"
        }
      ],
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724220670307
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Echo and Stop"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By setting the echo parameter to true, you’re asking the language model to **return the prompt embedded within the completion.** This is useful for debugging."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'Nationwide Building Society is a '\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    echo=False)\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "165-year-old, mutually based financial institution in the UK and is the world’s largest building society. With over 16 million members, Nationwide is the UK's second-largest mortgage lender and has one of the highest customer satisfaction scores as compared to other banking\n"
        }
      ],
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724220697335
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ** stop ** parameter allows you to specify up to 4 sequences of text on which the language model will halt and return the result. This is useful for specifying early termination triggers for the language model."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'Nationwide Building Society is a '\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    temperature=0,\n",
        "    stop=\"company\")\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "168-year-old mutual organisation that has been providing financial services to its members since 1846. Nationwide is the world’s largest building society, with over 15 million members and 700 branches across the UK. Nationwide is committed to providing its members with\n"
        }
      ],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724220701307
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'Nationwide Building Society is a '\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    temperature=0,\n",
        "    stop=[\"company\",\"United\"])\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "168-year-old mutual organisation that has been providing financial services to its members since 1846. Nationwide is the world’s largest building society, with over 15 million members and 700 branches across the UK. Nationwide is committed to providing its members with\n"
        }
      ],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724220703305
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/reference"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}