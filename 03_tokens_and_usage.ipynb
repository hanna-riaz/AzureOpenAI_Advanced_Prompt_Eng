{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Key topics:\n",
        "\n",
        "**Tokens**: Tokens are a numerical representation of how the Azure OpenAI models process text. So they are representing words or just chunks of characters. For English text, 1 token is approximately 4 characters or 0.75 words. \n",
        "\n",
        "**Tokenization**: splitting input/output texts into smaller units for LLMs.\n",
        "\n",
        "**Vocabulary size**: the number of tokens each model uses, which varies among different GPT models."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken #python library for encoding text \n",
        "\n",
        "cl100k_base = tiktoken.get_encoding(\"cl100k_base\") #pretrained tokenizer\n",
        "\n",
        "enc = tiktoken.Encoding( \n",
        "    name=\"gpt-35-turbo\",  \n",
        "    pat_str=cl100k_base._pat_str, \n",
        "    mergeable_ranks=cl100k_base._mergeable_ranks, \n",
        "    special_tokens={ \n",
        "        **cl100k_base._special_tokens, \n",
        "        \"<|im_start|>\": 100264, \n",
        "        \"<|im_end|>\": 100265\n",
        "    } \n",
        ") \n",
        "\n",
        "tokens = enc.encode( \n",
        "    \"Boost employee health and productivity with Bupa by your side. That's better for business.\"\n",
        ") \n",
        "\n",
        "print('Total number of tokens:', len(tokens))\n",
        "print('Tokens : ', [enc.decode([t]) for t in tokens])\n",
        "print(\"Tokens' numerical values:\", tokens)\n",
        "\n",
        "#https://platform.openai.com/tokenizer"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Total number of tokens: 18\nTokens :  ['Boost', ' employee', ' health', ' and', ' productivity', ' with', ' B', 'upa', ' by', ' your', ' side', '.', ' That', \"'s\", ' better', ' for', ' business', '.']\nTokens' numerical values: [53463, 9548, 2890, 323, 26206, 449, 426, 46931, 555, 701, 3185, 13, 3011, 596, 2731, 369, 2626, 13]\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1720519263978
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns the num of tokens used on a string\n",
        "def num_tokens_from_string(string: str) -> int:\n",
        "    encoding_name ='cl100k_base'\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720050922768
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens_from_string(\"Boost employee health and productivity with Bupa by your side. That's better for business.\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "18"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720050944808
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "\n",
        "import os\n",
        "from openai import AzureOpenAI\n",
        "    \n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
        "    api_version=\"2024-02-15-preview\",\n",
        "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    )\n",
        "    \n",
        "deployment_name='gpt-35-turbo' #This will correspond to the custom name you chose for your deployment when you deployed a model. \n",
        " "
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720086955158
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Send a completion call to generate an answer\n",
        "print('Sending a test completion job')\n",
        "start_phrase = 'Royal London company is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    max_tokens=1000)\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sending a test completion job\n47,000 employee corporation with almost negligible operating profits in this country. And like so many multi-national companies, Bupa exploits an egregious tax avoidance structure. But how frightening the potential power of 47,000 health workers apparently taking a collective view on something they know relatively very little about. Even our own Health Secretary, Jeremy Hunt, who describes himself as an ‘insider with a rebel soul’ at Davos, admits that social media sites such as Twitter “can all too quickly become a cesspit with a very particular world view.” So it cannot be coincidence that the outpouring of support on social media for the BMA’s stance against contract imposition came overwhelmingly from doctors in the early stages of their career, many with vested interests in pension agreements and pay scales.\n\nThe standard five-day hospital week remains a luxury for many hospital doctors, with many of their ‘rest’ days spent on call. Their’s is a highly demanding, sometimes very stressful profession where errors of judgement, misdiagnoses or incorrect prescriptions can lead to serious consequences. Daily shift patterns mean that millions of women on routine contraceptives may have to consider alternatives if GPs go on strike, with the prospect of unwanted pregnancies or the risk of blood clots that replacement treatments may carry. But there are also the unsung heroes, the junior doctors who every day are also grappling with the effects of a cruel and underfunded social care system, which has forced hospitals to struggle to discharge frail older patients because there are few, if any, social care facilities for them to receive care at home.\n\nIt should not be forgotten that NHS staff have lost out even more in many ways than those who they care for. Their pay, pensions and working conditions have been reduced in relative terms since 2010 by the most ideological government since the last two decades of the eighteenth century. Patients have not helped the situation by failing to turn up for appointments, causing additional stress to their often exhausted caregivers who bear the brunt of their misplaced anger. In a civilised society we should have deep and very abiding concerns about anyone who thinks a doctor’s working conditions and pay do not affect patient safety, even if you believe the government’s assessment of the tender in paediatric services that was won by Virgin Care. In Greece, ‘cash strapped’ hospitals have resorted to begging nurses and doctors to put in overtime for free.\n\nAt the heart of the matter is the fact that junior doctors have no other bargaining tools with which to defend their 24/7 contracts and their highly unsocial shift patterns. If they go ahead and withdraw their services completely from A&E departments, there will be undisputed public protests that they are not essential services and that patients’ lives are being put at risk. If they only walk out in the run up to the Christmas period, they risk the same public opprobrium because they will sound as if they are trying to pressurise the public purse.\n\nNo-one doubts that Jeremy Hunt has behaved throughout these negotiations as if he was Thatcher reincarnated, and has alienated an entire profession by using statistics to suit rather than inform government policy. Nevertheless, the BMA’s leader, Dr Mark Porter, should consider very carefully the concerns of the senior medical economists who are calling for a referendum on this contract proposal. He, more than any other union boss, knows that brinkmanship by both sides is not only damaging to patients but also to this country’s reputation as a civilised society.\n\nLast night George Osborne made a commitment to pay down the national debt in 2016-17, the year in which he hopes George Osborne can celebrate the economy. This is the year that Osborne will be hoping to hit his target – eradicating the deficit and priming the economy for faster growth. But he has also pledged to start paying down the debt built-up since the crisis, a move which suggests fiscal responsibility and helps him take the focus off controversial economic revision. But how accurate is this?\n\nOsborne has taken the lion’s share of the credit for obliging Britain with managed austerity and the economic prudence which reduced the deficit and placed the country back onto what would have been a sure and steady course of sustainable growth. He triumphantly proclaimed during the Today programme a few months ago that he ultimately had no choice but to make the cuts to public spending and raise taxes because of the excessively large deficit and the threats posed to the nation by international creditors. Many thought that this was the moment at which he may be forced into a little modesty regarding the uptake of austerity measures, but instead he deftly spun the story in a way that absolved him of all personal culpability for the cuts, and against other policy-makers within the coalition government.\n\nUnfortunately for Osborne, this narrative is false and needs closer examination. Of course it is an unpleasant and disheartening task to cut public spending, but the harsh reality is that every one of Osborne’s numbers was the direct outcome of his own\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1720087021008
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usage"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "Completion(id='cmpl-9h3W0m3dpSWCRYM6V7jtFDZOafWld', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text='2019 breakingvoices.com Awards finalist.\\n\\nMeer over Bupa UK\\n\\nThe Breaking Voices 2019 Awards shortlist is an exclusive list of the best organizations and individuals from across each category. It recognizes achievements in business, innovation, creativity and social impact. The awarding ceremony will take place November 26th, 2019 at the Somerset House in London.\\n\\nPaul Landau, CEO Bupa UK Insurance: \"We\\'re proud to be shortlisted for two awards in this year\\'s Breaking', content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1720048644, model='gpt-35-turbo', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=100, prompt_tokens=6, total_tokens=106), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720048693734
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.usage"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "CompletionUsage(completion_tokens=1000, prompt_tokens=6, total_tokens=1006)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1720087099420
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Azure OpenAI uses a subword tokenization method called \"Byte-Pair Encoding (BPE)\" for its GPT-based models. ** BPE is a method that merges the most frequently occurring pairs of characters or bytes into a single token **, until a certain number of tokens or a vocabulary size is reached. BPE can help the model to handle rare or unseen words, and to create more compact and consistent representations of the texts. BPE can also allow the model to generate new words or tokens, by combining existing ones. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/tokens"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}