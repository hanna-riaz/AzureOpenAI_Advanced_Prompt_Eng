{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Key topics:\n",
        "\n",
        "**Tokens**: Tokens are a numerical representation of how the Azure OpenAI models process text. So they are representing words or just chunks of characters. For English text, 1 token is approximately 4 characters or 0.75 words. \n",
        "\n",
        "**Tokenization**: splitting input/output texts into smaller units for LLMs.\n",
        "\n",
        "**Vocabulary size**: the number of tokens each model uses, which varies among different GPT models."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install tiktoken #The open source version of tiktoken can be installed from PyPI"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716193272223
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken \n",
        "\n",
        "cl100k_base = tiktoken.get_encoding(\"cl100k_base\") \n",
        "\n",
        "enc = tiktoken.Encoding( \n",
        "    name=\"gpt-35-turbo\",  \n",
        "    pat_str=cl100k_base._pat_str, \n",
        "    mergeable_ranks=cl100k_base._mergeable_ranks, \n",
        "    special_tokens={ \n",
        "        **cl100k_base._special_tokens, \n",
        "        \"<|im_start|>\": 100264, \n",
        "        \"<|im_end|>\": 100265\n",
        "    } \n",
        ") \n",
        "\n",
        "tokens = enc.encode( \n",
        "    \"Enstar is a leading global insurance group that delivers innovative insurance solutions through our network of group companies.\"\n",
        ") \n",
        "\n",
        "print('Total number of tokens:', len(tokens))\n",
        "print('Tokens : ', [enc.decode([t]) for t in tokens])\n",
        "print(\"Tokens' numerical values:\", tokens)\n",
        "\n",
        "#https://platform.openai.com/tokenizer"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Total number of tokens: 20\nTokens :  ['En', 'star', ' is', ' a', ' leading', ' global', ' insurance', ' group', ' that', ' delivers', ' innovative', ' insurance', ' solutions', ' through', ' our', ' network', ' of', ' group', ' companies', '.']\nTokens' numerical values: [1737, 12134, 374, 264, 6522, 3728, 8276, 1912, 430, 28421, 18699, 8276, 10105, 1555, 1057, 4009, 315, 1912, 5220, 13]\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1716417105836
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "\n",
        "import os\n",
        "from openai import AzureOpenAI\n",
        "    \n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
        "    api_version=\"2024-02-15-preview\",\n",
        "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    )\n",
        "    \n",
        "deployment_name='gpt-35-turbo' #This will correspond to the custom name you chose for your deployment when you deployed a model. \n",
        " "
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716464353242
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Send a completion call to generate an answer\n",
        "print('Sending a test completion job')\n",
        "start_phrase = 'Enstar Group is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    max_tokens=100)\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sending a test completion job\n2020 Forbes Best Mid-Sized Employer Enstar Group Limited (NASDAQ: ESGR) announced today that it has been named a 2020 Forbes Best Mid-Sized Employer. Enstar is one of 500 companies on the list of the best mid-sized employers in the United States with 1,000 to 5,000 employees. “We are honored to receive this recognition, which is a testament to our employees and their dedication to Enstar’s vision, values, and culture,”\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1716464357140
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usage"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "Completion(id='cmpl-9Rosl5DwpLHwtCcLlWAiYdaXJx6Xu', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text='5.89 billion dollar company focused on the acquisition, management, and renewal of insurance-related business. They are powered by its operating subsidiaries: Enstar International, which provides management, consulting and other services to the company’s subsidiaries and PBMs, and Enstar USA, one of the largest diversified insurance companies in the world. Enstar has a continual pipeline of working capital for acquisitions, and opportunities for strategic expansion. The company’s focus is to manage business as opposed to underwriting', content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1716417475, model='gpt-35-turbo', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=100, prompt_tokens=6, total_tokens=106), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716417487961
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.usage"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "CompletionUsage(completion_tokens=100, prompt_tokens=6, total_tokens=106)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1716417489152
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Azure OpenAI uses a subword tokenization method called \"Byte-Pair Encoding (BPE)\" for its GPT-based models. ** BPE is a method that merges the most frequently occurring pairs of characters or bytes into a single token **, until a certain number of tokens or a vocabulary size is reached. BPE can help the model to handle rare or unseen words, and to create more compact and consistent representations of the texts. BPE can also allow the model to generate new words or tokens, by combining existing ones. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/tokens"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}