{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Key topics:\n",
        "\n",
        "**Tokens**: basic units of text/code for LLMs to process/generate language.\n",
        "\n",
        "**Tokenization**: splitting input/output texts into smaller units for LLMs.\n",
        "\n",
        "**Vocabulary size**: the number of tokens each model uses, which varies among different GPT models.\n",
        "\n",
        "**Tokenization cost**: affects the memory and computational resources that a model needs, which influences the cost and performance of running Azure OpenAI model."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install tiktoken #The open source version of tiktoken can be installed from PyPI"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692046188868
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken \n",
        "\n",
        "cl100k_base = tiktoken.get_encoding(\"cl100k_base\") \n",
        "\n",
        "enc = tiktoken.Encoding( \n",
        "    name=\"gpt-35-turbo\",  \n",
        "    pat_str=cl100k_base._pat_str, \n",
        "    mergeable_ranks=cl100k_base._mergeable_ranks, \n",
        "    special_tokens={ \n",
        "        **cl100k_base._special_tokens, \n",
        "        \"<|im_start|>\": 100264, \n",
        "        \"<|im_end|>\": 100265\n",
        "    } \n",
        ") \n",
        "\n",
        "tokens = enc.encode( \n",
        "    \"The road to creating new medicines and vaccines has traditionally been long and winding!\"\n",
        ") \n",
        "\n",
        "print('Total number of tokens:', len(tokens))\n",
        "print('Tokens : ', [enc.decode([t]) for t in tokens])\n",
        "print(\"Tokens' numerical values:\", tokens)\n",
        "\n",
        "#https://platform.openai.com/tokenizer"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Total number of tokens: 15\nTokens :  ['The', ' road', ' to', ' creating', ' new', ' medicines', ' and', ' vaccines', ' has', ' traditionally', ' been', ' long', ' and', ' winding', '!']\nTokens' numerical values: [791, 5754, 311, 6968, 502, 39653, 323, 40300, 706, 36342, 1027, 1317, 323, 54826, 0]\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1700427628830
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "import os \n",
        "from azure.identity import ManagedIdentityCredential\n",
        "\n",
        "default_credential=ManagedIdentityCredential(client_id=\"d30cba06-04c1-4065-a91d-8b7ce3b07b78\")\n",
        "token=default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "Resource_endpoint=\"https://openaiykus.openai.azure.com/\"\n",
        "openai.api_type=\"azure_ad\"\n",
        "\n",
        "client = AzureOpenAI(\n",
        "  azure_endpoint = Resource_endpoint, \n",
        "  api_key=token.token,  \n",
        "  api_version=\"2023-05-15\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700427833831
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deployment_name='gpt-35-turbo-instruct' \n",
        "#This will correspond to the custom name you chose for your deployment when you deployed a model. \n",
        "    \n",
        "# Send a completion call to generate an answer\n",
        "print('Sending a test completion job')\n",
        "start_phrase = 'Help with the cost of living. '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    max_tokens=10)\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sending a test completion job\n\nHere are a few tips for managing the cost\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1700427836833
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usage"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "Completion(id='cmpl-8MjFMIEUxLhergfxuoP7OgFIsEZeN', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text='\\nHere are a few tips for managing the cost')], created=1700427836, model='gpt-35-turbo-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=8, total_tokens=18))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700427886932
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.usage"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "CompletionUsage(completion_tokens=10, prompt_tokens=8, total_tokens=18)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1700427929896
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Azure OpenAI uses a subword tokenization method called \"Byte-Pair Encoding (BPE)\" for its GPT-based models. ** BPE is a method that merges the most frequently occurring pairs of characters or bytes into a single token **, until a certain number of tokens or a vocabulary size is reached. BPE can help the model to handle rare or unseen words, and to create more compact and consistent representations of the texts. BPE can also allow the model to generate new words or tokens, by combining existing ones. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/tokens"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}