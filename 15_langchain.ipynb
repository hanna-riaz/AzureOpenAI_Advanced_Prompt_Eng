{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Set up variables"
      ],
      "metadata": {},
      "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import urllib\n",
        "import requests\n",
        "import random\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "from IPython.display import display, HTML, Markdown\n",
        "from typing import List\n",
        "from operator import itemgetter\n",
        "\n",
        "# LangChain Imports needed\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
        "#from langchain_core.documents import Document\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "\n",
        "\n",
        "# Our own libraries needed\n",
        "#from common.prompts import DOCSEARCH_PROMPT\n",
        "#from common.utils import get_search_results\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1724229561634
        }
      },
      "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f"
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"what is azure ml for\""
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1724229561786
        }
      },
      "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1724229561921
        }
      },
      "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A gentle intro to chaining LLMs and prompt engineering"
      ],
      "metadata": {},
      "id": "0e7c720e-ece1-45ad-9d01-2dfd15c182bb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step.\n",
        "\n",
        "Azure OpenAI is a type of LLM (provider) that you can use but there are others like Cohere, Huggingface, etc.\n",
        "\n",
        "Chains can be simple (i.e. Generic) or specialized (i.e. Utility).\n",
        "\n",
        "* Generic — A single LLM is the simplest chain. It takes an input prompt and the name of the LLM and then uses the LLM for text generation (i.e. output for the prompt).\n",
        "\n",
        "Here’s an example:"
      ],
      "metadata": {},
      "id": "2bcd7028-5a6c-4296-8c85-4f420d408d69"
    },
    {
      "cell_type": "code",
      "source": [
        "COMPLETION_TOKENS = 2000\n",
        "llm = AzureChatOpenAI(deployment_name=\"gpt-4-0125-Preview\", \n",
        "                      temperature=0.5, \n",
        "                      max_tokens=COMPLETION_TOKENS)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1724229566372
        }
      },
      "id": "13df9247-e784-4e04-9475-55e672efea47"
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = StrOutputParser()\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an assistant that give thorough responses to users.\"),\n",
        "    (\"user\", \"{input}. Give your response in {language}\")\n",
        "])"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1724229567664
        }
      },
      "id": "a3b55adb-6f98-4f15-b67a-9fbba5820560"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The | symbol is similar to a unix pipe operator, which chains together the different components feeds the output from one component as input into the next component."
      ],
      "metadata": {},
      "id": "6417d052-0035-4635-93e8-2bd3ec50d796"
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm | output_parser"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1724229569672
        }
      },
      "id": "77a37e60-a1ef-4750-a1ec-9e4fe5ba07fa"
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"input\": QUESTION, \"language\": \"Spanish\"})"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "'Azure ML (Machine Learning) es una plataforma de computación en la nube de Microsoft diseñada para permitir a los desarrolladores y científicos de datos construir, entrenar y desplegar modelos de aprendizaje automático de manera más eficiente y efectiva. La plataforma ofrece una amplia gama de herramientas y servicios que facilitan el proceso de desarrollo de soluciones de inteligencia artificial (IA) desde la fase de experimentación hasta la producción a gran escala.\\n\\nAzure ML está diseñado para:\\n\\n1. **Facilitar el desarrollo de modelos de aprendizaje automático**: Ofrece un entorno integrado que permite a los usuarios crear, entrenar y validar modelos de manera eficiente. Esto incluye acceso a bibliotecas de aprendizaje automático de alto rendimiento y la capacidad de usar lenguajes de programación populares como Python y R.\\n\\n2. **Gestionar el ciclo de vida completo de los modelos de IA**: Azure ML ayuda a gestionar todo el ciclo de vida de los modelos, desde el desarrollo y el entrenamiento hasta el despliegue y la monitorización en producción. Esto ayuda a garantizar que los modelos se mantengan actualizados y continúen funcionando de manera óptima.\\n\\n3. **Escalar y optimizar los recursos de computación**: La plataforma permite a los usuarios escalar sus recursos de computación fácilmente para manejar grandes volúmenes de datos y modelos complejos. Esto incluye la capacidad de usar GPUs y clusters de alta potencia para acelerar el entrenamiento de los modelos.\\n\\n4. **Integrar con otros servicios de Azure**: Azure ML se integra sin problemas con otros servicios de Azure, como Azure Data Factory, Azure Databricks y Azure Synapse Analytics, lo que permite a los usuarios construir soluciones de IA completas y complejas que pueden incluir la ingesta de datos, el procesamiento, el análisis y la visualización.\\n\\n5. **Facilitar la colaboración y el intercambio de conocimientos**: La plataforma ofrece herramientas para la colaboración entre equipos, lo que permite a los científicos de datos y desarrolladores compartir fácilmente experimentos, modelos y conocimientos. Esto es especialmente útil en entornos donde el trabajo en equipo es esencial para el éxito del proyecto.\\n\\nEn resumen, Azure ML es una plataforma poderosa y flexible que ayuda a democratizar el uso del aprendizaje automático, permitiendo a empresas de todos los tamaños desarrollar soluciones de IA innovadoras y efectivas.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229583840
        }
      },
      "id": "50ea1a39-bea2-4f18-bcc0-bd4eb2e01675"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great!!, now you know how to create a simple prompt and use a chain in order to answer a general question using ChatGPT knowledge!. \n",
        "\n",
        "It is important to note that we rarely use generic chains as standalone chains. More often they are used as building blocks for Utility chains (as we will see next). Also important to notice is that we are NOT using our documents or the result of the Azure Search yet, just the knowledge of ChatGPT on the data it was trained on."
      ],
      "metadata": {},
      "id": "50ed014c-0c6b-448c-b995-fe7970b92ad5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The second type of Chains are Utility:**\n",
        "\n",
        "* Utility — These are specialized chains, comprised of many building blocks to help solve a specific task. For example, LangChain supports some end-to-end chains (such as `create_retrieval_chain` for QnA Doc retrieval, Summarization, etc).\n",
        "\n",
        "We will build our own specific chain in this workshop for digging deeper and solve our use case of enhancing the results of Azure AI Search."
      ],
      "metadata": {
        "tags": []
      },
      "id": "12c48038-b1af-4228-8ffb-720e554fd3b2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "So really, our only job now is to make sure that the results from the Azure AI Search queries fit on the LLM context size, and then let it do its magic."
      ],
      "metadata": {},
      "id": "80e79235-3d8b-4713-9336-5004cc4a1556"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create a Prompt Template that will ground the response only in the given context."
      ],
      "metadata": {},
      "id": "235d4238-df6e-40eb-ab38-4fe6db614acd"
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Answer the question based **ONLY** on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "If the question is different from the context, just tell \"sorry,I can not assist with this query\"\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1724229587824
        }
      },
      "id": "f86ed786-aca0-4e25-947b-d9cf3a82665c"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='Answer the question based **ONLY** on the following context:\\n{context}\\n\\nQuestion: {question}\\nIf the question is different from the context, just tell \"sorry,I can not assist with this query\"\\n'))])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229593680
        }
      },
      "id": "919edc42-2c25-4407-84d3-e9e86046801e"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "# Creation of our custom chain\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "chain.invoke({\"question\": \"Tell me about Nationwide Building Society\", \"context\": \"Azure Machine LEarning is E2E ML platform.\"})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 16.5 ms, sys: 0 ns, total: 16.5 ms\nWall time: 507 ms\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "'Sorry, I cannot assist with this query.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {},
      "id": "25cba3d1-b5ab-4e28-96b3-ef923d99dc9f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Internet and Websites Search using Bing API"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "f1b94b8f-ea6f-40ee-afd9-2400ac6d5208"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from typing import Dict, List, Optional, Type\n",
        "import asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "from langchain import hub\n",
        "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import BaseTool, StructuredTool, tool\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.agents import AgentExecutor, Tool, create_openai_tools_agent\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.utilities import BingSearchAPIWrapper\n",
        "\n",
        "from common.callbacks import StdOutCallbackHandler\n",
        "from common.prompts import BINGSEARCH_PROMPT\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string.replace(\"$\",\"USD \")))\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229619613
        }
      },
      "id": "dceab3d9-5a9e-42cb-bc95-68b85c10f1ef"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229619770
        }
      },
      "id": "2f7c618e-5d5d-4c6d-8fcc-9debf84227d8"
    },
    {
      "cell_type": "code",
      "source": [
        "cb_handler = StdOutCallbackHandler()\n",
        "cb_manager = CallbackManager(handlers=[cb_handler])\n",
        "\n",
        "COMPLETION_TOKENS = 2000\n",
        "\n",
        "llm = AzureChatOpenAI(deployment_name=\"gpt-4-0125-Preview\", \n",
        "                      temperature=0.5, max_tokens=COMPLETION_TOKENS, \n",
        "                      streaming=True, callback_manager=cb_manager)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229620074
        }
      },
      "id": "f22ed7aa-4e48-4488-b80c-63a35e733b33"
    },
    {
      "cell_type": "code",
      "source": [
        "class SearchInput(BaseModel):\n",
        "    query: str = Field(description=\"should be a search query\")\n",
        "\n",
        "class MyBingSearch(BaseTool):\n",
        "    \"\"\"Tool for a Bing Search Wrapper\"\"\"\n",
        "    \n",
        "    name = \"Searcher\"\n",
        "    description = \"useful to search the internet.\\n\"\n",
        "    args_schema: Type[BaseModel] = SearchInput\n",
        "\n",
        "    k: int = 5\n",
        "    \n",
        "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
        "        bing = BingSearchAPIWrapper(k=self.k)\n",
        "        return bing.results(query,num_results=self.k)\n",
        "            \n",
        "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
        "        bing = BingSearchAPIWrapper(k=self.k)\n",
        "        loop = asyncio.get_event_loop()\n",
        "        results = await loop.run_in_executor(ThreadPoolExecutor(), bing.results, query, self.k)\n",
        "        return results"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229621693
        }
      },
      "id": "97a3eb01-904b-401a-9f7b-f39aa77d311e"
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_html(content) -> str:\n",
        "    soup = BeautifulSoup(content, 'html.parser')\n",
        "    text_content_with_links = soup.get_text()\n",
        "    return text_content_with_links\n",
        "\n",
        "def fetch_web_page(url: str) -> str:\n",
        "    HEADERS = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:90.0) Gecko/20100101 Firefox/90.0'}\n",
        "    response = requests.get(url, headers=HEADERS)\n",
        "    return parse_html(response.content)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229627664
        }
      },
      "id": "f3a9dd6f-0762-40a9-b212-a9f7138ab64b"
    },
    {
      "cell_type": "code",
      "source": [
        "web_fetch_tool = Tool.from_function(\n",
        "    func=fetch_web_page,\n",
        "    name=\"WebFetcher\",\n",
        "    description=\"useful to fetch the content of a url\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229627805
        }
      },
      "id": "2d9d6efb-ee00-4271-9282-1a513185dd1e"
    },
    {
      "cell_type": "code",
      "source": [
        "# tools = [MyBingSearch(k=5), web_fetch_tool] # With GPT-4 you can add the web_fetch_tool\n",
        "\n",
        "tools = [MyBingSearch(k=5)] # With GPT-3.5 \n",
        "\n",
        "prompt = BINGSEARCH_PROMPT\n",
        "\n",
        "# Construct the OpenAI Tools agent\n",
        "agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "\n",
        "# Create an agent executor by passing in the agent and tools\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False, \n",
        "                               return_intermediate_steps=True)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229629791
        }
      },
      "id": "23aab0bd-11f2-4318-8e10-33469e37c945"
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.tools"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "[MyBingSearch()]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229641704
        }
      },
      "id": "e0bc94fb-85d1-444c-9097-6fce420b4e85"
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION = \"Create a list with the main facts on What is happening with the oil supply in the world right now?\"\n",
        "# QUESTION = \"How much is 50 USD in Euros and is it enough for an average hotel in Madrid?\"\n",
        "# QUESTION = \"My son needs to build a pinewood car for a pinewood derbi, how do I build such a car?\"\n",
        "# QUESTION = \"I'm planning a vacation to Greece, tell me budget for a family of 4, in Summer, for 7 days including travel, lodging and food costs\"\n",
        "# QUESTION = \"Who won the 2023 superbowl and who was the MVP?\"\n",
        "QUESTION = \"\"\"\n",
        "compare the number of job opennings (provide the exact number), the average salary within 15 miles of Dallas, TX, for these ocupations:\n",
        "\n",
        "- ADN Registerd Nurse \n",
        "- Occupational therapist assistant\n",
        "- Dental Hygienist\n",
        "- Graphic Designer\n",
        "\n",
        "\n",
        "# Create a table with your findings. Place the sources on each cell.\n",
        "# \"\"\""
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229643667
        }
      },
      "id": "890b4270-834a-499d-907c-c4396de4bc99"
    },
    {
      "cell_type": "code",
      "source": [
        "async for chunk in agent_executor.astream({\"question\": QUESTION}):\n",
        "    # Agent Action\n",
        "    if \"actions\" in chunk:\n",
        "        for action in chunk[\"actions\"]:\n",
        "            print(f\"Calling Tool: `{action.tool}` with input `{action.tool_input}`\")\n",
        "    # Observation\n",
        "    elif \"steps\" in chunk:\n",
        "        # Uncomment if you need to have the information retrieve from the tool\n",
        "        # for step in chunk[\"steps\"]:\n",
        "        #     print(f\"Tool Result: `{step.observation}`\")\n",
        "        continue\n",
        "    # Final result\n",
        "    elif \"output\" in chunk:\n",
        "        # No need to print the final output again since we would be streaming it as it is produced\n",
        "        # print(f'Final Output: {chunk[\"output\"]}') \n",
        "        continue\n",
        "    else:\n",
        "        raise ValueError()\n",
        "    print(\"---\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Calling Tool: `Searcher` with input `{'query': 'ADN Registered Nurse job openings in Dallas, TX'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'ADN Registered Nurse average salary within 15 miles of Dallas, TX'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'Occupational therapist assistant job openings in Dallas, TX'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'Occupational therapist assistant average salary within 15 miles of Dallas, TX'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'Dental Hygienist job openings in Dallas, TX'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'Dental Hygienist average salary within 15 miles of Dallas, TX'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'Graphic Designer job openings in Dallas, TX'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'Graphic Designer average salary within 15 miles of Dallas, TX'}`\n---\nHere's a comparison of the number of job openings and the average salary within 15 miles of Dallas, TX, for the specified occupations, presented in a table format:\n\n| Occupation                  | Number of Job Openings | Source for Job Openings | Average Salary (USD/year) | Source for Average Salary |\n|-----------------------------|------------------------|-------------------------|---------------------------|---------------------------|\n| ADN Registered Nurse        | 177                    | [SimplyHired](https://www.simplyhired.com/search?q=rn+%28adn%29&l=dallas%2C+tx) | $70,905                   | [Salary.com](https://www.salary.com/research/salary/hiring/rn-adn-salary/dallas-tx) |\n| Occupational Therapist Assistant | 436                  | [LinkedIn](https://www.linkedin.com/jobs/occupational-therapy-assistant-jobs-dallas) | $91,611                   | [Glassdoor](https://www.glassdoor.com/Salaries/dallas-fort-worth-tx-occupational-therapy-assistant-salary-SRCH_IL.0,20_IM218_KO21,51.htm) |\n| Dental Hygienist           | 290                    | [LinkedIn](https://www.linkedin.com/jobs/dental-hygienist-jobs-dallas-tx) | $82,820                   | [Salary.com](https://www.salary.com/research/salary/benchmark/dental-hygienist-salary/dallas-tx) |\n| Graphic Designer           | 197                    | [LinkedIn](https://www.linkedin.com/jobs/graphic-designer-jobs-dallas) | $69,530                   | [Salary.com](https://www.salary.com/research/salary/recruiting/graphic-designer-salary/dallas-tx) |\n\nThis table provides a clear comparison of the job market and salary expectations for ADN Registered Nurses, Occupational Therapist Assistants, Dental Hygienists, and Graphic Designers in the Dallas, TX area."
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229671695
        }
      },
      "id": "384faabb-2de3-4283-98f8-e1d828987114"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Without showing the intermedite steps, just the final answer"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "7dd531cb-a5dc-47e4-ae73-f7c83282a52d"
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"How much is 50 USD in Euros and is it enough for an average hotel in Madrid?\"\n",
        "\n",
        "try:\n",
        "    response = agent_executor.invoke({\"question\":QUESTION})\n",
        "except Exception as e:\n",
        "    response = str(e)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Based on the current exchange rate, 50 USD is approximately equal to 45.63 Euros [[1]](https://wise.com/gb/currency-converter/usd-to-eur-rate?amount=50.99). \n\nRegarding the cost of an average hotel in Madrid, the price for a week's stay is surprisingly affordable at $625 on average, which equates to roughly $89 per night [[2]](https://www.budgetyourtrip.com/hotels/spain/madrid-3117735). In Euros, considering the current exchange rate, this would be approximately 80.72 Euros per night. \n\nTherefore, 50 USD converted to Euros (approximately 45.63 Euros) would not be enough for an average hotel night in Madrid, as the cost is closer to 80.72 Euros per night."
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229681702
        }
      },
      "id": "629d26b3-00f3-41dd-8576-84b18a48b381"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "printmd(response[\"output\"])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Based on the current exchange rate, 50 USD is approximately equal to 45.63 Euros [[1]](https://wise.com/gb/currency-converter/usd-to-eur-rate?amount=50.99). \n\nRegarding the cost of an average hotel in Madrid, the price for a week's stay is surprisingly affordable at USD 625 on average, which equates to roughly USD 89 per night [[2]](https://www.budgetyourtrip.com/hotels/spain/madrid-3117735). In Euros, considering the current exchange rate, this would be approximately 80.72 Euros per night. \n\nTherefore, 50 USD converted to Euros (approximately 45.63 Euros) would not be enough for an average hotel night in Madrid, as the cost is closer to 80.72 Euros per night."
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229681845
        }
      },
      "id": "8786a3ad-430e-4abc-8751-c38d8fe3716d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QnA to specific websites\n",
        "\n",
        "There are several use cases where we want the smart bot to answer questions about a specific company's public website. There are two approaches we can take:\n",
        "\n",
        "1. Create a crawler script that runs regularly, finds every page on the website, and pushes the documents to Azure Cognitive Search.\n",
        "2. Since Bing has likely already indexed the public website, we can utilize Bing search targeted specifically to that site, rather than attempting to index the site ourselves and duplicate the work already done by Bing's crawler.\n",
        "\n",
        "Below are some sample questions related to specific sites. Take a look:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "58848313-e475-4e07-aa20-5b58dbb73676"
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION = \"information on how to kill wasps in homedepot.com\"\n",
        "QUESTION = \"in target.com, find how what's the price of a Nesspresso coffee machine and of a Keurig coffee machine\"\n",
        "# QUESTION = \"in microsoft.com, find out what is the latests news on quantum computing\"\n",
        "# QUESTION = \"give me on a list the main points on the latest investor report from mondelezinternational.com\""
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229685666
        }
      },
      "id": "80631275-d9e4-49b6-b786-fdb6e94723db"
    },
    {
      "cell_type": "code",
      "source": [
        "async for chunk in agent_executor.astream({\"question\": QUESTION}):\n",
        "    # Agent Action\n",
        "    if \"actions\" in chunk:\n",
        "        for action in chunk[\"actions\"]:\n",
        "            print(f\"Calling Tool: `{action.tool}` with input `{action.tool_input}`\")\n",
        "    # Observation\n",
        "    elif \"steps\" in chunk:\n",
        "        # Uncomment if you need to have the information retrieve from the tool\n",
        "        # for step in chunk[\"steps\"]:\n",
        "        #     print(f\"Tool Result: `{step.observation}`\")\n",
        "        continue\n",
        "    # Final result\n",
        "    elif \"output\" in chunk:\n",
        "        # No need to print the final output again since we would be streaming it as it is produced\n",
        "        # print(f'Final Output: {chunk[\"output\"]}') \n",
        "        continue\n",
        "    else:\n",
        "        raise ValueError()\n",
        "    print(\"---\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Calling Tool: `Searcher` with input `{'query': 'site:target.com Nespresso coffee machine price'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'site:target.com Keurig coffee machine price'}`\n---\nCalling Tool: `WebFetcher` with input `{'url': 'https://www.target.com/p/nespresso-vertuo-next-coffee-maker-and-espresso-machine-by-delonghi-gray/-/A-79332989'}`\n---\nCalling Tool: `WebFetcher` with input `{'url': 'https://www.target.com/p/keurig-k-mini-single-serve-k-cup-pod-coffee-maker/-/A-53788870'}`\n---\nI encountered an issue accessing the specific product pages on Target's website to provide you with the current prices for the Nespresso and Keurig coffee machines. To find the most accurate and up-to-date prices, I recommend visiting Target's website directly and searching for the Nespresso and Keurig coffee machines. This will allow you to view the range of models available and their respective prices."
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229695668
        }
      },
      "id": "8da312eb-316f-4c76-a52b-eb8fafc178e3"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "71e7ac1e-78bc-465d-89a1-5d9abbad90c9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}