{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Set up variables"
      ],
      "metadata": {},
      "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import urllib\n",
        "import requests\n",
        "import random\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "from IPython.display import display, HTML, Markdown\n",
        "from typing import List\n",
        "from operator import itemgetter\n",
        "\n",
        "# LangChain Imports needed\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
        "#from langchain_core.documents import Document\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "\n",
        "\n",
        "# Our own libraries needed\n",
        "#from common.prompts import DOCSEARCH_PROMPT\n",
        "#from common.utils import get_search_results\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1720105086135
        }
      },
      "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f"
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"what is azure ml for\""
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1720105086359
        }
      },
      "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1720105092182
        }
      },
      "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A gentle intro to chaining LLMs and prompt engineering"
      ],
      "metadata": {},
      "id": "0e7c720e-ece1-45ad-9d01-2dfd15c182bb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step.\n",
        "\n",
        "Azure OpenAI is a type of LLM (provider) that you can use but there are others like Cohere, Huggingface, etc.\n",
        "\n",
        "Chains can be simple (i.e. Generic) or specialized (i.e. Utility).\n",
        "\n",
        "* Generic — A single LLM is the simplest chain. It takes an input prompt and the name of the LLM and then uses the LLM for text generation (i.e. output for the prompt).\n",
        "\n",
        "Here’s an example:"
      ],
      "metadata": {},
      "id": "2bcd7028-5a6c-4296-8c85-4f420d408d69"
    },
    {
      "cell_type": "code",
      "source": [
        "COMPLETION_TOKENS = 2000\n",
        "llm = AzureChatOpenAI(deployment_name=\"gpt-4-0125-Preview\", \n",
        "                      temperature=0.5, \n",
        "                      max_tokens=COMPLETION_TOKENS)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1720105362182
        }
      },
      "id": "13df9247-e784-4e04-9475-55e672efea47"
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = StrOutputParser()\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an assistant that give thorough responses to users.\"),\n",
        "    (\"user\", \"{input}. Give your response in {language}\")\n",
        "])"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1720105392288
        }
      },
      "id": "a3b55adb-6f98-4f15-b67a-9fbba5820560"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The | symbol is similar to a unix pipe operator, which chains together the different components feeds the output from one component as input into the next component."
      ],
      "metadata": {},
      "id": "6417d052-0035-4635-93e8-2bd3ec50d796"
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm | output_parser"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1720105418200
        }
      },
      "id": "77a37e60-a1ef-4750-a1ec-9e4fe5ba07fa"
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"input\": QUESTION, \"language\": \"Spanish\"})"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "'Azure ML (Machine Learning) es una plataforma de computación en la nube ofrecida por Microsoft que permite a los desarrolladores, científicos de datos e investigadores construir, entrenar y desplegar modelos de machine learning de manera rápida y eficiente. Esta plataforma proporciona herramientas y servicios que facilitan el proceso de desarrollo de soluciones de inteligencia artificial, desde la preparación de datos hasta la implementación de modelos en producción.\\n\\nAlgunos de los usos principales de Azure ML incluyen:\\n\\n1. **Desarrollo de modelos de aprendizaje automático**: Permite a los usuarios crear, entrenar y validar modelos utilizando diversos algoritmos y técnicas de aprendizaje supervisado, no supervisado y de refuerzo.\\n\\n2. **Automatización y optimización de modelos**: Ofrece servicios como la búsqueda automática de hiperparámetros y la selección de modelos, lo que ayuda a optimizar el rendimiento de los modelos de manera eficiente.\\n\\n3. **Integración y despliegue**: Facilita la integración de modelos de machine learning en aplicaciones existentes y su despliegue en diversos entornos, como la nube, dispositivos periféricos (edge devices) y aplicaciones móviles.\\n\\n4. **Gestión del ciclo de vida de ML**: Proporciona herramientas para el seguimiento, la gestión y el mantenimiento de modelos a lo largo de todo su ciclo de vida, desde el desarrollo hasta la producción.\\n\\n5. **Trabajo colaborativo**: Permite a equipos de trabajo colaborar eficientemente en proyectos de machine learning, compartiendo experimentos, modelos y conjuntos de datos de forma segura.\\n\\n6. **Escalabilidad y rendimiento**: Azure ML se beneficia de la infraestructura de Azure para ofrecer un rendimiento escalable, lo que significa que los usuarios pueden aumentar o disminuir los recursos según las necesidades de su proyecto, asegurando así una ejecución eficiente y coste-efectiva de los modelos de machine learning.\\n\\nEn resumen, Azure ML es una solución integral para el desarrollo y despliegue de modelos de machine learning, que ayuda a simplificar y acelerar el proceso de creación de soluciones de inteligencia artificial, facilitando a las empresas y a los investigadores la implementación de innovaciones basadas en datos.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720105462129
        }
      },
      "id": "50ea1a39-bea2-4f18-bcc0-bd4eb2e01675"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great!!, now you know how to create a simple prompt and use a chain in order to answer a general question using ChatGPT knowledge!. \n",
        "\n",
        "It is important to note that we rarely use generic chains as standalone chains. More often they are used as building blocks for Utility chains (as we will see next). Also important to notice is that we are NOT using our documents or the result of the Azure Search yet, just the knowledge of ChatGPT on the data it was trained on."
      ],
      "metadata": {},
      "id": "50ed014c-0c6b-448c-b995-fe7970b92ad5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The second type of Chains are Utility:**\n",
        "\n",
        "* Utility — These are specialized chains, comprised of many building blocks to help solve a specific task. For example, LangChain supports some end-to-end chains (such as `create_retrieval_chain` for QnA Doc retrieval, Summarization, etc).\n",
        "\n",
        "We will build our own specific chain in this workshop for digging deeper and solve our use case of enhancing the results of Azure AI Search."
      ],
      "metadata": {
        "tags": []
      },
      "id": "12c48038-b1af-4228-8ffb-720e554fd3b2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "So really, our only job now is to make sure that the results from the Azure AI Search queries fit on the LLM context size, and then let it do its magic."
      ],
      "metadata": {},
      "id": "80e79235-3d8b-4713-9336-5004cc4a1556"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create a Prompt Template that will ground the response only in the given context."
      ],
      "metadata": {},
      "id": "235d4238-df6e-40eb-ab38-4fe6db614acd"
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Answer the question based **ONLY** on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "If the question is different from the context, just tell \"sorry,I can not assist with this query\"\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1720105496305
        }
      },
      "id": "f86ed786-aca0-4e25-947b-d9cf3a82665c"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='Answer the question based **ONLY** on the following context:\\n{context}\\n\\nQuestion: {question}\\nIf the question is different from the context, just tell \"sorry,I can not assist with this query\"\\n'))])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720063771278
        }
      },
      "id": "919edc42-2c25-4407-84d3-e9e86046801e"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "# Creation of our custom chain\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "chain.invoke({\"question\": \"Tell me about Bupa\", \"context\": \"Azure Machine LEarning is E2E ML platform.\"})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 20.8 ms, sys: 1.61 ms, total: 22.4 ms\nWall time: 585 ms\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "'Sorry, I cannot assist with this query.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {},
      "id": "25cba3d1-b5ab-4e28-96b3-ef923d99dc9f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Internet and Websites Search using Bing API"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "f1b94b8f-ea6f-40ee-afd9-2400ac6d5208"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from typing import Dict, List, Optional, Type\n",
        "import asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "from langchain import hub\n",
        "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import BaseTool, StructuredTool, tool\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.agents import AgentExecutor, Tool, create_openai_tools_agent\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.utilities import BingSearchAPIWrapper\n",
        "\n",
        "from common.callbacks import StdOutCallbackHandler\n",
        "from common.prompts import BINGSEARCH_PROMPT\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string.replace(\"$\",\"USD \")))\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720105618376
        }
      },
      "id": "dceab3d9-5a9e-42cb-bc95-68b85c10f1ef"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720105718212
        }
      },
      "id": "2f7c618e-5d5d-4c6d-8fcc-9debf84227d8"
    },
    {
      "cell_type": "code",
      "source": [
        "cb_handler = StdOutCallbackHandler()\n",
        "cb_manager = CallbackManager(handlers=[cb_handler])\n",
        "\n",
        "COMPLETION_TOKENS = 2000\n",
        "\n",
        "llm = AzureChatOpenAI(deployment_name=\"gpt-4-0125-Preview\", \n",
        "                      temperature=0.5, max_tokens=COMPLETION_TOKENS, \n",
        "                      streaming=True, callback_manager=cb_manager)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720105730237
        }
      },
      "id": "f22ed7aa-4e48-4488-b80c-63a35e733b33"
    },
    {
      "cell_type": "code",
      "source": [
        "class SearchInput(BaseModel):\n",
        "    query: str = Field(description=\"should be a search query\")\n",
        "\n",
        "class MyBingSearch(BaseTool):\n",
        "    \"\"\"Tool for a Bing Search Wrapper\"\"\"\n",
        "    \n",
        "    name = \"Searcher\"\n",
        "    description = \"useful to search the internet.\\n\"\n",
        "    args_schema: Type[BaseModel] = SearchInput\n",
        "\n",
        "    k: int = 5\n",
        "    \n",
        "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
        "        bing = BingSearchAPIWrapper(k=self.k)\n",
        "        return bing.results(query,num_results=self.k)\n",
        "            \n",
        "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
        "        bing = BingSearchAPIWrapper(k=self.k)\n",
        "        loop = asyncio.get_event_loop()\n",
        "        results = await loop.run_in_executor(ThreadPoolExecutor(), bing.results, query, self.k)\n",
        "        return results"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720105942308
        }
      },
      "id": "97a3eb01-904b-401a-9f7b-f39aa77d311e"
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_html(content) -> str:\n",
        "    soup = BeautifulSoup(content, 'html.parser')\n",
        "    text_content_with_links = soup.get_text()\n",
        "    return text_content_with_links\n",
        "\n",
        "def fetch_web_page(url: str) -> str:\n",
        "    HEADERS = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:90.0) Gecko/20100101 Firefox/90.0'}\n",
        "    response = requests.get(url, headers=HEADERS)\n",
        "    return parse_html(response.content)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720105942474
        }
      },
      "id": "f3a9dd6f-0762-40a9-b212-a9f7138ab64b"
    },
    {
      "cell_type": "code",
      "source": [
        "web_fetch_tool = Tool.from_function(\n",
        "    func=fetch_web_page,\n",
        "    name=\"WebFetcher\",\n",
        "    description=\"useful to fetch the content of a url\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720105944149
        }
      },
      "id": "2d9d6efb-ee00-4271-9282-1a513185dd1e"
    },
    {
      "cell_type": "code",
      "source": [
        "# tools = [MyBingSearch(k=5), web_fetch_tool] # With GPT-4 you can add the web_fetch_tool\n",
        "\n",
        "tools = [MyBingSearch(k=5)] # With GPT-3.5 \n",
        "\n",
        "prompt = BINGSEARCH_PROMPT\n",
        "\n",
        "# Construct the OpenAI Tools agent\n",
        "agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "\n",
        "# Create an agent executor by passing in the agent and tools\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False, \n",
        "                               return_intermediate_steps=True)"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720105944351
        }
      },
      "id": "23aab0bd-11f2-4318-8e10-33469e37c945"
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.tools"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "[MyBingSearch()]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720105950219
        }
      },
      "id": "e0bc94fb-85d1-444c-9097-6fce420b4e85"
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION = \"Create a list with the main facts on What is happening with the oil supply in the world right now?\"\n",
        "# QUESTION = \"How much is 50 USD in Euros and is it enough for an average hotel in Madrid?\"\n",
        "# QUESTION = \"My son needs to build a pinewood car for a pinewood derbi, how do I build such a car?\"\n",
        "# QUESTION = \"I'm planning a vacation to Greece, tell me budget for a family of 4, in Summer, for 7 days including travel, lodging and food costs\"\n",
        "# QUESTION = \"Who won the 2023 superbowl and who was the MVP?\"\n",
        "QUESTION = \"\"\"\n",
        "compare the number of job opennings (provide the exact number), the average salary within 15 miles of Dallas, TX, for these ocupations:\n",
        "\n",
        "- ADN Registerd Nurse \n",
        "- Occupational therapist assistant\n",
        "- Dental Hygienist\n",
        "- Graphic Designer\n",
        "\n",
        "\n",
        "# Create a table with your findings. Place the sources on each cell.\n",
        "# \"\"\""
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720105968458
        }
      },
      "id": "890b4270-834a-499d-907c-c4396de4bc99"
    },
    {
      "cell_type": "code",
      "source": [
        "async for chunk in agent_executor.astream({\"question\": QUESTION}):\n",
        "    # Agent Action\n",
        "    if \"actions\" in chunk:\n",
        "        for action in chunk[\"actions\"]:\n",
        "            print(f\"Calling Tool: `{action.tool}` with input `{action.tool_input}`\")\n",
        "    # Observation\n",
        "    elif \"steps\" in chunk:\n",
        "        # Uncomment if you need to have the information retrieve from the tool\n",
        "        # for step in chunk[\"steps\"]:\n",
        "        #     print(f\"Tool Result: `{step.observation}`\")\n",
        "        continue\n",
        "    # Final result\n",
        "    elif \"output\" in chunk:\n",
        "        # No need to print the final output again since we would be streaming it as it is produced\n",
        "        # print(f'Final Output: {chunk[\"output\"]}') \n",
        "        continue\n",
        "    else:\n",
        "        raise ValueError()\n",
        "    print(\"---\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Calling Tool: `Searcher` with input `{'query': 'ADN Registered Nurse job openings in Dallas, TX'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'ADN Registered Nurse average salary within 15 miles of Dallas, TX'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'Occupational therapist assistant job openings in Dallas, TX'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'Occupational therapist assistant average salary within 15 miles of Dallas, TX'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'Dental Hygienist job openings in Dallas, TX'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'Dental Hygienist average salary within 15 miles of Dallas, TX'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'Graphic Designer job openings in Dallas, TX'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'Graphic Designer average salary within 15 miles of Dallas, TX'}`\n---\n"
        },
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "429 Client Error: Too Many Requests for url: https://api.bing.microsoft.com/v7.0/search?q=ADN+Registered+Nurse+average+salary+within+15+miles+of+Dallas%2C+TX&count=5&textDecorations=True&textFormat=HTML",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m agent_executor\u001b[38;5;241m.\u001b[39mastream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: QUESTION}):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Agent Action\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m chunk:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m chunk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/langchain/agents/agent.py:1592\u001b[0m, in \u001b[0;36mAgentExecutor.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m   1582\u001b[0m iterator \u001b[38;5;241m=\u001b[39m AgentExecutorIterator(\n\u001b[1;32m   1583\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1591\u001b[0m )\n\u001b[0;32m-> 1592\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m   1593\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m step\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/langchain/agents/agent_iterator.py:240\u001b[0m, in \u001b[0;36mAgentExecutorIterator.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39m_should_continue(\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_elapsed\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# take the next step: this plans next action, executes it,\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# yielding action and observation as they are generated\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     next_step_seq: NextStepOutput \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39m_aiter_next_step(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_to_tool_map,\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolor_mapping,\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs,\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_steps,\n\u001b[1;32m    245\u001b[0m         run_manager,\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         next_step_seq\u001b[38;5;241m.\u001b[39mappend(chunk)\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;66;03m# if we're yielding actions, yield them as they come\u001b[39;00m\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;66;03m# do not yield AgentFinish, which will be handled below\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/langchain/agents/agent.py:1359\u001b[0m, in \u001b[0;36mAgentExecutor._aiter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;66;03m# Use asyncio.gather to run multiple tool.arun() calls concurrently\u001b[39;00m\n\u001b[0;32m-> 1359\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m   1360\u001b[0m     \u001b[38;5;241m*\u001b[39m[\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aperform_agent_action(\n\u001b[1;32m   1362\u001b[0m             name_to_tool_map, color_mapping, agent_action, run_manager\n\u001b[1;32m   1363\u001b[0m         )\n\u001b[1;32m   1364\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions\n\u001b[1;32m   1365\u001b[0m     ],\n\u001b[1;32m   1366\u001b[0m )\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;66;03m# TODO This could yield each result as it becomes available\u001b[39;00m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m result:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/langchain/agents/agent.py:1392\u001b[0m, in \u001b[0;36mAgentExecutor._aperform_agent_action\u001b[0;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[1;32m   1390\u001b[0m         tool_run_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m-> 1392\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m tool\u001b[38;5;241m.\u001b[39marun(\n\u001b[1;32m   1393\u001b[0m         agent_action\u001b[38;5;241m.\u001b[39mtool_input,\n\u001b[1;32m   1394\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m   1395\u001b[0m         color\u001b[38;5;241m=\u001b[39mcolor,\n\u001b[1;32m   1396\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1397\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_run_kwargs,\n\u001b[1;32m   1398\u001b[0m     )\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1400\u001b[0m     tool_run_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mtool_run_logging_kwargs()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/langchain_core/tools.py:557\u001b[0m, in \u001b[0;36mBaseTool.arun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e)\n\u001b[0;32m--> 557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(\n\u001b[1;32m    560\u001b[0m         observation, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    561\u001b[0m     )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/langchain_core/tools.py:516\u001b[0m, in \u001b[0;36mBaseTool.arun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m         observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(coro, context\u001b[38;5;241m=\u001b[39mcontext)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m         observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_validation_error:\n",
            "Cell \u001b[0;32mIn[16], line 20\u001b[0m, in \u001b[0;36mMyBingSearch._arun\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m     18\u001b[0m bing \u001b[38;5;241m=\u001b[39m BingSearchAPIWrapper(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk)\n\u001b[1;32m     19\u001b[0m loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[0;32m---> 20\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mrun_in_executor(ThreadPoolExecutor(), bing\u001b[38;5;241m.\u001b[39mresults, query, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/langchain_community/utilities/bing_search.py:95\u001b[0m, in \u001b[0;36mBingSearchAPIWrapper.results\u001b[0;34m(self, query, num_results)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run query through BingSearch and return metadata.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m        link - The link to the result.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m metadata_results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 95\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bing_search_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo good Bing Search Result was found\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/langchain_community/utilities/bing_search.py:45\u001b[0m, in \u001b[0;36mBingSearchAPIWrapper._bing_search_results\u001b[0;34m(self, search_term, count)\u001b[0m\n\u001b[1;32m     33\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m: search_term,\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m: count,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs,\n\u001b[1;32m     39\u001b[0m }\n\u001b[1;32m     40\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbing_search_url,\n\u001b[1;32m     42\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m     43\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     44\u001b[0m )\n\u001b[0;32m---> 45\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m search_results \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwebPages\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m search_results:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[0;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://api.bing.microsoft.com/v7.0/search?q=ADN+Registered+Nurse+average+salary+within+15+miles+of+Dallas%2C+TX&count=5&textDecorations=True&textFormat=HTML"
          ]
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720106052068
        }
      },
      "id": "384faabb-2de3-4283-98f8-e1d828987114"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Without showing the intermedite steps, just the final answer"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "7dd531cb-a5dc-47e4-ae73-f7c83282a52d"
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"How much is 50 USD in Euros and is it enough for an average hotel in Madrid?\"\n",
        "\n",
        "try:\n",
        "    response = agent_executor.invoke({\"question\":QUESTION})\n",
        "except Exception as e:\n",
        "    response = str(e)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "50 USD is equivalent to approximately 46.68 Euros at the current exchange rate [[1]](https://www.xe.com/en/currencyconverter/convert/?Amount=50&From=USD&To=EUR).\n\nRegarding the cost of an average hotel in Madrid, the prices can vary significantly. The average price of accommodation in hotels and similar lodging establishments in Madrid amounted to 169 euros in February 2024 [[2]](https://www.statista.com/statistics/614059/overnight-accommodation-costs-madrid-city/). However, for budget hotels, prices can range from approximately 30 to 70 euros per night, offering basic amenities like free Wi-Fi and breakfast [[3]](https://luxurytraveldiva.com/how-much-does-a-hotel-cost-in-madrid-spain/).\n\nGiven this information, 50 USD (approximately 46.68 Euros) would not be enough for an average hotel in Madrid, especially considering the average price of 169 euros for standard accommodations. However, it might contribute towards a night in a budget hotel, depending on the specific rates and availability during your intended travel period."
        }
      ],
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720063939334
        }
      },
      "id": "629d26b3-00f3-41dd-8576-84b18a48b381"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "printmd(response[\"output\"])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "50 USD is equivalent to approximately 46.68 Euros at the current exchange rate [[1]](https://www.xe.com/en/currencyconverter/convert/?Amount=50&From=USD&To=EUR).\n\nRegarding the cost of an average hotel in Madrid, the prices can vary significantly. The average price of accommodation in hotels and similar lodging establishments in Madrid amounted to 169 euros in February 2024 [[2]](https://www.statista.com/statistics/614059/overnight-accommodation-costs-madrid-city/). However, for budget hotels, prices can range from approximately 30 to 70 euros per night, offering basic amenities like free Wi-Fi and breakfast [[3]](https://luxurytraveldiva.com/how-much-does-a-hotel-cost-in-madrid-spain/).\n\nGiven this information, 50 USD (approximately 46.68 Euros) would not be enough for an average hotel in Madrid, especially considering the average price of 169 euros for standard accommodations. However, it might contribute towards a night in a budget hotel, depending on the specific rates and availability during your intended travel period."
          },
          "metadata": {}
        }
      ],
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720064015358
        }
      },
      "id": "8786a3ad-430e-4abc-8751-c38d8fe3716d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QnA to specific websites\n",
        "\n",
        "There are several use cases where we want the smart bot to answer questions about a specific company's public website. There are two approaches we can take:\n",
        "\n",
        "1. Create a crawler script that runs regularly, finds every page on the website, and pushes the documents to Azure Cognitive Search.\n",
        "2. Since Bing has likely already indexed the public website, we can utilize Bing search targeted specifically to that site, rather than attempting to index the site ourselves and duplicate the work already done by Bing's crawler.\n",
        "\n",
        "Below are some sample questions related to specific sites. Take a look:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "58848313-e475-4e07-aa20-5b58dbb73676"
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION = \"information on how to kill wasps in homedepot.com\"\n",
        "QUESTION = \"in target.com, find how what's the price of a Nesspresso coffee machine and of a Keurig coffee machine\"\n",
        "# QUESTION = \"in microsoft.com, find out what is the latests news on quantum computing\"\n",
        "# QUESTION = \"give me on a list the main points on the latest investor report from mondelezinternational.com\""
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720064083330
        }
      },
      "id": "80631275-d9e4-49b6-b786-fdb6e94723db"
    },
    {
      "cell_type": "code",
      "source": [
        "async for chunk in agent_executor.astream({\"question\": QUESTION}):\n",
        "    # Agent Action\n",
        "    if \"actions\" in chunk:\n",
        "        for action in chunk[\"actions\"]:\n",
        "            print(f\"Calling Tool: `{action.tool}` with input `{action.tool_input}`\")\n",
        "    # Observation\n",
        "    elif \"steps\" in chunk:\n",
        "        # Uncomment if you need to have the information retrieve from the tool\n",
        "        # for step in chunk[\"steps\"]:\n",
        "        #     print(f\"Tool Result: `{step.observation}`\")\n",
        "        continue\n",
        "    # Final result\n",
        "    elif \"output\" in chunk:\n",
        "        # No need to print the final output again since we would be streaming it as it is produced\n",
        "        # print(f'Final Output: {chunk[\"output\"]}') \n",
        "        continue\n",
        "    else:\n",
        "        raise ValueError()\n",
        "    print(\"---\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Calling Tool: `Searcher` with input `{'query': 'site:target.com Nespresso coffee machine price'}`\n---\nCalling Tool: `Searcher` with input `{'query': 'site:target.com Keurig coffee machine price'}`\n---\nBased on the search results from Target's website, here are the prices for Nespresso and Keurig coffee machines:\n\n### Nespresso Coffee Machines:\n- **Nespresso Vertuo Next Coffee Maker and Espresso Machine by De'Longhi, Gray** is available but the price is not listed in the snippet. For the most accurate price, please visit the [product page](https://www.target.com/p/nespresso-vertuo-next-coffee-maker-and-espresso-machine-by-delonghi-gray/-/A-79332989).\n- **Nespresso VertuoPlus Coffee Maker and Espresso Machine by De'Longhi, Black Matte** is also available with detailed information on the website but no price mentioned in the snippet. Check the [product page](https://www.target.com/p/nespresso-vertuoplus-coffee-maker-and-espresso-machine-by-delonghi-black-matte/-/A-54498718) for the latest price.\n- **Nespresso Vertuo Pop+ Coffee Machine with Aeroccino Frother by De'Longhi, Liquorice Black** is priced at **USD 129.99**. Another variant, **Nespresso Vertuo Next Coffee Maker And Espresso Machine by Breville, Red**, is priced at **USD 249.99**. For more details, visit the [product page](https://www.target.com/p/nespresso-vertuo-next-coffee-maker-and-espresso-machine-by-breville-red/-/A-85896429).\n\n### Keurig Coffee Machines:\n- **Keurig K-Express Coffee Maker - Black** is listed with a price of **USD 69.99**. For more information, you can visit the [product page](https://www.target.com/s/keurig+coffee+maker+deals).\n- **Keurig K-Café SMART Single-Serve Coffee Maker with WiFi Compatibility, 6 Brew Sizes - Black** is available for **USD 199.99**. For further details, check the [product page](https://www.target.com/s/coffee+makers+keurig).\n\nPlease note that prices and availability are subject to change, and it's always a good idea to check the provided links for the most current information."
        }
      ],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720064117478
        }
      },
      "id": "8da312eb-316f-4c76-a52b-eb8fafc178e3"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "71e7ac1e-78bc-465d-89a1-5d9abbad90c9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}