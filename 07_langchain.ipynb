{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Set up variables"
      ],
      "metadata": {},
      "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install openai bs4 langchain langchain-openai langchainhub langchain-community"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "a49a41b3-dfa7-41df-9c1a-983bdfb04ada"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import urllib\n",
        "import requests\n",
        "import random\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "from IPython.display import display, HTML, Markdown\n",
        "from typing import List\n",
        "from operator import itemgetter\n",
        "\n",
        "# LangChain Imports needed\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
        "#from langchain_core.documents import Document\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "\n",
        "\n",
        "# Our own libraries needed\n",
        "#from common.prompts import DOCSEARCH_PROMPT\n",
        "#from common.utils import get_search_results\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1733330921838
        }
      },
      "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f"
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"what is azure ml for\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1733330922100
        }
      },
      "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1733330922317
        }
      },
      "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A gentle intro to chaining LLMs and prompt engineering"
      ],
      "metadata": {},
      "id": "0e7c720e-ece1-45ad-9d01-2dfd15c182bb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step.\n",
        "\n",
        "Azure OpenAI is a type of LLM (provider) that you can use but there are others like Cohere, Huggingface, etc.\n",
        "\n",
        "Chains can be simple (i.e. Generic) or specialized (i.e. Utility).\n",
        "\n",
        "* Generic — A single LLM is the simplest chain. It takes an input prompt and the name of the LLM and then uses the LLM for text generation (i.e. output for the prompt).\n",
        "\n",
        "Here’s an example:"
      ],
      "metadata": {},
      "id": "2bcd7028-5a6c-4296-8c85-4f420d408d69"
    },
    {
      "cell_type": "code",
      "source": [
        "COMPLETION_TOKENS = 2000\n",
        "llm = AzureChatOpenAI(deployment_name=\"gpt-4o-mini\", \n",
        "                      temperature=0.5, \n",
        "                      max_tokens=COMPLETION_TOKENS)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1733330922527
        }
      },
      "id": "13df9247-e784-4e04-9475-55e672efea47"
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = StrOutputParser()\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an assistant that give thorough responses to users.\"),\n",
        "    (\"user\", \"{input}. Give your response in {language}\")\n",
        "])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1733330922760
        }
      },
      "id": "a3b55adb-6f98-4f15-b67a-9fbba5820560"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The | symbol is similar to a unix pipe operator, which chains together the different components feeds the output from one component as input into the next component."
      ],
      "metadata": {},
      "id": "6417d052-0035-4635-93e8-2bd3ec50d796"
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm | output_parser"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1733330922978
        }
      },
      "id": "77a37e60-a1ef-4750-a1ec-9e4fe5ba07fa"
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"input\": QUESTION, \"language\": \"French\"})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330928070
        }
      },
      "id": "50ea1a39-bea2-4f18-bcc0-bd4eb2e01675"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great!!, now you know how to create a simple prompt and use a chain in order to answer a general question using ChatGPT knowledge!. \n",
        "\n",
        "It is important to note that we rarely use generic chains as standalone chains. More often they are used as building blocks for Utility chains (as we will see next). Also important to notice is that we are NOT using our documents or the result of the Azure Search yet, just the knowledge of ChatGPT on the data it was trained on."
      ],
      "metadata": {},
      "id": "50ed014c-0c6b-448c-b995-fe7970b92ad5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The second type of Chains are Utility:**\n",
        "\n",
        "* Utility — These are specialized chains, comprised of many building blocks to help solve a specific task. For example, LangChain supports some end-to-end chains (such as `create_retrieval_chain` for QnA Doc retrieval, Summarization, etc).\n",
        "\n",
        "We will build our own specific chain in this workshop for digging deeper and solve our use case of enhancing the results of Azure AI Search."
      ],
      "metadata": {
        "tags": []
      },
      "id": "12c48038-b1af-4228-8ffb-720e554fd3b2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "So really, our only job now is to make sure that the results from the Azure AI Search queries fit on the LLM context size, and then let it do its magic."
      ],
      "metadata": {},
      "id": "80e79235-3d8b-4713-9336-5004cc4a1556"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create a Prompt Template that will ground the response only in the given context."
      ],
      "metadata": {},
      "id": "235d4238-df6e-40eb-ab38-4fe6db614acd"
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Answer the question based **ONLY** on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "If the question is different from the context, just tell \"sorry,I can not assist with this query\"\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1733330928317
        }
      },
      "id": "f86ed786-aca0-4e25-947b-d9cf3a82665c"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330928534
        }
      },
      "id": "919edc42-2c25-4407-84d3-e9e86046801e"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "# Creation of our custom chain\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "chain.invoke({\"question\": \"Tell me about Nationwide Building Society\", \"context\": \"Azure Machine Learning is E2E ML platform.\"})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "25cba3d1-b5ab-4e28-96b3-ef923d99dc9f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Internet and Websites Search using Bing API"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "f1b94b8f-ea6f-40ee-afd9-2400ac6d5208"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from typing import Dict, List, Optional, Type\n",
        "import asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "from langchain import hub\n",
        "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
        "# from langchain.pydantic_v1 import BaseModel, Field\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.tools import BaseTool, StructuredTool, tool\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.agents import AgentExecutor, Tool, create_openai_tools_agent\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "#from langchain.utilities import BingSearchAPIWrapper\n",
        "from langchain_community.utilities import BingSearchAPIWrapper\n",
        "\n",
        "from common.callbacks import StdOutCallbackHandler\n",
        "from common.prompts import BINGSEARCH_PROMPT\n",
        "\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string.replace(\"$\",\"USD \")))\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330928987
        }
      },
      "id": "dceab3d9-5a9e-42cb-bc95-68b85c10f1ef"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330929244
        }
      },
      "id": "2f7c618e-5d5d-4c6d-8fcc-9debf84227d8"
    },
    {
      "cell_type": "code",
      "source": [
        "cb_handler = StdOutCallbackHandler()\n",
        "cb_manager = CallbackManager(handlers=[cb_handler])\n",
        "\n",
        "COMPLETION_TOKENS = 2000\n",
        "\n",
        "llm = AzureChatOpenAI(deployment_name=\"gpt-4o-mini\", \n",
        "                      temperature=0.5, max_tokens=COMPLETION_TOKENS, \n",
        "                      streaming=True, callback_manager=cb_manager)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330929483
        }
      },
      "id": "f22ed7aa-4e48-4488-b80c-63a35e733b33"
    },
    {
      "cell_type": "code",
      "source": [
        "class SearchInput(BaseModel):\n",
        "    query: str = Field(description=\"should be a search query\")\n",
        "\n",
        "class MyBingSearch(BaseTool):\n",
        "    \"\"\"Tool for a Bing Search Wrapper\"\"\"\n",
        "    args_schema: Type[BaseModel] = SearchInput\n",
        "\n",
        "    k: int = 5\n",
        "    \n",
        "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
        "        bing = BingSearchAPIWrapper(k=self.k)\n",
        "        return bing.results(query,num_results=self.k)\n",
        "            \n",
        "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
        "        bing = BingSearchAPIWrapper(k=self.k)\n",
        "        loop = asyncio.get_event_loop()\n",
        "        results = await loop.run_in_executor(ThreadPoolExecutor(), bing.results, query, self.k)\n",
        "        return results"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330929750
        }
      },
      "id": "97a3eb01-904b-401a-9f7b-f39aa77d311e"
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_html(content) -> str:\n",
        "    soup = BeautifulSoup(content, 'html.parser')\n",
        "    text_content_with_links = soup.get_text()\n",
        "    return text_content_with_links\n",
        "\n",
        "def fetch_web_page(url: str) -> str:\n",
        "    HEADERS = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:90.0) Gecko/20100101 Firefox/90.0'}\n",
        "    response = requests.get(url, headers=HEADERS)\n",
        "    return parse_html(response.content)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330930000
        }
      },
      "id": "f3a9dd6f-0762-40a9-b212-a9f7138ab64b"
    },
    {
      "cell_type": "code",
      "source": [
        "web_fetch_tool = Tool.from_function(\n",
        "    func=fetch_web_page,\n",
        "    name=\"WebFetcher\",\n",
        "    description=\"useful to fetch the content of a url\"\n",
        ")\n",
        "\n",
        "MyBingSearch = MyBingSearch(k=5, name=\"Searcher\", description=\"useful to search the internet.\\n\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330930255
        }
      },
      "id": "2d9d6efb-ee00-4271-9282-1a513185dd1e"
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [MyBingSearch, web_fetch_tool] # With GPT-4 you can add the web_fetch_tool\n",
        "\n",
        "# tools = [MyBingSearch] # With GPT-3.5 \n",
        "\n",
        "prompt = BINGSEARCH_PROMPT\n",
        "\n",
        "# Construct the OpenAI Tools agent\n",
        "agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "\n",
        "# Create an agent executor by passing in the agent and tools\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False, \n",
        "                               return_intermediate_steps=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330930533
        }
      },
      "id": "23aab0bd-11f2-4318-8e10-33469e37c945"
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.tools"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330930779
        }
      },
      "id": "e0bc94fb-85d1-444c-9097-6fce420b4e85"
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION = \"Create a list with the main facts on What is happening with the oil supply in the world right now?\"\n",
        "# QUESTION = \"How much is 50 USD in Euros and is it enough for an average hotel in Madrid?\"\n",
        "# QUESTION = \"My son needs to build a pinewood car for a pinewood derbi, how do I build such a car?\"\n",
        "# QUESTION = \"I'm planning a vacation to Greece, tell me budget for a family of 4, in Summer, for 7 days including travel, lodging and food costs\"\n",
        "# QUESTION = \"Who won the 2023 superbowl and who was the MVP?\"\n",
        "QUESTION = \"\"\"\n",
        "compare the number of job opennings (provide the exact number), the average salary within 15 miles of Dallas, TX, for these ocupations:\n",
        "\n",
        "- ADN Registerd Nurse \n",
        "- Occupational therapist assistant\n",
        "- Dental Hygienist\n",
        "- Graphic Designer\n",
        "\n",
        "\n",
        "# Create a table with your findings. Place the sources on each cell.\n",
        "# \"\"\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330931021
        }
      },
      "id": "890b4270-834a-499d-907c-c4396de4bc99"
    },
    {
      "cell_type": "code",
      "source": [
        "async for chunk in agent_executor.astream({\"question\": QUESTION}):\n",
        "    # Agent Action\n",
        "    if \"actions\" in chunk:\n",
        "        for action in chunk[\"actions\"]:\n",
        "            print(f\"Calling Tool: `{action.tool}` with input `{action.tool_input}`\")\n",
        "    # Observation\n",
        "    elif \"steps\" in chunk:\n",
        "        # Uncomment if you need to have the information retrieve from the tool\n",
        "        # for step in chunk[\"steps\"]:\n",
        "        #     print(f\"Tool Result: `{step.observation}`\")\n",
        "        continue\n",
        "    # Final result\n",
        "    elif \"output\" in chunk:\n",
        "        # No need to print the final output again since we would be streaming it as it is produced\n",
        "        # print(f'Final Output: {chunk[\"output\"]}') \n",
        "        continue\n",
        "    else:\n",
        "        raise ValueError()\n",
        "    print(\"---\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330938406
        }
      },
      "id": "384faabb-2de3-4283-98f8-e1d828987114"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Without showing the intermedite steps, just the final answer"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "7dd531cb-a5dc-47e4-ae73-f7c83282a52d"
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"How much is 50 USD in Euros and is it enough for an average hotel in Madrid?\"\n",
        "\n",
        "try:\n",
        "    response = agent_executor.invoke({\"question\":QUESTION})\n",
        "except Exception as e:\n",
        "    response = str(e)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330948213
        }
      },
      "id": "629d26b3-00f3-41dd-8576-84b18a48b381"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "printmd(response[\"output\"])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330948562
        }
      },
      "id": "8786a3ad-430e-4abc-8751-c38d8fe3716d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QnA to specific websites\n",
        "\n",
        "There are several use cases where we want the smart bot to answer questions about a specific company's public website. There are two approaches we can take:\n",
        "\n",
        "1. Create a crawler script that runs regularly, finds every page on the website, and pushes the documents to Azure Cognitive Search.\n",
        "2. Since Bing has likely already indexed the public website, we can utilize Bing search targeted specifically to that site, rather than attempting to index the site ourselves and duplicate the work already done by Bing's crawler.\n",
        "\n",
        "Below are some sample questions related to specific sites. Take a look:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "58848313-e475-4e07-aa20-5b58dbb73676"
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION = \"information on how to kill wasps in homedepot.com\"\n",
        "QUESTION = \"in target.com, find how what's the price of a Nesspresso coffee machine and of a Keurig coffee machine\"\n",
        "# QUESTION = \"in microsoft.com, find out what is the latests news on quantum computing\"\n",
        "# QUESTION = \"give me on a list the main points on the latest investor report from mondelezinternational.com\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330948857
        }
      },
      "id": "80631275-d9e4-49b6-b786-fdb6e94723db"
    },
    {
      "cell_type": "code",
      "source": [
        "async for chunk in agent_executor.astream({\"question\": QUESTION}):\n",
        "    # Agent Action\n",
        "    if \"actions\" in chunk:\n",
        "        for action in chunk[\"actions\"]:\n",
        "            print(f\"Calling Tool: `{action.tool}` with input `{action.tool_input}`\")\n",
        "    # Observation\n",
        "    elif \"steps\" in chunk:\n",
        "        # Uncomment if you need to have the information retrieve from the tool\n",
        "        # for step in chunk[\"steps\"]:\n",
        "        #     print(f\"Tool Result: `{step.observation}`\")\n",
        "        continue\n",
        "    # Final result\n",
        "    elif \"output\" in chunk:\n",
        "        # No need to print the final output again since we would be streaming it as it is produced\n",
        "        # print(f'Final Output: {chunk[\"output\"]}') \n",
        "        continue\n",
        "    else:\n",
        "        raise ValueError()\n",
        "    print(\"---\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733330958078
        }
      },
      "id": "8da312eb-316f-4c76-a52b-eb8fafc178e3"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "71e7ac1e-78bc-465d-89a1-5d9abbad90c9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
