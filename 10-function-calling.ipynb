{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "import os \n",
        "from azure.identity import ManagedIdentityCredential\n",
        "\n",
        "default_credential=ManagedIdentityCredential(client_id=\"d30cba06-04c1-4065-a91d-8b7ce3b07b78\")\n",
        "token=default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "Resource_endpoint=\"https://openaiykus.openai.azure.com/\"\n",
        "\n",
        "client = AzureOpenAI(\n",
        "  azure_endpoint = Resource_endpoint, \n",
        "  api_key=token.token,  \n",
        "  api_version=\"2023-07-01-preview\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1700444501380
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Test Function Calling"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_function_call(messages, function_call = \"auto\"):\n",
        "    # Define the functions to use\n",
        "    functions = [\n",
        "        {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                    },\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    # Call the model with the user query (messages) and the functions defined in the functions parameter\n",
        "    response = client.chat.completions.create(\n",
        "    model=\"gpt-4-32k\", # model = \"deployment_name\".\n",
        "    messages=messages,\n",
        "    functions=functions,\n",
        "    function_call=function_call)\n",
        "\n",
        "\n",
        "    return response.model_dump_json(indent=2)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700444505416
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_message = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco?\"}]\n",
        "# 'auto' : Let the model decide what function to call\n",
        "print(\"Let the model decide what function to call:\")\n",
        "print (get_function_call(first_message, \"auto\"))\n",
        "\n",
        "# 'none' : Don't call any function \n",
        "print(\"Don't call any function:\")\n",
        "print (get_function_call(first_message, \"none\"))\n",
        "\n",
        "# force a specific function call\n",
        "print(\"Force a specific function call:\")\n",
        "print (get_function_call(first_message, function_call={\"name\": \"get_current_weather\"}))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Let the model decide what function to call:\n{\n  \"id\": \"chatcmpl-8MnaI7dFwjoBhQ0Adhz6KJG4xjMq5\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"function_call\",\n      \"index\": 0,\n      \"message\": {\n        \"content\": null,\n        \"role\": \"assistant\",\n        \"function_call\": {\n          \"arguments\": \"{\\n  \\\"location\\\": \\\"San Francisco, CA\\\"\\n}\",\n          \"name\": \"get_current_weather\"\n        },\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {}\n    }\n  ],\n  \"created\": 1700444510,\n  \"model\": \"gpt-4-32k\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 19,\n    \"prompt_tokens\": 83,\n    \"total_tokens\": 102\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\nDon't call any function:\n{\n  \"id\": \"chatcmpl-8MnaJ0yyBR36VPR8T79OFSj9ZAyNM\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"message\": {\n        \"content\": \"Sure, let me check that for you.\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1700444511,\n  \"model\": \"gpt-4-32k\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 9,\n    \"prompt_tokens\": 84,\n    \"total_tokens\": 93\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\nForce a specific function call:\n{\n  \"id\": \"chatcmpl-8MnaKQ9vn3E1UjXeB6ql9nSNJA24V\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"message\": {\n        \"content\": null,\n        \"role\": \"assistant\",\n        \"function_call\": {\n          \"arguments\": \"{\\n  \\\"location\\\": \\\"San Francisco\\\"\\n}\",\n          \"name\": \"get_current_weather\"\n        },\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {}\n    }\n  ],\n  \"created\": 1700444512,\n  \"model\": \"gpt-4-32k\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 10,\n    \"prompt_tokens\": 90,\n    \"total_tokens\": 100\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700444511785
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Define Functions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytz\n",
        "from datetime import datetime\n",
        "\n",
        "def get_current_time(location):\n",
        "    try:\n",
        "        # Get the timezone for the city\n",
        "        timezone = pytz.timezone(location)\n",
        "\n",
        "        # Get the current time in the timezone\n",
        "        now = datetime.now(timezone)\n",
        "        current_time = now.strftime(\"%I:%M:%S %p\")\n",
        "\n",
        "        return current_time\n",
        "    except:\n",
        "        return \"Sorry, I couldn't find the timezone for that location.\""
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700444541381
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_current_time(\"America/New_York\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "'08:42:24 PM'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700444543425
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Call a Function using AOAI"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Describe the functions so that the model knows how to call them"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "functions = [\n",
        "        {\n",
        "            \"name\": \"get_current_time\",\n",
        "            \"description\": \"Get the current time in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The location name. The pytz is used to get the timezone for that location. Location names should be in a format like America/New_York, Asia/Bangkok, Europe/London\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        }\n",
        "    ]\n",
        "\n",
        "available_functions = {\n",
        "            \"get_current_time\": get_current_time\n",
        "        } "
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700444551382
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Define a helper function to validate the function call"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "\n",
        "# helper method used to check if the correct arguments are provided to a function\n",
        "def check_args(function, args):\n",
        "    sig = inspect.signature(function)\n",
        "    params = sig.parameters\n",
        "\n",
        "    # Check if there are extra arguments\n",
        "    for name in args:\n",
        "        if name not in params:\n",
        "            return False\n",
        "    # Check if the required arguments are provided \n",
        "    for name, param in params.items():\n",
        "        if param.default is param.empty and name not in args:\n",
        "            return False\n",
        "\n",
        "    return True"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700444559399
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700444563709
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4-32k\", # model = \"deployment_name\".\n",
        "    messages=first_message,\n",
        "    functions=functions,\n",
        "    function_call=\"auto\")\n",
        "\n",
        "\n",
        "response_message = response.choices[0].message\n",
        "print(response_message)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ChatCompletionMessage(content=\"I'm sorry, I don't have a function to fetch live weather data. Is there anything else you would like to ask?\", role='assistant', function_call=None, tool_calls=None)\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700444943294
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_conversation(messages, functions, available_functions, deployment_id):\n",
        "    # Step 1: send the conversation and available functions to GPT\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "    model=\"gpt-4-32k\", # model = \"deployment_name\".\n",
        "    messages=messages,\n",
        "    functions=functions,\n",
        "    function_call=\"auto\")\n",
        "\n",
        "\n",
        "    response_message = response.choices[0].message\n",
        "\n",
        "\n",
        "    # Step 2: check if GPT wanted to call a function\n",
        "    if response_message.function_call:\n",
        "        print(\"Recommended Function call:\")\n",
        "        print(response_message.function_call)\n",
        "        print()\n",
        "        \n",
        "        # Step 3: call the function\n",
        "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
        "        \n",
        "        function_name = response_message.function_call.name\n",
        "        \n",
        "        # verify function exists\n",
        "        if function_name not in available_functions:\n",
        "            return \"Function \" + function_name + \" does not exist\"\n",
        "        function_to_call = available_functions[function_name]  \n",
        "        \n",
        "        # verify function has correct number of arguments\n",
        "        function_args = json.loads(response_message.function_call.arguments)\n",
        "        if check_args(function_to_call, function_args) is False:\n",
        "            return \"Invalid number of arguments for function: \" + function_name\n",
        "        function_response = function_to_call(**function_args)\n",
        "        \n",
        "        print(\"Output of function call:\")\n",
        "        print(function_response)\n",
        "        print()\n",
        "        \n",
        "        # Step 4: send the info on the function call and function response to GPT\n",
        "        \n",
        "        # adding assistant response to messages\n",
        "        messages.append(\n",
        "            {\n",
        "                \"role\": response_message.role,\n",
        "                \"name\": response_message.function_call.name,\n",
        "                \"content\": response_message.function_call.arguments,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # adding function response to messages\n",
        "        messages.append(\n",
        "            {\n",
        "                \"role\": \"function\",\n",
        "                \"name\": function_name,\n",
        "                \"content\": function_response,\n",
        "            }\n",
        "        )  # extend conversation with function response\n",
        "\n",
        "        print(\"Messages in second request:\")\n",
        "        for message in messages:\n",
        "            print(message)\n",
        "        print()\n",
        "\n",
        "        # get a new response from GPT where it can see the function response\n",
        "        second_response = client.chat.completions.create(\n",
        "        model=\"gpt-4-32k\", # model = \"deployment_name\".\n",
        "        messages=messages,\n",
        "        )\n",
        "        return second_response.choices[0].message.content"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700445351864
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What time is it in New York?\"}]\n",
        "assistant_response = run_conversation(messages, functions, available_functions, \"gpt-4-32k\")\n",
        "print(assistant_response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Recommended Function call:\nFunctionCall(arguments='{\\n  \"location\": \"America/New_York\"\\n}', name='get_current_time')\n\nOutput of function call:\n08:57:29 PM\n\nMessages in second request:\n{'role': 'user', 'content': 'What time is it in New York?'}\n{'role': 'assistant', 'name': 'get_current_time', 'content': '{\\n  \"location\": \"America/New_York\"\\n}'}\n{'role': 'function', 'name': 'get_current_time', 'content': '08:57:29 PM'}\n\nThe current time in New York is 08:57:29 PM.\n"
        }
      ],
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700445449620
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}