{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Getting started with prompty"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Install dependent packages"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install --force-reinstall typing-extensions==4.8"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720091586128
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%capture --no-stderr # magic command in Jupyter notebooks is used to capture the output of a cell,\n",
        "#%pip install prompflow-core"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Execute a Prompty\n",
        "\n",
        "Prompty is a file with .prompty extension for developing prompt template. \n",
        "The prompty asset is a markdown file with a modified front matter. \n",
        "The front matter is in yaml format that contains a number of metadata fields which defines model configuration and expected inputs of the prompty."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"prompty/basic.prompty\") as fin:\n",
        "    print(fin.read())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "---\nname: Basic Prompt\ndescription: A basic prompt that uses the chat API to answer questions\nmodel:\n    api: chat\n    configuration:\n        type: azure_openai\n        azure_deployment: gpt-4-0125-Preview\n    parameters:\n        max_tokens: 128\n        temperature: 0.2\ninputs:\n  question:\n    type: string\nsample:\n  \"question\": \"Who is the most famous person in the world?\"\n---\nsystem:\nYou are an AI assistant who helps people find information.\nAs the assistant, you answer questions briefly, succinctly. \n\nuser:\n{{question}}\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1724222847390
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(\"credentials.env\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1724223950474
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.core import Prompty\n",
        "\n",
        "# load prompty as a flow\n",
        "f = Prompty.load(source=\"prompty/basic.prompty\")\n",
        "\n",
        "# execute the flow as function\n",
        "result = f(question=\"What is the capital of France?\")\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "'The capital of France is Paris.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1724224827422
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can override configuration with `AzureOpenAIModelConfiguration` and `OpenAIModelConfiguration`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.core import AzureOpenAIModelConfiguration, OpenAIModelConfiguration\n",
        "\n",
        "# override configuration with AzureOpenAIModelConfiguration\n",
        "configuration = AzureOpenAIModelConfiguration(\n",
        "    #azure_endpoint=\"${env:AZURE_OPENAI_ENDPOINT}\",  # Use ${env:<ENV_NAME>} to surround the environment variable name.\n",
        "    #api_key=\"${env:AZURE_OPENAI_API_KEY}\",\n",
        "    azure_deployment=\"gpt-4o\",\n",
        ")\n",
        "\n",
        "# override configuration with OpenAIModelConfiguration\n",
        "# configuration = OpenAIModelConfiguration(\n",
        "#     base_url=\"${env:OPENAI_BASE_URL}\",\n",
        "#     api_key=\"${env:OPENAI_API_KEY}\",\n",
        "#     model=\"gpt-3.5-turbo\"\n",
        "# )\n",
        "\n",
        "override_model = {\"configuration\": configuration, \"parameters\": {\"max_tokens\": 512}}\n",
        "\n",
        "# load prompty as a flow\n",
        "f = Prompty.load(source=\"prompty/basic.prompty\", model=override_model)\n",
        "\n",
        "# execute the flow as function\n",
        "result = f(question=\"What is the capital of France?\")\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "'The capital of France is Paris.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1724223963289
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize trace by using start_trace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.tracing import start_trace\n",
        "\n",
        "# start a trace session, and print a url for user to check trace\n",
        "start_trace()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Starting prompt flow service...\nStart prompt flow service on 127.0.0.1:23333, version: 1.13.0.\nYou can stop the prompt flow service with the following command:'\u001b[1mpf service stop\u001b[0m'.\n\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1724223476284
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Re-run below cell will collect a trace in trace UI."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# rerun the function, which will be recorded in the trace\n",
        "question = \"What is the capital of Japan?\"\n",
        "ground_truth = \"Tokyo\"\n",
        "result = f(question=question)\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You can view the trace detail from the following URL:\nhttp://127.0.0.1:23333/v1.0/ui/traces/?#collection=AzureOpenAI_Advanced&uiTraceId=0x940d19a845a3aed6165fb02aa414bd8f\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "'Tokyo.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1724223504326
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eval the result \n",
        "\n",
        "Note: the eval flow returns a `json_object`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# load prompty as a flow\n",
        "eval_flow = Prompty.load(\"prompty/eval.prompty\")\n",
        "# execute the flow as function\n",
        "result = eval_flow(question=question, ground_truth=ground_truth, answer=result)\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You can view the trace detail from the following URL:\nhttp://127.0.0.1:23333/v1.0/ui/traces/?#collection=AzureOpenAI_Advanced&uiTraceId=0xd5fd8d891da39648c15201cb9cff5c1c\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "{'score': '5', 'explanation': 'Tokyo is indeed the capital of Japan.'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1724223736306
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pf service stop"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Prompt flow service stop on 127.0.0.1:23333.\r\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724223769332
        }
      }
    }
  ],
  "metadata": {
    "resources": "examples/requirements.txt, examples/prompty/basic, examples/prompty/eval-basic",
    "build_doc": {
      "author": [
        "lalala123123@github.com",
        "wangchao1230@github.com"
      ],
      "category": "local",
      "section": "Prompty",
      "weight": 10
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "description": "A quickstart tutorial to run a prompty and evaluate it.",
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}