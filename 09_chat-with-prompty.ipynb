{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chat with prompty"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Learning Objectives** - Upon completing this tutorial, you should be able to:\n",
        "\n",
        "- Write LLM application using prompty and visualize the trace of your application.\n",
        "- Understand how to handle chat conversation using prompty\n",
        "- batch run prompty against multi lines of data.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Install dependent packages"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install promptflow-devkit"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install promptflow promptflow-tools"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: promptflow in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (1.13.0)\nRequirement already satisfied: promptflow-tools in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (1.4.0)\nRequirement already satisfied: promptflow-devkit==1.13.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow) (1.13.0)\nRequirement already satisfied: promptflow-tracing==1.13.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow) (1.13.0)\nRequirement already satisfied: promptflow-core==1.13.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow) (1.13.0)\nRequirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (0.18.6)\nRequirement already satisfied: flask<4.0.0,>=2.2.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (3.0.3)\nRequirement already satisfied: filetype>=1.2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (1.2.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (2.8.2)\nRequirement already satisfied: fastapi<1.0.0,>=0.109.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (0.111.0)\nRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (4.17.3)\nRequirement already satisfied: psutil in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (5.9.5)\nRequirement already satisfied: docutils!=0.21.post1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (0.20.1)\nRequirement already satisfied: waitress<3.0.0,>=2.1.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (2.1.2)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (1.25.0)\nRequirement already satisfied: argcomplete>=3.2.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (3.4.0)\nRequirement already satisfied: pandas<3.0.0,>=1.5.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (2.0.2)\nRequirement already satisfied: pydash<8.0.0,>=6.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (7.0.7)\nRequirement already satisfied: colorama<0.5.0,>=0.4.6 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (0.4.6)\nRequirement already satisfied: flask-cors<5.0.0,>=4.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (4.0.1)\nRequirement already satisfied: azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (1.0.0b27)\nRequirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (1.0.1)\nRequirement already satisfied: gitpython<4.0.0,>=3.1.24 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (3.1.43)\nRequirement already satisfied: cryptography>=42.0.4 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (42.0.8)\nRequirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (2.0.31)\nRequirement already satisfied: tabulate<1.0.0,>=0.9.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (0.9.0)\nRequirement already satisfied: flask-restx<2.0.0,>=1.2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (1.3.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (3.21.3)\nRequirement already satisfied: keyring<25.0.0,>=24.2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (24.3.1)\nRequirement already satisfied: filelock<4.0.0,>=3.4.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (3.12.2)\nRequirement already satisfied: httpx>=0.25.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (0.27.0)\nRequirement already satisfied: pillow<11.0.0,>=10.1.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (10.4.0)\nRequirement already satisfied: strictyaml<2.0.0,>=1.5.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (1.7.3)\nRequirement already satisfied: tiktoken>=0.4.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-tracing==1.13.0->promptflow) (0.7.0)\nRequirement already satisfied: openai in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-tracing==1.13.0->promptflow) (1.35.10)\nRequirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-tracing==1.13.0->promptflow) (1.25.0)\nRequirement already satisfied: google-search-results==2.4.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-tools) (2.4.1)\nRequirement already satisfied: requests in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from google-search-results==2.4.1->promptflow-tools) (2.31.0)\nRequirement already satisfied: sniffio in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (1.3.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (3.7.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (1.8.0)\nRequirement already satisfied: tqdm>4 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (4.66.4)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (1.10.9)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (4.8.0)\nRequirement already satisfied: exceptiongroup in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai->promptflow-tracing==1.13.0->promptflow) (1.1.1)\nRequirement already satisfied: idna>=2.8 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai->promptflow-tracing==1.13.0->promptflow) (3.4)\nRequirement already satisfied: msrest>=0.6.10 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (0.7.1)\nRequirement already satisfied: fixedint==0.1.6 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (0.1.6)\nRequirement already satisfied: opentelemetry-api~=1.21 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (1.25.0)\nRequirement already satisfied: azure-core<2.0.0,>=1.28.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (1.30.2)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from cryptography>=42.0.4->promptflow-devkit==1.13.0->promptflow) (1.15.1)\nRequirement already satisfied: orjson>=3.2.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (3.10.6)\nRequirement already satisfied: starlette<0.38.0,>=0.37.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.37.2)\nRequirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (5.10.0)\nRequirement already satisfied: python-multipart>=0.0.7 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.0.9)\nRequirement already satisfied: email_validator>=2.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (2.2.0)\nRequirement already satisfied: uvicorn[standard]>=0.12.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.30.1)\nRequirement already satisfied: jinja2>=2.11.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (3.1.4)\nRequirement already satisfied: fastapi-cli>=0.0.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.0.4)\nRequirement already satisfied: blinker>=1.6.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (1.8.2)\nRequirement already satisfied: Werkzeug>=3.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (3.0.3)\nRequirement already satisfied: importlib-metadata>=3.6.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (6.7.0)\nRequirement already satisfied: itsdangerous>=2.1.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (8.1.3)\nRequirement already satisfied: pytz in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.13.0->promptflow) (2023.3)\nRequirement already satisfied: aniso8601>=0.82 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.13.0->promptflow) (9.0.1)\nRequirement already satisfied: importlib-resources in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.13.0->promptflow) (5.12.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit==1.13.0->promptflow) (4.0.11)\nRequirement already satisfied: certifi in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from httpx>=0.25.1->promptflow-devkit==1.13.0->promptflow) (2023.5.7)\nRequirement already satisfied: httpcore==1.* in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from httpx>=0.25.1->promptflow-devkit==1.13.0->promptflow) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from httpcore==1.*->httpx>=0.25.1->promptflow-devkit==1.13.0->promptflow) (0.14.0)\nRequirement already satisfied: attrs>=17.4.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.13.0->promptflow) (23.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.13.0->promptflow) (0.19.3)\nRequirement already satisfied: pkgutil-resolve-name>=1.3.10 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.13.0->promptflow) (1.3.10)\nRequirement already satisfied: jaraco.classes in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.13.0->promptflow) (3.4.0)\nRequirement already satisfied: SecretStorage>=3.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.13.0->promptflow) (3.3.3)\nRequirement already satisfied: jeepney>=0.4.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.13.0->promptflow) (0.8.0)\nRequirement already satisfied: packaging>=17.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit==1.13.0->promptflow) (23.0)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (1.59.1)\nRequirement already satisfied: deprecated>=1.2.6 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (1.2.14)\nRequirement already satisfied: opentelemetry-proto==1.25.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (1.25.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (1.25.0)\nRequirement already satisfied: protobuf<5.0,>=3.19 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-proto==1.25.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (4.23.3)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.13.0->promptflow) (0.46b0)\nRequirement already satisfied: tzdata>=2022.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit==1.13.0->promptflow) (2023.3)\nRequirement already satisfied: numpy>=1.20.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit==1.13.0->promptflow) (1.24.3)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1.0->promptflow-core==1.13.0->promptflow) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests->google-search-results==2.4.1->promptflow-tools) (3.1.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests->google-search-results==2.4.1->promptflow-tools) (1.26.16)\nRequirement already satisfied: ruamel.yaml.clib>=0.2.7 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from ruamel.yaml<1.0.0,>=0.17.10->promptflow-core==1.13.0->promptflow) (0.2.8)\nRequirement already satisfied: greenlet!=0.4.17 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit==1.13.0->promptflow) (3.0.3)\nRequirement already satisfied: regex>=2022.1.18 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from tiktoken>=0.4.0->promptflow-tracing==1.13.0->promptflow) (2024.5.15)\nRequirement already satisfied: pycparser in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=42.0.4->promptflow-devkit==1.13.0->promptflow) (2.21)\nRequirement already satisfied: wrapt<2,>=1.10 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (1.16.0)\nRequirement already satisfied: dnspython>=2.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from email_validator>=2.0.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (2.6.1)\nRequirement already satisfied: typer>=0.12.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.12.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit==1.13.0->promptflow) (5.0.1)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from importlib-metadata>=3.6.0->flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (3.15.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jinja2>=2.11.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (2.1.5)\nRequirement already satisfied: isodate>=0.6.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (0.6.1)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (1.3.1)\nRequirement already satisfied: watchfiles>=0.13 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.22.0)\nRequirement already satisfied: websockets>=10.4 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (12.0)\nRequirement already satisfied: httptools>=0.5.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.6.1)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.19.0)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (6.0)\nRequirement already satisfied: more-itertools in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit==1.13.0->promptflow) (10.3.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (3.2.2)\nRequirement already satisfied: rich>=10.11.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (13.4.2)\nRequirement already satisfied: shellingham>=1.3.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (1.5.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (2.15.1)\nRequirement already satisfied: mdurl~=0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Prompty\n",
        "\n",
        "Prompty is a file with .prompty extension for developing prompt template. \n",
        "The prompty asset is a markdown file with a modified front matter. \n",
        "The front matter is in yaml format that contains a number of metadata fields which defines model configuration and expected inputs of the prompty."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"prompty/chat.prompty\") as fin:\n",
        "    print(fin.read())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "---\nname: Chat Prompt\ndescription: A basic prompt that uses the chat API to answer questions with chat_history\nmodel:\n    api: chat\n    configuration:\n        type: azure_openai\n        connection: my_azure_open_ai_connection\n        azure_deployment: gpt-4-0125-Preview\n    parameters:\n        max_tokens: 256\n        temperature: 0.2\n\ninputs:\n    question:\n        type: string\n    chat_history:\n        type: list\n        default: []\nsample:\n    question: What is the meaning of life?\n    chat_history: []\n\n---\nsystem:\nYou are an AI assistant who helps people find information.\nAs the assistant, you answer questions briefly, succinctly, \nand in a personable manner using markdown and even add some personal flair with appropriate emojis.\n\n{% for item in chat_history %}\n{{item.role}}:\n{{item.content}}\n{% endfor %}\n\nuser:\n{{question}}\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1720100331250
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create necessary connections\n",
        "Connection helps securely store and manage secret keys or other sensitive credentials required for interacting with LLM and other external tools for example Azure Content Safety.\n",
        "\n",
        "Above prompty uses connection `open_ai_connection` inside, we need to set up the connection if we haven't added it before. After created, it's stored in local db and can be used in any flow.\n",
        "\n",
        "Prepare your Azure Open AI resource follow this [instruction](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal) and get your `api_key` if you don't have one."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install keyrings.alt"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.client import PFClient\n",
        "from promptflow.connections import AzureOpenAIConnection, OpenAIConnection\n",
        "\n",
        "from promptflow.entities import AzureOpenAIConnection\n",
        "client = PFClient()\n",
        "# Initialize an AzureOpenAIConnection object\n",
        "connection = AzureOpenAIConnection(\n",
        "    name=\"my_azure_open_ai_connection\",\n",
        "    api_key=\"8b96d7ba6a31403089100421919c7962\",\n",
        "    api_base=\"https://azuremlopenai.openai.azure.com/\",\n",
        ")\n",
        "# Create the connection, note that api_key will be scrubbed in the returned result\n",
        "result = client.connections.create_or_update(connection)\n",
        "print(result)\n",
        "\n",
        "print(connection)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "auth_mode: key\nname: my_azure_open_ai_connection\nmodule: promptflow.connections\ncreated_date: '2024-07-04T11:24:33.153641'\nlast_modified_date: '2024-07-04T13:39:19.031051'\ntype: azure_open_ai\napi_key: '******'\napi_base: https://azuremlopenai.openai.azure.com/\napi_type: azure\napi_version: '2024-02-01'\n\nauth_mode: key\nname: my_azure_open_ai_connection\nmodule: promptflow.connections\ntype: azure_open_ai\napi_key: '******'\napi_base: https://azuremlopenai.openai.azure.com/\napi_type: azure\napi_version: '2024-02-01'\n\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1720100358497
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conn_name = \"my_azure_open_ai_connection\"\n",
        "conn = client.connections.get(name=conn_name)\n",
        "print(\"using this connection :\",conn_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "using this connection : my_azure_open_ai_connection\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720100384703
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute prompty as function"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.core import Prompty\n",
        "\n",
        "# load prompty as a flow\n",
        "f = Prompty.load(\"prompty/chat.prompty\")\n",
        "# execute the flow as function\n",
        "question = \"What is the capital of France?\"\n",
        "result = f(question=question)\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "\"The capital of France is Paris! 🇫🇷✨ It's not just the political capital but also a global center for art, fashion, gastronomy, and culture. A truly iconic city!\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1720100391520
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can override connection with `AzureOpenAIModelConfiguration` and `OpenAIModelConfiguration`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.core import AzureOpenAIModelConfiguration, OpenAIModelConfiguration\n",
        "\n",
        "\n",
        "# override configuration with created connection in AzureOpenAIModelConfiguration\n",
        "configuration = AzureOpenAIModelConfiguration(\n",
        "    connection=\"my_azure_open_ai_connection\", azure_deployment=\"gpt-4o\"\n",
        ")\n",
        "\n",
        "# override openai connection with OpenAIModelConfiguration\n",
        "# configuration = OpenAIModelConfiguration(\n",
        "#     connection=connection,\n",
        "#     model=\"gpt-3.5-turbo\"\n",
        "# )\n",
        "\n",
        "override_model = {\n",
        "    \"configuration\": configuration,\n",
        "}\n",
        "\n",
        "# load prompty as a flow\n",
        "f = Prompty.load(\"prompty/chat.prompty\", model=override_model)\n",
        "# execute the flow as function\n",
        "question = \"What is the capital of France?\"\n",
        "result = f(question=question)\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "'The capital of France is Paris! 🇫🇷✨'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1720100426305
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize trace by using start_trace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.tracing import start_trace\n",
        "\n",
        "# start a trace session, and print a url for user to check trace\n",
        "start_trace()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Prompt flow service has started...\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1720100446852
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Re-run below cell will collect a trace in trace UI."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# rerun the function, which will be recorded in the trace\n",
        "result = f(question=question)\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "'The capital of France is Paris! 🇫🇷✨'"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You can view the trace detail from the following URL:\nhttp://127.0.0.1:23333/v1.0/ui/traces/?#collection=AzureOpenAI_Advanced&uiTraceId=0x9cb9e13a2381a014220befe3cd07b522\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1720100440219
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Summarize our conversation\"\n",
        "result = f(question=question)\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You can view the trace detail from the following URL:\nhttp://127.0.0.1:23333/v1.0/ui/traces/?#collection=AzureOpenAI_Advanced&uiTraceId=0x099f500a1b0b709b9526888e47b7c861\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "\"Sure thing! 😊 So far, you've asked me to summarize our conversation. That's it! If you have any other questions or need more info, feel free to ask! 📚✨\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720100456915
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eval the result \n",
        "\n",
        "In this example, we will use a prompt that determines whether a chat conversation contains an apology from the assistant."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "eval_prompty = \"prompty/apology.prompty\"\n",
        "\n",
        "with open(eval_prompty) as fin:\n",
        "    print(fin.read())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "---\nname: Apology Prompt\ndescription: A prompt that determines whether a chat conversation contains an apology from the assistant\nmodel:\n  api: chat\n  configuration:\n    type: azure_openai\n    connection: my_azure_open_ai_connection\n    azure_deployment: gpt-4o\n  parameters:\n    temperature: 0.2\n    response_format: { \"type\": \"json_object\" }\ninputs: \n  question:\n    type: string\n  answer:\n    type: string\n  messages:\n    type: list\noutputs:\n  apology:\n    type: string\nsample: ${file:sample.json}\n---\n\nsystem:\nYou are an AI tool that determines if, in a chat conversation, the assistant apologized, like say sorry.\nOnly provide a response of {\"apology\": 0} or {\"apology\": 1} so that the output is valid JSON.\nGive a apology of 1 if apologized in the chat conversation.\n\nHere are some examples of chat conversations and the correct response:\n\n**Example 1**\nuser: Where can I get my car fixed?\nassistant: I'm sorry, I don't know that. Would you like me to look it up for you?\nresult:\n{\"apology\": 1}\n\n**Here the actual conversation to be scored:**\n{% for message in messages %}\n{{ message.role }}: {{ message.content}}\n{% endfor %}\nuser: {{question}}\nassistant: {{answer}}\n\n**result**\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1720100468607
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: the eval flow returns a `json_object`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# load prompty as a flow\n",
        "eval_flow = Prompty.load(eval_prompty)\n",
        "# execute the flow as function\n",
        "result = eval_flow(question=question, answer=result, messages=[])\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You can view the trace detail from the following URL:\nhttp://127.0.0.1:23333/v1.0/ui/traces/?#collection=AzureOpenAI_Advanced&uiTraceId=0x82d98a37d9f914399b04389ef1ead882\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "{'apology': 0}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1720100492722
        }
      }
    }
  ],
  "metadata": {
    "resources": "examples/requirements.txt, examples/prompty/chat-basic, examples/prompty/eval-apology",
    "build_doc": {
      "author": [
        "lalala123123@github.com",
        "wangchao1230@github.com"
      ],
      "category": "local",
      "section": "Prompty",
      "weight": 20
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "description": "A quickstart tutorial to run a chat prompty and evaluate it.",
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}