{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chat with prompty"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Install dependent packages"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#%%capture --no-stderr\n",
        "#%pip install promptflow-devkit"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install promptflow promptflow-tools"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: promptflow in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (1.13.0)\nRequirement already satisfied: promptflow-tools in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (1.4.0)\nRequirement already satisfied: promptflow-devkit==1.13.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow) (1.13.0)\nRequirement already satisfied: promptflow-tracing==1.13.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow) (1.13.0)\nRequirement already satisfied: promptflow-core==1.13.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow) (1.13.0)\nRequirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (0.18.6)\nRequirement already satisfied: flask<4.0.0,>=2.2.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (3.0.3)\nRequirement already satisfied: filetype>=1.2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (1.2.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (2.8.2)\nRequirement already satisfied: fastapi<1.0.0,>=0.109.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (0.111.0)\nRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (4.17.3)\nRequirement already satisfied: psutil in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (5.9.5)\nRequirement already satisfied: docutils!=0.21.post1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (0.20.1)\nRequirement already satisfied: waitress<3.0.0,>=2.1.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (2.1.2)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (1.25.0)\nRequirement already satisfied: argcomplete>=3.2.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (3.4.0)\nRequirement already satisfied: pandas<3.0.0,>=1.5.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (2.0.2)\nRequirement already satisfied: pydash<8.0.0,>=6.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (7.0.7)\nRequirement already satisfied: colorama<0.5.0,>=0.4.6 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (0.4.6)\nRequirement already satisfied: flask-cors<5.0.0,>=4.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (4.0.1)\nRequirement already satisfied: azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (1.0.0b27)\nRequirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (1.0.1)\nRequirement already satisfied: gitpython<4.0.0,>=3.1.24 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (3.1.43)\nRequirement already satisfied: cryptography>=42.0.4 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (42.0.8)\nRequirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (2.0.31)\nRequirement already satisfied: tabulate<1.0.0,>=0.9.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (0.9.0)\nRequirement already satisfied: flask-restx<2.0.0,>=1.2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (1.3.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (3.21.3)\nRequirement already satisfied: keyring<25.0.0,>=24.2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (24.3.1)\nRequirement already satisfied: filelock<4.0.0,>=3.4.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (3.12.2)\nRequirement already satisfied: httpx>=0.25.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (0.27.0)\nRequirement already satisfied: pillow<11.0.0,>=10.1.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (10.4.0)\nRequirement already satisfied: strictyaml<2.0.0,>=1.5.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (1.7.3)\nRequirement already satisfied: tiktoken>=0.4.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-tracing==1.13.0->promptflow) (0.7.0)\nRequirement already satisfied: openai in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-tracing==1.13.0->promptflow) (1.35.10)\nRequirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-tracing==1.13.0->promptflow) (1.25.0)\nRequirement already satisfied: google-search-results==2.4.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-tools) (2.4.1)\nRequirement already satisfied: requests in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from google-search-results==2.4.1->promptflow-tools) (2.31.0)\nRequirement already satisfied: sniffio in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (1.3.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (3.7.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (1.8.0)\nRequirement already satisfied: tqdm>4 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (4.66.4)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (1.10.9)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (4.8.0)\nRequirement already satisfied: exceptiongroup in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai->promptflow-tracing==1.13.0->promptflow) (1.1.1)\nRequirement already satisfied: idna>=2.8 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai->promptflow-tracing==1.13.0->promptflow) (3.4)\nRequirement already satisfied: msrest>=0.6.10 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (0.7.1)\nRequirement already satisfied: fixedint==0.1.6 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (0.1.6)\nRequirement already satisfied: opentelemetry-api~=1.21 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (1.25.0)\nRequirement already satisfied: azure-core<2.0.0,>=1.28.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (1.30.2)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from cryptography>=42.0.4->promptflow-devkit==1.13.0->promptflow) (1.15.1)\nRequirement already satisfied: orjson>=3.2.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (3.10.6)\nRequirement already satisfied: starlette<0.38.0,>=0.37.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.37.2)\nRequirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (5.10.0)\nRequirement already satisfied: python-multipart>=0.0.7 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.0.9)\nRequirement already satisfied: email_validator>=2.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (2.2.0)\nRequirement already satisfied: uvicorn[standard]>=0.12.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.30.1)\nRequirement already satisfied: jinja2>=2.11.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (3.1.4)\nRequirement already satisfied: fastapi-cli>=0.0.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.0.4)\nRequirement already satisfied: blinker>=1.6.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (1.8.2)\nRequirement already satisfied: Werkzeug>=3.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (3.0.3)\nRequirement already satisfied: importlib-metadata>=3.6.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (6.7.0)\nRequirement already satisfied: itsdangerous>=2.1.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (8.1.3)\nRequirement already satisfied: pytz in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.13.0->promptflow) (2023.3)\nRequirement already satisfied: aniso8601>=0.82 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.13.0->promptflow) (9.0.1)\nRequirement already satisfied: importlib-resources in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.13.0->promptflow) (5.12.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit==1.13.0->promptflow) (4.0.11)\nRequirement already satisfied: certifi in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from httpx>=0.25.1->promptflow-devkit==1.13.0->promptflow) (2023.5.7)\nRequirement already satisfied: httpcore==1.* in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from httpx>=0.25.1->promptflow-devkit==1.13.0->promptflow) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from httpcore==1.*->httpx>=0.25.1->promptflow-devkit==1.13.0->promptflow) (0.14.0)\nRequirement already satisfied: attrs>=17.4.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.13.0->promptflow) (23.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.13.0->promptflow) (0.19.3)\nRequirement already satisfied: pkgutil-resolve-name>=1.3.10 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.13.0->promptflow) (1.3.10)\nRequirement already satisfied: jaraco.classes in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.13.0->promptflow) (3.4.0)\nRequirement already satisfied: SecretStorage>=3.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.13.0->promptflow) (3.3.3)\nRequirement already satisfied: jeepney>=0.4.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.13.0->promptflow) (0.8.0)\nRequirement already satisfied: packaging>=17.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit==1.13.0->promptflow) (23.0)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (1.59.1)\nRequirement already satisfied: deprecated>=1.2.6 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (1.2.14)\nRequirement already satisfied: opentelemetry-proto==1.25.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (1.25.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (1.25.0)\nRequirement already satisfied: protobuf<5.0,>=3.19 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-proto==1.25.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (4.23.3)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.13.0->promptflow) (0.46b0)\nRequirement already satisfied: tzdata>=2022.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit==1.13.0->promptflow) (2023.3)\nRequirement already satisfied: numpy>=1.20.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit==1.13.0->promptflow) (1.24.3)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1.0->promptflow-core==1.13.0->promptflow) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests->google-search-results==2.4.1->promptflow-tools) (3.1.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests->google-search-results==2.4.1->promptflow-tools) (1.26.16)\nRequirement already satisfied: ruamel.yaml.clib>=0.2.7 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from ruamel.yaml<1.0.0,>=0.17.10->promptflow-core==1.13.0->promptflow) (0.2.8)\nRequirement already satisfied: greenlet!=0.4.17 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit==1.13.0->promptflow) (3.0.3)\nRequirement already satisfied: regex>=2022.1.18 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from tiktoken>=0.4.0->promptflow-tracing==1.13.0->promptflow) (2024.5.15)\nRequirement already satisfied: pycparser in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=42.0.4->promptflow-devkit==1.13.0->promptflow) (2.21)\nRequirement already satisfied: wrapt<2,>=1.10 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (1.16.0)\nRequirement already satisfied: dnspython>=2.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from email_validator>=2.0.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (2.6.1)\nRequirement already satisfied: typer>=0.12.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.12.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit==1.13.0->promptflow) (5.0.1)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from importlib-metadata>=3.6.0->flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (3.15.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jinja2>=2.11.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (2.1.5)\nRequirement already satisfied: isodate>=0.6.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (0.6.1)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (1.3.1)\nRequirement already satisfied: watchfiles>=0.13 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.22.0)\nRequirement already satisfied: websockets>=10.4 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (12.0)\nRequirement already satisfied: httptools>=0.5.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.6.1)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.19.0)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (6.0)\nRequirement already satisfied: more-itertools in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit==1.13.0->promptflow) (10.3.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (3.2.2)\nRequirement already satisfied: rich>=10.11.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (13.4.2)\nRequirement already satisfied: shellingham>=1.3.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (1.5.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (2.15.1)\nRequirement already satisfied: mdurl~=0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Prompty\n",
        "\n",
        "Prompty is a file with .prompty extension for developing prompt template. \n",
        "The prompty asset is a markdown file with a modified front matter. \n",
        "The front matter is in yaml format that contains a number of metadata fields which defines model configuration and expected inputs of the prompty."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"prompty/chat.prompty\") as fin:\n",
        "    print(fin.read())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "---\nname: Chat Prompt\ndescription: A basic prompt that uses the chat API to answer questions with chat_history\nmodel:\n    api: chat\n    configuration:\n        type: azure_openai\n        connection: my_azure_open_ai_connection\n        azure_deployment: gpt-4-0125-Preview\n    parameters:\n        max_tokens: 256\n        temperature: 0.2\n\ninputs:\n    question:\n        type: string\n    chat_history:\n        type: list\n        default: []\nsample:\n    question: What is the meaning of life?\n    chat_history: []\n\n---\nsystem:\nYou are an AI assistant who helps people find information.\nAs the assistant, you answer questions briefly, succinctly, \nand in a personable manner using markdown and even add some personal flair with appropriate emojis.\n\n{% for item in chat_history %}\n{{item.role}}:\n{{item.content}}\n{% endfor %}\n\nuser:\n{{question}}\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1724227192462
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create necessary connections\n",
        "Connection helps securely store and manage secret keys or other sensitive credentials required for interacting with LLM and other external tools for example Azure Content Safety.\n",
        "\n",
        "We need to set up the connection if we haven't added it before. After created, it's stored in local db and can be used in any flow.\n",
        "\n",
        "Prepare your Azure Open AI resource follow this [instruction](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal) and get your `api_key` if you don't have one."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install keyrings.alt"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.client import PFClient\n",
        "from promptflow.connections import AzureOpenAIConnection, OpenAIConnection\n",
        "\n",
        "from promptflow.entities import AzureOpenAIConnection\n",
        "client = PFClient()\n",
        "# Initialize an AzureOpenAIConnection object\n",
        "connection = AzureOpenAIConnection(\n",
        "    name=\"my_azure_open_ai_connection\",\n",
        "    api_key=\"XXX\",\n",
        "    api_base=\"XXX\",\n",
        ")\n",
        "# Create the connection, note that api_key will be scrubbed in the returned result\n",
        "result = client.connections.create_or_update(connection)\n",
        "print(result)\n",
        "\n",
        "print(connection)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "auth_mode: key\nname: my_azure_open_ai_connection\nmodule: promptflow.connections\ncreated_date: '2024-07-04T01:25:55.056628'\nlast_modified_date: '2024-08-21T07:59:58.201822'\ntype: azure_open_ai\napi_key: '******'\napi_base: https://azuremlopenai.openai.azure.com/\napi_type: azure\napi_version: '2024-02-01'\n\nauth_mode: key\nname: my_azure_open_ai_connection\nmodule: promptflow.connections\ntype: azure_open_ai\napi_key: '******'\napi_base: https://azuremlopenai.openai.azure.com/\napi_type: azure\napi_version: '2024-02-01'\n\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1724227198319
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conn_name = \"my_azure_open_ai_connection\"\n",
        "conn = client.connections.get(name=conn_name)\n",
        "print(\"using this connection :\",conn_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "using this connection : my_azure_open_ai_connection\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724227207417
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute prompty as function"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.core import Prompty\n",
        "\n",
        "# load prompty as a flow\n",
        "f = Prompty.load(\"prompty/chat.prompty\")\n",
        "# execute the flow as function\n",
        "question = \"What is the capital of France?\"\n",
        "result = f(question=question)\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "\"The capital of France is Paris! 🇫🇷✨ It's not just the political capital but also a global center for art, fashion, gastronomy, and culture. A truly iconic city!\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1724227211381
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can override connection with `AzureOpenAIModelConfiguration` and `OpenAIModelConfiguration`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.core import AzureOpenAIModelConfiguration, OpenAIModelConfiguration\n",
        "\n",
        "\n",
        "# override configuration with created connection in AzureOpenAIModelConfiguration\n",
        "configuration = AzureOpenAIModelConfiguration(\n",
        "    connection=\"my_azure_open_ai_connection\", azure_deployment=\"gpt-4o\"\n",
        ")\n",
        "\n",
        "# override openai connection with OpenAIModelConfiguration\n",
        "# configuration = OpenAIModelConfiguration(\n",
        "#     connection=connection,\n",
        "#     model=\"gpt-3.5-turbo\"\n",
        "# )\n",
        "\n",
        "override_model = {\n",
        "    \"configuration\": configuration,\n",
        "}\n",
        "\n",
        "# load prompty as a flow\n",
        "f = Prompty.load(\"prompty/chat.prompty\", model=override_model)\n",
        "# execute the flow as function\n",
        "question = \"What is the capital of France?\"\n",
        "result = f(question=question)\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "'The capital of France is Paris! 🇫🇷✨'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1724227224344
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize trace by using start_trace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.tracing import start_trace\n",
        "\n",
        "# start a trace session, and print a url for user to check trace\n",
        "start_trace()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Prompt flow service has started...\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1724226907338
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Re-run below cell will collect a trace in trace UI."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# rerun the function, which will be recorded in the trace\n",
        "result = f(question=question)\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "'The capital of France is Paris! 🇫🇷✨'"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You can view the trace detail from the following URL:\nhttp://127.0.0.1:23333/v1.0/ui/traces/?#collection=AzureOpenAI_Advanced&uiTraceId=0x73a5f4ff53faf77ee686f6a84d7556b4\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1724226911351
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eval the result \n",
        "\n",
        "In this example, we will use a prompt that determines whether a chat conversation contains an apology from the assistant."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "eval_prompty = \"prompty/apology.prompty\"\n",
        "\n",
        "with open(eval_prompty) as fin:\n",
        "    print(fin.read())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "---\nname: Apology Prompt\ndescription: A prompt that determines whether a chat conversation contains an apology from the assistant\nmodel:\n  api: chat\n  configuration:\n    type: azure_openai\n    connection: my_azure_open_ai_connection\n    azure_deployment: gpt-4o\n  parameters:\n    temperature: 0.2\n    response_format: { \"type\": \"json_object\" }\ninputs: \n  question:\n    type: string\n  answer:\n    type: string\n  messages:\n    type: list\noutputs:\n  apology:\n    type: string\nsample: ${file:sample.json}\n---\n\nsystem:\nYou are an AI tool that determines if, in a chat conversation, the assistant apologized, like say sorry.\nOnly provide a response of {\"apology\": 0} or {\"apology\": 1} so that the output is valid JSON.\nGive a apology of 1 if apologized in the chat conversation.\n\nHere are some examples of chat conversations and the correct response:\n\n**Example 1**\nuser: Where can I get my car fixed?\nassistant: I'm sorry, I don't know that. Would you like me to look it up for you?\nresult:\n{\"apology\": 1}\n\n**Here the actual conversation to be scored:**\n{% for message in messages %}\n{{ message.role }}: {{ message.content}}\n{% endfor %}\nuser: {{question}}\nassistant: {{answer}}\n\n**result**\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1724227565334
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: the eval flow returns a `json_object`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# load prompty as a flow\n",
        "eval_flow = Prompty.load(eval_prompty)\n",
        "# execute the flow as function\n",
        "result = eval_flow(question=question, answer=result, messages=[])\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "{'apology': 0}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1724227675353
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pf service stop"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Prompt flow service stop on 127.0.0.1:23333.\r\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch run with multi-line data\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.client import PFClient\n",
        "\n",
        "flow = \"./prompty/chat.prompty\"  # path to the prompty file\n",
        "data = \"./prompty/data.jsonl\"  # path to the data file\n",
        "\n",
        "# create run with the flow and data\n",
        "pf = PFClient()\n",
        "base_run = pf.run(\n",
        "    flow=flow,\n",
        "    data=data,\n",
        "    column_mapping={\n",
        "        \"question\": \"${data.question}\",\n",
        "        \"chat_history\": \"${data.chat_history}\",\n",
        "    },\n",
        "    stream=True,\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[2024-08-21 08:22:47 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run prompty_20240821_082247_217704, log path: /home/azureuser/.promptflow/.runs/prompty_20240821_082247_217704/logs.txt\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Prompt flow service has started...\nYou can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=prompty_20240821_082247_217704\n2024-08-21 08:22:55 +0000 3217081 execution.bulk     INFO     Process 3217104 terminated.\n2024-08-21 08:22:55 +0000 3217081 execution.bulk     WARNING  Process 3217120 had been terminated.\n2024-08-21 08:22:55 +0000 3217081 execution.bulk     WARNING  Process 3217109 had been terminated.\n2024-08-21 08:22:47 +0000 3217002 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n2024-08-21 08:22:47 +0000 3217002 execution.bulk     INFO     Set process count to 3 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 3}.\n2024-08-21 08:22:49 +0000 3217002 execution.bulk     INFO     Process name(ForkProcess-2:3)-Process id(3217120)-Line number(0) start execution.\n2024-08-21 08:22:49 +0000 3217002 execution.bulk     INFO     Process name(ForkProcess-2:1)-Process id(3217104)-Line number(1) start execution.\n2024-08-21 08:22:49 +0000 3217002 execution.bulk     INFO     Process name(ForkProcess-2:2)-Process id(3217109)-Line number(2) start execution.\n2024-08-21 08:22:51 +0000 3217002 execution.bulk     INFO     Process name(ForkProcess-2:1)-Process id(3217104)-Line number(1) completed.\n2024-08-21 08:22:51 +0000 3217002 execution.bulk     INFO     Finished 1 / 3 lines.\n2024-08-21 08:22:51 +0000 3217002 execution.bulk     INFO     Average execution time for completed lines: 4.0 seconds. Estimated time for incomplete lines: 8.0 seconds.\n2024-08-21 08:22:52 +0000 3217002 execution.bulk     INFO     Process name(ForkProcess-2:2)-Process id(3217109)-Line number(2) completed.\n2024-08-21 08:22:52 +0000 3217002 execution.bulk     INFO     Finished 2 / 3 lines.\n2024-08-21 08:22:52 +0000 3217002 execution.bulk     INFO     Average execution time for completed lines: 2.5 seconds. Estimated time for incomplete lines: 2.5 seconds.\n2024-08-21 08:22:54 +0000 3217002 execution.bulk     INFO     Process name(ForkProcess-2:3)-Process id(3217120)-Line number(0) completed.\n2024-08-21 08:22:54 +0000 3217002 execution.bulk     INFO     Finished 3 / 3 lines.\n2024-08-21 08:22:54 +0000 3217002 execution.bulk     INFO     Average execution time for completed lines: 2.34 seconds. Estimated time for incomplete lines: 0.0 seconds.\n2024-08-21 08:22:54 +0000 3217002 execution.bulk     INFO     The thread monitoring the process [3217104-ForkProcess-2:1] will be terminated.\n2024-08-21 08:22:54 +0000 3217002 execution.bulk     INFO     The thread monitoring the process [3217120-ForkProcess-2:3] will be terminated.\n2024-08-21 08:22:54 +0000 3217002 execution.bulk     INFO     The thread monitoring the process [3217109-ForkProcess-2:2] will be terminated.\n2024-08-21 08:22:54 +0000 3217104 execution.bulk     INFO     The process [3217104] has received a terminate signal.\n2024-08-21 08:22:54 +0000 3217120 execution.bulk     INFO     The process [3217120] has received a terminate signal.\n2024-08-21 08:22:54 +0000 3217109 execution.bulk     INFO     The process [3217109] has received a terminate signal.\n======= Run Summary =======\n\nRun name: \"prompty_20240821_082247_217704\"\nRun status: \"Completed\"\nStart time: \"2024-08-21 08:22:47.217538+00:00\"\nDuration: \"0:00:09.228898\"\nOutput path: \"/home/azureuser/.promptflow/.runs/prompty_20240821_082247_217704\"\n\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724228576093
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "details = pf.get_details(base_run)\n",
        "details"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "                 inputs.question  \\\n0               What's chat-GPT?   \n1  How many questions did I ask?   \n2    Summarize our conversation?   \n\n                                 inputs.chat_history  inputs.line_number  \\\n0                                                 []                   0   \n1                                                 []                   1   \n2  [{'role': 'user', 'content': 'where is the nea...                   2   \n\n                                      outputs.output  \n0  Chat-GPT is like a digital buddy that's super ...  \n1  You've asked one question so far! 🎉 Got any mo...  \n2  Of course! 😊 You asked about the nearest coffe...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>inputs.question</th>\n      <th>inputs.chat_history</th>\n      <th>inputs.line_number</th>\n      <th>outputs.output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What's chat-GPT?</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>Chat-GPT is like a digital buddy that's super ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How many questions did I ask?</td>\n      <td>[]</td>\n      <td>1</td>\n      <td>You've asked one question so far! 🎉 Got any mo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Summarize our conversation?</td>\n      <td>[{'role': 'user', 'content': 'where is the nea...</td>\n      <td>2</td>\n      <td>Of course! 😊 You asked about the nearest coffe...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724228583471
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "details.head(3)['outputs.output'].values"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "array([\"Chat-GPT is like a digital buddy that's super good at chatting! 🤖✨ Developed by OpenAI, it's a type of AI (Artificial Intelligence) that's designed to have conversations with humans. Whether you need help with homework, want to know the weather, or just feel like chatting about your favorite TV show, Chat-GPT is there to keep the conversation going. It's based on a model called GPT (Generative Pre-trained Transformer), which is just a fancy way of saying it's really good at understanding and generating human-like text. So, it's like having a chat with a friend who knows a ton of stuff! 📚💬\",\n       \"You've asked one question so far! 🎉 Got any more for me? 😊\",\n       \"Of course! 😊 You asked about the nearest coffee shop, but since I couldn't access your location, I couldn't provide a specific answer. Then, you inquired about Azure ML, and I briefly described it as a cloud-based platform for machine learning provided by Microsoft Azure. It's designed to help users build, train, and deploy machine learning models efficiently. Hope that helps!\"],\n      dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724228589908
        }
      }
    }
  ],
  "metadata": {
    "resources": "examples/requirements.txt, examples/prompty/chat-basic, examples/prompty/eval-apology",
    "build_doc": {
      "author": [
        "lalala123123@github.com",
        "wangchao1230@github.com"
      ],
      "category": "local",
      "section": "Prompty",
      "weight": 20
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "description": "A quickstart tutorial to run a chat prompty and evaluate it.",
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}