{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import openai\n",
        "# from openai import AzureOpenAI\n",
        "# import os \n",
        "# from azure.identity import ManagedIdentityCredential\n",
        "\n",
        "# default_credential=ManagedIdentityCredential(client_id=\"f4980c43-9766-48d7-a925-c377a74605bb\")\n",
        "# token=default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "# Resource_endpoint=\"https://openaiykus.openai.azure.com/\"\n",
        "\n",
        "# client = AzureOpenAI(\n",
        "#   azure_endpoint = Resource_endpoint, \n",
        "#   api_key=token.token,  \n",
        "#   api_version=\"2023-05-15\"\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712287450305
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "    \n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
        "    api_version=\"2024-02-01\", #latest GA API version: https://learn.microsoft.com/en-us/azure/ai-services/openai/api-version-deprecation\n",
        "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716203871112
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Temperature\n",
        "\n",
        "Defaults to 1, Optional\n",
        "\n",
        "What sampling temperature to use, between 0 and 2. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 for ones with a well-defined answer.\n",
        "\n",
        "We generally recommend altering this or top_p but not both."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(num_times, start_phrase, temperature):\n",
        "    for i in range(num_times):\n",
        "        \n",
        "        deployment_name='gpt-35-turbo' \n",
        "\n",
        "        # Send a completion call to generate an answer\n",
        "        response = client.completions.create(\n",
        "            model=deployment_name, \n",
        "            prompt=start_phrase, \n",
        "            temperature=temperature,\n",
        "            max_tokens=10)\n",
        "        print(response.choices[0].text)\n",
        "        print(\"*****************************\")"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1716203874967
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'The Very Group company is a ', temperature = 0)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716203880806
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'The Very Group company is a  ', temperature = 2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " eCommerce.getProductPage.Group.Joinvl16 Explanation data-marker\n*****************************\n High models ®#. Part ._like o-ball discarded\n*****************************\nOOSe_cpp(foo moduleName_codegen_ANVOKEDescriptor_Runtime\n*****************************\n ============================================================================\n207680 toph<stdUnitRefresh茴\n*****************************\n returning summit 출력  \n\nSupplyafter provided visitor’s \n*****************************\n issued by ⁦@[theempmockgotir\n*****************************\n Located1Among culture grouped.ilocHL presentsancialgrounds\n*****************************\n harass-submitbohydrteesaboutsnodoc concert nodes staining how\n*****************************\n pest pledged dodár needs expensive CRReviewer rapport revive\n*****************************\n)viewDidLoad()leetcodeStaticMJ 문해 little.getProject(query\n*****************************\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716197134417
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Top_p\n",
        "\n",
        "Defaults to 1, Optional\n",
        "\n",
        "top_p parameter which stands for “top probability” and an alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. \n",
        "\n",
        "The top_p refers to the probability mass that should be used when considering the next word in the generated text. Essentially it ** sets a threshold for the probability of the next word being chosen and only considers the most likely words that exceed that threshold.**\n",
        "\n",
        "We generally recommend altering this or temperature but not both."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(num_times, start_phrase, top_p):\n",
        "    for i in range(num_times):\n",
        "        \n",
        "        deployment_name='gpt-35-turbo' \n",
        "\n",
        "        # Send a completion call to generate an answer\n",
        "        response = client.completions.create(\n",
        "            model=deployment_name, \n",
        "            prompt=start_phrase, \n",
        "            top_p=top_p,\n",
        "            max_tokens=10)\n",
        "        print(response.choices[0].text)\n",
        "        print(\"*****************************\")"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1716197144461
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'The Very Group company is a ', top_p = 0.1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n24/7 operation, so you will be required\n*****************************\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1716197154474
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'The Very Group company is a ', top_p = 1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "15-year-old e-commerce company that was called Shop\n*****************************\n2019 UK busines\n*****************************\n24/7 global operation; therefore, you must\n*****************************\n20 years old and is well-established. It is\n*****************************\n114-year-old retail brand that has progressed with time\n*****************************\n24/7 operation, working on rotational shift patterns\n*****************************\netail company that has grown significantly in recent years but\n*****************************\n24-hour operation with over 4,000 people\n*****************************\n24/7 operation. Flexibility with working hours\n*****************************\n7 year old business headquartered in the United Kingdom with\n*****************************\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1716197160387
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Max_Tokens \n",
        "\n",
        "Default value=16, Optional\n",
        "\n",
        "The maximum number of tokens to generate in the completion. **The token count of your prompt plus max_tokens can't exceed the model's context length. **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deployment_name='gpt-35-turbo' \n",
        "#This will correspond to the custom name you chose for your deployment when you deployed a model. \n",
        "    \n",
        "# Send a completion call to generate an answer\n",
        "start_phrase = 'The Very Group company is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    temperature=1,\n",
        "    max_tokens=5)\n",
        "\n",
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9QtZEamU7DUjGQm6zuCQAY1YkfGMA\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"text\": \"24,000-strong business\",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1716197156,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 5,\n    \"prompt_tokens\": 7,\n    \"total_tokens\": 12\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716197164779
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Send a completion call to generate an answer\n",
        "start_phrase = 'The Very Group company is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    temperature=1,\n",
        "    max_tokens=1000)\n",
        "\n",
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9Ab7N00IP0PYCHCwZB6bhpTD5vVwP\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"text\": \"UK-based online retailer that specializes in fashion, homeware, and electrical goods. It was formerly known as Shop Direct and rebranded to The Very Group in 2019. The company was founded in 2005 and has its headquarters in Liverpool, England.\\n\\nThe Very Group operates through its two main brands: Very and Littlewoods. Very is an online fashion retailer that sells clothing for men, women, and children, as well as homeware and electrical items. It also has its own fashion label, V by Very. Littlewoods is an established name in UK retail, offering a wide range of products including clothing, homeware, and electrical goods.\\n\\nThe company's online-only business model allows it to offer competitive prices and a wide variety of products to customers across the UK. The Very Group also offers flexible payment options, including a \\\"buy now, pay later\\\" service, to help customers manage their purchases.\\n\\nIn addition to its retail operations, The Very Group has a strong focus on sustainability and social responsibility. It has committed to reducing its carbon footprint and has initiatives in place to promote employee well-being and support charitable causes.\\n\\nIn recent years, The Very Group has invested in technology and innovation to enhance its online shopping experience and improve its logistics operations. It has also expanded its product range to include more premium and designer brands.\\n\\nOverall, The Very Group is a successful and innovative online retailer that continues to grow and adapt to the ever-changing retail landscape in the UK. \",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1712312989,\n  \"model\": \"gpt-35-turbo-instruct\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 296,\n    \"prompt_tokens\": 7,\n    \"total_tokens\": 303\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 70,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712312992039
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# n\n",
        "\n",
        "Defaults to 1, optional\n",
        "\n",
        "How many completions to generate for each prompt. To generate multiple completions, we specify the n request parameter, which simply stands for ** “number of completions” **\n",
        "\n",
        "Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "deployment_name='gpt-35-turbo' \n",
        "#This will correspond to the custom name you chose for your deployment when you deployed a model. \n",
        "    \n",
        "# Send a completion call to generate an answer\n",
        "start_phrase = 'The Very Group is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    temperature=1,\n",
        "    n=3)\n",
        "\n",
        "for i in response.choices:\n",
        "    print(i.text)\n",
        "    print (\"**************************\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "50/50 joint venture between Might Group Holdings Ltd and Guangzhou FullNet Market\n**************************\n30 year old business which until recently was called Shop Direct. We were established in\n**************************\netailer that was launched in 2005 as ‘Shop Direct’ by the\n**************************\n"
        }
      ],
      "execution_count": 71,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712313370957
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# logprobs\n",
        "\n",
        "Defaults to null, optional\n",
        "\n",
        "Log probabilities of output tokens indicate **the likelihood of each token occurring in the sequence given the context.** To simplify, a logprob is log(p), where p = probability of a token occurring at a specific position based on the previous tokens in the context.\n",
        "\n",
        "For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response.\n",
        "\n",
        "** tokens ** — is an array of tokens generated by the language model. Each token is a word or part of a word.\n",
        "\n",
        "** token_logprobs ** — represents an array of log probabilities for each token in the tokens array. Log probability indicates the likelihood of the language model generating that token for the given prompt. The logprob values are negative, where smaller (more negative) numbers indicate a less likely outcome.\n",
        "\n",
        "** top_logprobs ** — represents an array of log probability objects, representing tokens most likely to be used for the completion. For example, if we specify the request parameter top_p = 0.5, then top_logprobs would contain log probabilities for top 50% of generated tokens."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'The Very Group is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    logprobs=3)"
      ],
      "outputs": [],
      "execution_count": 72,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712313420616
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9AbEL6YQGAfQc4FWxRAyQOiiCS7kg\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": {\n        \"text_offset\": [\n          20,\n          25,\n          27,\n          31,\n          33,\n          36,\n          41,\n          42,\n          46,\n          52,\n          61,\n          70,\n          75,\n          78,\n          86,\n          90\n        ],\n        \"token_logprobs\": [\n          -0.5947807,\n          -0.119705014,\n          -1.3655376,\n          -8.322807,\n          -1.9481281,\n          -0.114622734,\n          -1.9761851,\n          -1.7313466,\n          -15.362309,\n          -6.7370224,\n          -4.0788326,\n          -1.4590615,\n          -0.6136453,\n          -2.636688,\n          -3.2919044,\n          -4.769308\n        ],\n        \"tokens\": [\n          \"etail\",\n          \"er\",\n          \" and\",\n          \"\\n\\n\",\n          \"ret\",\n          \"ailer\",\n          \",\",\n          \" and\",\n          \" scans\",\n          \" consumer\",\n          \" shopping\",\n          \" data\",\n          \" to\",\n          \" predict\",\n          \" and\",\n          \" cater\"\n        ],\n        \"top_logprobs\": [\n          {\n            \"etail\": -0.5947807,\n            \"24\": -1.9710147,\n            \"1\": -3.6231945\n          },\n          {\n            \"er\": -0.119705014,\n            \"ing\": -3.8099916,\n            \" giant\": -3.8464105\n          },\n          {\n            \" and\": -1.3655376,\n            \" that\": -1.0165577,\n            \" with\": -3.0397243\n          },\n          {\n            \" financial\": -0.19615133,\n            \" technology\": -3.1606708,\n            \" fint\": -4.1041675\n          },\n          {\n            \"ret\": -1.9481281,\n            \"financial\": -1.9099792,\n            \"the\": -2.7526612\n          },\n          {\n            \"ailer\": -0.114622734,\n            \"ail\": -2.241738,\n            \"ails\": -7.512669\n          },\n          {\n            \",\": -1.9761851,\n            \" that\": -1.8734152,\n            \" of\": -1.9490893\n          },\n          {\n            \" and\": -1.7313466,\n            \" selling\": -1.8540769,\n            \" with\": -2.3606725\n          },\n          {\n            \" the\": -1.2256314,\n            \" is\": -2.5051684,\n            \" has\": -2.7014518\n          },\n          {\n            \" the\": -2.0464306,\n            \" its\": -2.5729275,\n            \" all\": -2.8926601\n          },\n          {\n            \" data\": -1.5353318,\n            \"\\n\\n\": -2.5310078,\n            \" demand\": -2.5603733\n          },\n          {\n            \" data\": -1.4590615,\n            \"\\n\\n\": -1.7075337,\n            \" habits\": -2.0916433\n          },\n          {\n            \" to\": -0.6136453,\n            \" from\": -2.6877515,\n            \" in\": -2.8360689\n          },\n          {\n            \" predict\": -2.636688,\n            \" identify\": -2.1775205,\n            \" understand\": -2.720659\n          },\n          {\n            \" what\": -1.7139015,\n            \" trends\": -1.9183464,\n            \" future\": -2.3964386\n          },\n          {\n            \" respond\": -2.610306,\n            \" forecast\": -2.9893706,\n            \" plan\": -3.058451\n          }\n        ]\n      },\n      \"text\": \"etailer and\\n\\nretailer, and scans consumer shopping data to predict and cater\",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1712313421,\n  \"model\": \"gpt-35-turbo-instruct\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 16,\n    \"prompt_tokens\": 6,\n    \"total_tokens\": 22\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 73,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712313433088
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": 74,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712313472636
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Word values :\",response.choices[0].logprobs.tokens)\n",
        "print(\"Token log probabilities :\",response.choices[0].logprobs.token_logprobs)\n",
        "print(\"Top log linear probabilities :\",np.round(np.exp(response.choices[0].logprobs.token_logprobs)*100,2))\n",
        "\n",
        "print(\"Response:\", response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Word values : ['etail', 'er', ' and', '\\n\\n', 'ret', 'ailer', ',', ' and', ' scans', ' consumer', ' shopping', ' data', ' to', ' predict', ' and', ' cater']\nToken log probabilities : [-0.5947807, -0.119705014, -1.3655376, -8.322807, -1.9481281, -0.114622734, -1.9761851, -1.7313466, -15.362309, -6.7370224, -4.0788326, -1.4590615, -0.6136453, -2.636688, -3.2919044, -4.769308]\nTop log linear probabilities : [5.517e+01 8.872e+01 2.552e+01 2.000e-02 1.425e+01 8.917e+01 1.386e+01\n 1.770e+01 0.000e+00 1.200e-01 1.690e+00 2.325e+01 5.414e+01 7.160e+00\n 3.720e+00 8.500e-01]\nResponse: etailer and\n\nretailer, and scans consumer shopping data to predict and cater\n"
        }
      ],
      "execution_count": 75,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712313474185
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Presence_penalty\n",
        "\n",
        "Defaults to 0, Optional -> 0 means there is really no penalty or reward for the same token appearing multiple times. \n",
        "\n",
        "Number between -2.0 and 2.0. Positive values penalize new tokens based on ** whether they appear in the text so far **, increasing the model's likelihood to talk about new topics.\n",
        "\n",
        "Smaller values (minimum -2) decrease the penalty and increase the chances of a token appearing, while higher values (maximum 2) increase the penalty and decrease the chances of a token appearing."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'The Very Group company is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    presence_penalty=2,\n",
        "    max_tokens=50)"
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712290077831
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " UK-based retailer that operates online retail brands such as Littlewoods and Very. It offers a wide range of products including fashion, beauty, homeware, electronics, and toys. The company was originally founded in 1932 as the Liverpool-based catalogue retailer\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712290084985
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'The Very Group company is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    presence_penalty=-2,\n",
        "    max_tokens=50)\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "UK-based online retail company that was founded in 2005. It was formerly known as Shop Direct Group and rebranded in 2019. The company operates several ecommerce brands, including Very, Very Exclusive, Littlewoods, and Very Prom.\n"
        }
      ],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712290149637
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-9AVAzBQ8ueKkbICE5c1RcXsYwsJwl\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"text\": \"UK-based online retail company that was founded in 2005. It was formerly known as Shop Direct Group and rebranded in 2019. The company operates several ecommerce brands, including Very, Very Exclusive, Littlewoods, and Very Prom.\",\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1712290149,\n  \"model\": \"gpt-35-turbo-instruct\",\n  \"object\": \"text_completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 50,\n    \"prompt_tokens\": 7,\n    \"total_tokens\": 57\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712290181410
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Frequency_penalty\n",
        "\n",
        "Defaults to 0\n",
        "\n",
        "Number between -2.0 and 2.0. Positive values ** penalize new tokens based on their existing frequency in the text so far **, decreasing the model's likelihood to repeat the same line verbatim."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Best_of\n",
        "\n",
        "Defaults to 1,optional\n",
        "\n",
        "This parameter tells the language model to generate multiple completions and return the best one, which is the one with the highest log probability per token.\n",
        "\n",
        "\n",
        "Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'The Very Group company is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase, \n",
        "    best_of=3,\n",
        "    max_tokens=50)\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "etailer company headquartered in Liverpool, UK. It was founded in 2005 as Shop Direct Group and rebranded as The Very Group in 2019. The company operates two major brands, Very and Littlewoods, which offer a wide range\n"
        }
      ],
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712290350644
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# logit_bias\n",
        "\n",
        "Defaults to null\n",
        "\n",
        "The logit_bias request parameter is used to modify the likelihood of specified tokens appearing in the completion. We can use this parameter to provide hints to the language model about **which tokens we want or don’t want to appear in the completion**. It basically allows us to make the model more biased towards certain keywords or topics."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-100 bias, which should completely prevent them from appearing.\n",
        "# 100 bias will show only that word\n",
        "start_phrase = 'The Very Group is a '\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    logit_bias={\"30\":10, \"5936\": 10})\n",
        "#5936 for April\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "etail group that operates multiple retail brands, including Very.co.uk\n\n?????????????????????????????????????\n"
        }
      ],
      "execution_count": 57,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712290772693
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Echo and Stop"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By setting the echo parameter to true, you’re asking the language model to **return the prompt embedded within the completion.** This is useful for debugging."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'The Very Group is a '\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    echo=True)\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The Very Group is a place where England’s footie fans can shop for all things related to their favourite sport. You can shop for England football tops, training wear, tracksuits and other iconic merchandise online.\n\nThe store is also one of the best places in the UK to\n"
        }
      ],
      "execution_count": 76,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712313860037
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ** stop ** parameter allows you to specify up to 4 sequences of text on which the language model will halt and return the result. This is useful for specifying early termination triggers for the language model."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'The Very Group company is a '\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    temperature=0,\n",
        "    stop=\"company\")\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "UK-based online retailer that was formerly known as Shop Direct. It was founded in 2005 and is headquartered in Liverpool, England. The \n"
        }
      ],
      "execution_count": 59,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712290876819
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_phrase = 'The Very Group company is a '\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=deployment_name, \n",
        "    prompt=start_phrase,\n",
        "    max_tokens=50,\n",
        "    temperature=0,\n",
        "    stop=[\"company\",\"England\"])\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "UK-based online retailer that was formerly known as Shop Direct. It was founded in 2005 and is headquartered in Liverpool, \n"
        }
      ],
      "execution_count": 60,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712290926381
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/reference"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}